{"cells":[{"cell_type":"markdown","source":["#README Classifier\n\n1.\tG. A. A. Prana, C. Treude, F. Thung, T. Atapattu, and D. Lo, “Categorizing the Content of GitHub README Files - Empirical Software Engineering,” SpringerLink, 12-Oct-2018. [Online]. Available: https://link.springer.com/article/10.1007/s10664-018-9660-3. [Accessed: 11-Dec-2021].\n2.\tGprana. “Gprana/READMEClassifier.” GitHub, https://github.com/gprana/READMEClassifier.\n\n\n\n##Install modules and make imports"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ea154f0f-a9e6-4c27-9858-350c343a1dc3"}}},{"cell_type":"code","source":["%sh\npip install nltk\npip install click\npip install html2text\npip install lxml\npip install markdown2\npip install numpy\npip install pandas\npip install python-dateutil\npip install pytz\npip install regex\npip install scikit-learn\npip install scipy\npip install six\npip install sklearn\npip install soupsieve\npip install threadpoolctl\npip install tqdm\npip install bs4\npip install beautifulsoup4\npip install --upgrade pip\npython -m nltk.downloader all"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5c6453c3-0cd4-4174-a58b-e167db5eb895"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Requirement already satisfied: nltk in /databricks/python3/lib/python3.8/site-packages (3.6.5)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (from nltk) (4.62.3)\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (from nltk) (8.0.3)\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.8/site-packages (from nltk) (2021.11.10)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from nltk) (1.0.1)\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (8.0.3)\nRequirement already satisfied: html2text in /databricks/python3/lib/python3.8/site-packages (2020.1.16)\nRequirement already satisfied: lxml in /databricks/python3/lib/python3.8/site-packages (4.6.4)\nRequirement already satisfied: markdown2 in /databricks/python3/lib/python3.8/site-packages (2.4.2)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.8/site-packages (1.19.2)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.8/site-packages (1.2.4)\nRequirement already satisfied: pytz>=2017.3 in /databricks/python3/lib/python3.8/site-packages (from pandas) (2020.5)\nRequirement already satisfied: numpy>=1.16.5 in /databricks/python3/lib/python3.8/site-packages (from pandas) (1.19.2)\nRequirement already satisfied: python-dateutil>=2.7.3 in /databricks/python3/lib/python3.8/site-packages (from pandas) (2.8.1)\nRequirement already satisfied: six>=1.5 in /databricks/python3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\nRequirement already satisfied: python-dateutil in /databricks/python3/lib/python3.8/site-packages (2.8.1)\nRequirement already satisfied: six>=1.5 in /databricks/python3/lib/python3.8/site-packages (from python-dateutil) (1.15.0)\nRequirement already satisfied: pytz in /databricks/python3/lib/python3.8/site-packages (2020.5)\nRequirement already satisfied: regex in /databricks/python3/lib/python3.8/site-packages (2021.11.10)\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.8/site-packages (0.24.1)\nRequirement already satisfied: joblib>=0.11 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn) (1.0.1)\nRequirement already satisfied: scipy>=0.19.1 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn) (1.6.2)\nRequirement already satisfied: numpy>=1.13.3 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn) (1.19.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.8/site-packages (1.6.2)\nRequirement already satisfied: numpy<1.23.0,>=1.16.5 in /databricks/python3/lib/python3.8/site-packages (from scipy) (1.19.2)\nRequirement already satisfied: six in /databricks/python3/lib/python3.8/site-packages (1.15.0)\nRequirement already satisfied: sklearn in /databricks/python3/lib/python3.8/site-packages (0.0)\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.8/site-packages (from sklearn) (0.24.1)\nRequirement already satisfied: joblib>=0.11 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.0.1)\nRequirement already satisfied: scipy>=0.19.1 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.6.2)\nRequirement already satisfied: numpy>=1.13.3 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.19.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\nRequirement already satisfied: soupsieve in /databricks/python3/lib/python3.8/site-packages (2.3.1)\nRequirement already satisfied: threadpoolctl in /databricks/python3/lib/python3.8/site-packages (2.1.0)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (4.62.3)\nRequirement already satisfied: bs4 in /databricks/python3/lib/python3.8/site-packages (0.0.1)\nRequirement already satisfied: beautifulsoup4 in /databricks/python3/lib/python3.8/site-packages (from bs4) (4.10.0)\nRequirement already satisfied: soupsieve>1.2 in /databricks/python3/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.3.1)\nRequirement already satisfied: beautifulsoup4 in /databricks/python3/lib/python3.8/site-packages (4.10.0)\nRequirement already satisfied: soupsieve>1.2 in /databricks/python3/lib/python3.8/site-packages (from beautifulsoup4) (2.3.1)\nRequirement already satisfied: pip in /databricks/python3/lib/python3.8/site-packages (21.3.1)\n/usr/lib/python3.8/runpy.py:127: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n  warn(RuntimeWarning(msg))\n[nltk_data] Downloading collection 'all'\n[nltk_data]    | \n[nltk_data]    | Downloading package abc to /root/nltk_data...\n[nltk_data]    |   Package abc is already up-to-date!\n[nltk_data]    | Downloading package alpino to /root/nltk_data...\n[nltk_data]    |   Package alpino is already up-to-date!\n[nltk_data]    | Downloading package biocreative_ppi to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n[nltk_data]    | Downloading package brown to /root/nltk_data...\n[nltk_data]    |   Package brown is already up-to-date!\n[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n[nltk_data]    |   Package brown_tei is already up-to-date!\n[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n[nltk_data]    |   Package cess_cat is already up-to-date!\n[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n[nltk_data]    |   Package cess_esp is already up-to-date!\n[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n[nltk_data]    |   Package chat80 is already up-to-date!\n[nltk_data]    | Downloading package city_database to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package city_database is already up-to-date!\n[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n[nltk_data]    |   Package cmudict is already up-to-date!\n[nltk_data]    | Downloading package comparative_sentences to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package comparative_sentences is already up-to-\n[nltk_data]    |       date!\n[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n[nltk_data]    |   Package comtrans is already up-to-date!\n[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n[nltk_data]    |   Package conll2000 is already up-to-date!\n[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n[nltk_data]    |   Package conll2002 is already up-to-date!\n[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n[nltk_data]    |   Package conll2007 is already up-to-date!\n[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n[nltk_data]    |   Package crubadan is already up-to-date!\n[nltk_data]    | Downloading package dependency_treebank to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package dependency_treebank is already up-to-date!\n[nltk_data]    | Downloading package dolch to /root/nltk_data...\n[nltk_data]    |   Package dolch is already up-to-date!\n[nltk_data]    | Downloading package europarl_raw to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package europarl_raw is already up-to-date!\n[nltk_data]    | Downloading package floresta to /root/nltk_data...\n[nltk_data]    |   Package floresta is already up-to-date!\n[nltk_data]    | Downloading package framenet_v15 to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package framenet_v15 is already up-to-date!\n[nltk_data]    | Downloading package framenet_v17 to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package framenet_v17 is already up-to-date!\n[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n[nltk_data]    |   Package gazetteers is already up-to-date!\n[nltk_data]    | Downloading package genesis to /root/nltk_data...\n[nltk_data]    |   Package genesis is already up-to-date!\n[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n[nltk_data]    |   Package gutenberg is already up-to-date!\n[nltk_data]    | Downloading package ieer to /root/nltk_data...\n[nltk_data]    |   Package ieer is already up-to-date!\n[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n[nltk_data]    |   Package inaugural is already up-to-date!\n[nltk_data]    | Downloading package indian to /root/nltk_data...\n[nltk_data]    |   Package indian is already up-to-date!\n[nltk_data]    | Downloading package jeita to /root/nltk_data...\n[nltk_data]    |   Package jeita is already up-to-date!\n[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n[nltk_data]    |   Package kimmo is already up-to-date!\n[nltk_data]    | Downloading package knbc to /root/nltk_data...\n[nltk_data]    |   Package knbc is already up-to-date!\n[nltk_data]    | Downloading package lin_thesaurus to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n[nltk_data]    |   Package mac_morpho is already up-to-date!\n[nltk_data]    | Downloading package machado to /root/nltk_data...\n[nltk_data]    |   Package machado is already up-to-date!\n[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n[nltk_data]    |   Package masc_tagged is already up-to-date!\n[nltk_data]    | Downloading package moses_sample to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package moses_sample is already up-to-date!\n[nltk_data]    | Downloading package movie_reviews to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package movie_reviews is already up-to-date!\n[nltk_data]    | Downloading package names to /root/nltk_data...\n[nltk_data]    |   Package names is already up-to-date!\n[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n[nltk_data]    |   Package nps_chat is already up-to-date!\n[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n[nltk_data]    |   Package omw-1.4 is already up-to-date!\n[nltk_data]    | Downloading package omw to /root/nltk_data...\n[nltk_data]    |   Package omw is already up-to-date!\n[nltk_data]    | Downloading package opinion_lexicon to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n[nltk_data]    |   Package paradigms is already up-to-date!\n[nltk_data]    | Downloading package pil to /root/nltk_data...\n[nltk_data]    |   Package pil is already up-to-date!\n[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n[nltk_data]    |   Package pl196x is already up-to-date!\n[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n[nltk_data]    |   Package ppattach is already up-to-date!\n[nltk_data]    | Downloading package problem_reports to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package problem_reports is already up-to-date!\n[nltk_data]    | Downloading package propbank to /root/nltk_data...\n[nltk_data]    |   Package propbank is already up-to-date!\n[nltk_data]    | Downloading package ptb to /root/nltk_data...\n[nltk_data]    |   Package ptb is already up-to-date!\n[nltk_data]    | Downloading package product_reviews_1 to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n[nltk_data]    | Downloading package product_reviews_2 to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n[nltk_data]    |   Package pros_cons is already up-to-date!\n[nltk_data]    | Downloading package qc to /root/nltk_data...\n[nltk_data]    |   Package qc is already up-to-date!\n[nltk_data]    | Downloading package reuters to /root/nltk_data...\n[nltk_data]    |   Package reuters is already up-to-date!\n[nltk_data]    | Downloading package rte to /root/nltk_data...\n[nltk_data]    |   Package rte is already up-to-date!\n[nltk_data]    | Downloading package semcor to /root/nltk_data...\n[nltk_data]    |   Package semcor is already up-to-date!\n[nltk_data]    | Downloading package senseval to /root/nltk_data...\n[nltk_data]    |   Package senseval is already up-to-date!\n[nltk_data]    | Downloading package sentiwordnet to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package sentiwordnet is already up-to-date!\n[nltk_data]    | Downloading package sentence_polarity to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package sentence_polarity is already up-to-date!\n[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n[nltk_data]    |   Package shakespeare is already up-to-date!\n[nltk_data]    | Downloading package sinica_treebank to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package sinica_treebank is already up-to-date!\n[nltk_data]    | Downloading package smultron to /root/nltk_data...\n[nltk_data]    |   Package smultron is already up-to-date!\n[nltk_data]    | Downloading package state_union to /root/nltk_data...\n[nltk_data]    |   Package state_union is already up-to-date!\n[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n[nltk_data]    |   Package stopwords is already up-to-date!\n[nltk_data]    | Downloading package subjectivity to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package subjectivity is already up-to-date!\n[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n[nltk_data]    |   Package swadesh is already up-to-date!\n[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n[nltk_data]    |   Package switchboard is already up-to-date!\n[nltk_data]    | Downloading package timit to /root/nltk_data...\n[nltk_data]    |   Package timit is already up-to-date!\n[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n[nltk_data]    |   Package toolbox is already up-to-date!\n[nltk_data]    | Downloading package treebank to /root/nltk_data...\n[nltk_data]    |   Package treebank is already up-to-date!\n[nltk_data]    | Downloading package twitter_samples to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package twitter_samples is already up-to-date!\n[nltk_data]    | Downloading package udhr to /root/nltk_data...\n[nltk_data]    |   Package udhr is already up-to-date!\n[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n[nltk_data]    |   Package udhr2 is already up-to-date!\n[nltk_data]    | Downloading package unicode_samples to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package unicode_samples is already up-to-date!\n[nltk_data]    | Downloading package universal_treebanks_v20 to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n[nltk_data]    |       date!\n[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n[nltk_data]    |   Package verbnet is already up-to-date!\n[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n[nltk_data]    |   Package verbnet3 is already up-to-date!\n[nltk_data]    | Downloading package webtext to /root/nltk_data...\n[nltk_data]    |   Package webtext is already up-to-date!\n[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n[nltk_data]    |   Package wordnet is already up-to-date!\n[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n[nltk_data]    |   Package wordnet31 is already up-to-date!\n[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n[nltk_data]    |   Package wordnet_ic is already up-to-date!\n[nltk_data]    | Downloading package words to /root/nltk_data...\n[nltk_data]    |   Package words is already up-to-date!\n[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n[nltk_data]    |   Package ycoe is already up-to-date!\n[nltk_data]    | Downloading package rslp to /root/nltk_data...\n[nltk_data]    |   Package rslp is already up-to-date!\n[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n[nltk_data]    |       to-date!\n[nltk_data]    | Downloading package universal_tagset to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package universal_tagset is already up-to-date!\n[nltk_data]    | Downloading package maxent_ne_chunker to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n[nltk_data]    | Downloading package punkt to /root/nltk_data...\n[nltk_data]    |   Package punkt is already up-to-date!\n[nltk_data]    | Downloading package book_grammars to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package book_grammars is already up-to-date!\n[nltk_data]    | Downloading package sample_grammars to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package sample_grammars is already up-to-date!\n[nltk_data]    | Downloading package spanish_grammars to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package spanish_grammars is already up-to-date!\n[nltk_data]    | Downloading package basque_grammars to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package basque_grammars is already up-to-date!\n[nltk_data]    | Downloading package large_grammars to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package large_grammars is already up-to-date!\n[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n[nltk_data]    |   Package tagsets is already up-to-date!\n[nltk_data]    | Downloading package snowball_data to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package snowball_data is already up-to-date!\n[nltk_data]    | Downloading package bllip_wsj_no_aux to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n[nltk_data]    | Downloading package word2vec_sample to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package word2vec_sample is already up-to-date!\n[nltk_data]    | Downloading package panlex_swadesh to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n[nltk_data]    |   Package mte_teip5 is already up-to-date!\n[nltk_data]    | Downloading package averaged_perceptron_tagger to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n[nltk_data]    |       to-date!\n[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n[nltk_data]    |       up-to-date!\n[nltk_data]    | Downloading package perluniprops to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package perluniprops is already up-to-date!\n[nltk_data]    | Downloading package nonbreaking_prefixes to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n[nltk_data]    | Downloading package vader_lexicon to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package vader_lexicon is already up-to-date!\n[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n[nltk_data]    |   Package porter_test is already up-to-date!\n[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n[nltk_data]    |   Package wmt15_eval is already up-to-date!\n[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n[nltk_data]    | \n[nltk_data]  Done downloading collection all\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: nltk in /databricks/python3/lib/python3.8/site-packages (3.6.5)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (from nltk) (4.62.3)\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (from nltk) (8.0.3)\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.8/site-packages (from nltk) (2021.11.10)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from nltk) (1.0.1)\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (8.0.3)\nRequirement already satisfied: html2text in /databricks/python3/lib/python3.8/site-packages (2020.1.16)\nRequirement already satisfied: lxml in /databricks/python3/lib/python3.8/site-packages (4.6.4)\nRequirement already satisfied: markdown2 in /databricks/python3/lib/python3.8/site-packages (2.4.2)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.8/site-packages (1.19.2)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.8/site-packages (1.2.4)\nRequirement already satisfied: pytz>=2017.3 in /databricks/python3/lib/python3.8/site-packages (from pandas) (2020.5)\nRequirement already satisfied: numpy>=1.16.5 in /databricks/python3/lib/python3.8/site-packages (from pandas) (1.19.2)\nRequirement already satisfied: python-dateutil>=2.7.3 in /databricks/python3/lib/python3.8/site-packages (from pandas) (2.8.1)\nRequirement already satisfied: six>=1.5 in /databricks/python3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\nRequirement already satisfied: python-dateutil in /databricks/python3/lib/python3.8/site-packages (2.8.1)\nRequirement already satisfied: six>=1.5 in /databricks/python3/lib/python3.8/site-packages (from python-dateutil) (1.15.0)\nRequirement already satisfied: pytz in /databricks/python3/lib/python3.8/site-packages (2020.5)\nRequirement already satisfied: regex in /databricks/python3/lib/python3.8/site-packages (2021.11.10)\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.8/site-packages (0.24.1)\nRequirement already satisfied: joblib>=0.11 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn) (1.0.1)\nRequirement already satisfied: scipy>=0.19.1 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn) (1.6.2)\nRequirement already satisfied: numpy>=1.13.3 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn) (1.19.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.8/site-packages (1.6.2)\nRequirement already satisfied: numpy<1.23.0,>=1.16.5 in /databricks/python3/lib/python3.8/site-packages (from scipy) (1.19.2)\nRequirement already satisfied: six in /databricks/python3/lib/python3.8/site-packages (1.15.0)\nRequirement already satisfied: sklearn in /databricks/python3/lib/python3.8/site-packages (0.0)\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.8/site-packages (from sklearn) (0.24.1)\nRequirement already satisfied: joblib>=0.11 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.0.1)\nRequirement already satisfied: scipy>=0.19.1 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.6.2)\nRequirement already satisfied: numpy>=1.13.3 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.19.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\nRequirement already satisfied: soupsieve in /databricks/python3/lib/python3.8/site-packages (2.3.1)\nRequirement already satisfied: threadpoolctl in /databricks/python3/lib/python3.8/site-packages (2.1.0)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (4.62.3)\nRequirement already satisfied: bs4 in /databricks/python3/lib/python3.8/site-packages (0.0.1)\nRequirement already satisfied: beautifulsoup4 in /databricks/python3/lib/python3.8/site-packages (from bs4) (4.10.0)\nRequirement already satisfied: soupsieve>1.2 in /databricks/python3/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.3.1)\nRequirement already satisfied: beautifulsoup4 in /databricks/python3/lib/python3.8/site-packages (4.10.0)\nRequirement already satisfied: soupsieve>1.2 in /databricks/python3/lib/python3.8/site-packages (from beautifulsoup4) (2.3.1)\nRequirement already satisfied: pip in /databricks/python3/lib/python3.8/site-packages (21.3.1)\n/usr/lib/python3.8/runpy.py:127: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n  warn(RuntimeWarning(msg))\n[nltk_data] Downloading collection 'all'\n[nltk_data]    | \n[nltk_data]    | Downloading package abc to /root/nltk_data...\n[nltk_data]    |   Package abc is already up-to-date!\n[nltk_data]    | Downloading package alpino to /root/nltk_data...\n[nltk_data]    |   Package alpino is already up-to-date!\n[nltk_data]    | Downloading package biocreative_ppi to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n[nltk_data]    | Downloading package brown to /root/nltk_data...\n[nltk_data]    |   Package brown is already up-to-date!\n[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n[nltk_data]    |   Package brown_tei is already up-to-date!\n[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n[nltk_data]    |   Package cess_cat is already up-to-date!\n[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n[nltk_data]    |   Package cess_esp is already up-to-date!\n[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n[nltk_data]    |   Package chat80 is already up-to-date!\n[nltk_data]    | Downloading package city_database to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package city_database is already up-to-date!\n[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n[nltk_data]    |   Package cmudict is already up-to-date!\n[nltk_data]    | Downloading package comparative_sentences to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package comparative_sentences is already up-to-\n[nltk_data]    |       date!\n[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n[nltk_data]    |   Package comtrans is already up-to-date!\n[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n[nltk_data]    |   Package conll2000 is already up-to-date!\n[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n[nltk_data]    |   Package conll2002 is already up-to-date!\n[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n[nltk_data]    |   Package conll2007 is already up-to-date!\n[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n[nltk_data]    |   Package crubadan is already up-to-date!\n[nltk_data]    | Downloading package dependency_treebank to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package dependency_treebank is already up-to-date!\n[nltk_data]    | Downloading package dolch to /root/nltk_data...\n[nltk_data]    |   Package dolch is already up-to-date!\n[nltk_data]    | Downloading package europarl_raw to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package europarl_raw is already up-to-date!\n[nltk_data]    | Downloading package floresta to /root/nltk_data...\n[nltk_data]    |   Package floresta is already up-to-date!\n[nltk_data]    | Downloading package framenet_v15 to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package framenet_v15 is already up-to-date!\n[nltk_data]    | Downloading package framenet_v17 to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package framenet_v17 is already up-to-date!\n[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n[nltk_data]    |   Package gazetteers is already up-to-date!\n[nltk_data]    | Downloading package genesis to /root/nltk_data...\n[nltk_data]    |   Package genesis is already up-to-date!\n[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n[nltk_data]    |   Package gutenberg is already up-to-date!\n[nltk_data]    | Downloading package ieer to /root/nltk_data...\n[nltk_data]    |   Package ieer is already up-to-date!\n[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n[nltk_data]    |   Package inaugural is already up-to-date!\n[nltk_data]    | Downloading package indian to /root/nltk_data...\n[nltk_data]    |   Package indian is already up-to-date!\n[nltk_data]    | Downloading package jeita to /root/nltk_data...\n[nltk_data]    |   Package jeita is already up-to-date!\n[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n[nltk_data]    |   Package kimmo is already up-to-date!\n[nltk_data]    | Downloading package knbc to /root/nltk_data...\n[nltk_data]    |   Package knbc is already up-to-date!\n[nltk_data]    | Downloading package lin_thesaurus to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n[nltk_data]    |   Package mac_morpho is already up-to-date!\n[nltk_data]    | Downloading package machado to /root/nltk_data...\n[nltk_data]    |   Package machado is already up-to-date!\n[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n[nltk_data]    |   Package masc_tagged is already up-to-date!\n[nltk_data]    | Downloading package moses_sample to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package moses_sample is already up-to-date!\n[nltk_data]    | Downloading package movie_reviews to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package movie_reviews is already up-to-date!\n[nltk_data]    | Downloading package names to /root/nltk_data...\n[nltk_data]    |   Package names is already up-to-date!\n[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n[nltk_data]    |   Package nps_chat is already up-to-date!\n[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n[nltk_data]    |   Package omw-1.4 is already up-to-date!\n[nltk_data]    | Downloading package omw to /root/nltk_data...\n[nltk_data]    |   Package omw is already up-to-date!\n[nltk_data]    | Downloading package opinion_lexicon to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n[nltk_data]    |   Package paradigms is already up-to-date!\n[nltk_data]    | Downloading package pil to /root/nltk_data...\n[nltk_data]    |   Package pil is already up-to-date!\n[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n[nltk_data]    |   Package pl196x is already up-to-date!\n[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n[nltk_data]    |   Package ppattach is already up-to-date!\n[nltk_data]    | Downloading package problem_reports to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package problem_reports is already up-to-date!\n[nltk_data]    | Downloading package propbank to /root/nltk_data...\n[nltk_data]    |   Package propbank is already up-to-date!\n[nltk_data]    | Downloading package ptb to /root/nltk_data...\n[nltk_data]    |   Package ptb is already up-to-date!\n[nltk_data]    | Downloading package product_reviews_1 to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n[nltk_data]    | Downloading package product_reviews_2 to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n[nltk_data]    |   Package pros_cons is already up-to-date!\n[nltk_data]    | Downloading package qc to /root/nltk_data...\n[nltk_data]    |   Package qc is already up-to-date!\n[nltk_data]    | Downloading package reuters to /root/nltk_data...\n[nltk_data]    |   Package reuters is already up-to-date!\n[nltk_data]    | Downloading package rte to /root/nltk_data...\n[nltk_data]    |   Package rte is already up-to-date!\n[nltk_data]    | Downloading package semcor to /root/nltk_data...\n[nltk_data]    |   Package semcor is already up-to-date!\n[nltk_data]    | Downloading package senseval to /root/nltk_data...\n[nltk_data]    |   Package senseval is already up-to-date!\n[nltk_data]    | Downloading package sentiwordnet to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package sentiwordnet is already up-to-date!\n[nltk_data]    | Downloading package sentence_polarity to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package sentence_polarity is already up-to-date!\n[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n[nltk_data]    |   Package shakespeare is already up-to-date!\n[nltk_data]    | Downloading package sinica_treebank to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package sinica_treebank is already up-to-date!\n[nltk_data]    | Downloading package smultron to /root/nltk_data...\n[nltk_data]    |   Package smultron is already up-to-date!\n[nltk_data]    | Downloading package state_union to /root/nltk_data...\n[nltk_data]    |   Package state_union is already up-to-date!\n[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n[nltk_data]    |   Package stopwords is already up-to-date!\n[nltk_data]    | Downloading package subjectivity to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package subjectivity is already up-to-date!\n[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n[nltk_data]    |   Package swadesh is already up-to-date!\n[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n[nltk_data]    |   Package switchboard is already up-to-date!\n[nltk_data]    | Downloading package timit to /root/nltk_data...\n[nltk_data]    |   Package timit is already up-to-date!\n[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n[nltk_data]    |   Package toolbox is already up-to-date!\n[nltk_data]    | Downloading package treebank to /root/nltk_data...\n[nltk_data]    |   Package treebank is already up-to-date!\n[nltk_data]    | Downloading package twitter_samples to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package twitter_samples is already up-to-date!\n[nltk_data]    | Downloading package udhr to /root/nltk_data...\n[nltk_data]    |   Package udhr is already up-to-date!\n[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n[nltk_data]    |   Package udhr2 is already up-to-date!\n[nltk_data]    | Downloading package unicode_samples to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package unicode_samples is already up-to-date!\n[nltk_data]    | Downloading package universal_treebanks_v20 to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n[nltk_data]    |       date!\n[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n[nltk_data]    |   Package verbnet is already up-to-date!\n[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n[nltk_data]    |   Package verbnet3 is already up-to-date!\n[nltk_data]    | Downloading package webtext to /root/nltk_data...\n[nltk_data]    |   Package webtext is already up-to-date!\n[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n[nltk_data]    |   Package wordnet is already up-to-date!\n[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n[nltk_data]    |   Package wordnet31 is already up-to-date!\n[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n[nltk_data]    |   Package wordnet_ic is already up-to-date!\n[nltk_data]    | Downloading package words to /root/nltk_data...\n[nltk_data]    |   Package words is already up-to-date!\n[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n[nltk_data]    |   Package ycoe is already up-to-date!\n[nltk_data]    | Downloading package rslp to /root/nltk_data...\n[nltk_data]    |   Package rslp is already up-to-date!\n[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n[nltk_data]    |       to-date!\n[nltk_data]    | Downloading package universal_tagset to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package universal_tagset is already up-to-date!\n[nltk_data]    | Downloading package maxent_ne_chunker to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n[nltk_data]    | Downloading package punkt to /root/nltk_data...\n[nltk_data]    |   Package punkt is already up-to-date!\n[nltk_data]    | Downloading package book_grammars to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package book_grammars is already up-to-date!\n[nltk_data]    | Downloading package sample_grammars to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package sample_grammars is already up-to-date!\n[nltk_data]    | Downloading package spanish_grammars to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package spanish_grammars is already up-to-date!\n[nltk_data]    | Downloading package basque_grammars to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package basque_grammars is already up-to-date!\n[nltk_data]    | Downloading package large_grammars to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package large_grammars is already up-to-date!\n[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n[nltk_data]    |   Package tagsets is already up-to-date!\n[nltk_data]    | Downloading package snowball_data to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package snowball_data is already up-to-date!\n[nltk_data]    | Downloading package bllip_wsj_no_aux to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n[nltk_data]    | Downloading package word2vec_sample to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package word2vec_sample is already up-to-date!\n[nltk_data]    | Downloading package panlex_swadesh to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n[nltk_data]    |   Package mte_teip5 is already up-to-date!\n[nltk_data]    | Downloading package averaged_perceptron_tagger to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n[nltk_data]    |       to-date!\n[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n[nltk_data]    |       up-to-date!\n[nltk_data]    | Downloading package perluniprops to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package perluniprops is already up-to-date!\n[nltk_data]    | Downloading package nonbreaking_prefixes to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n[nltk_data]    | Downloading package vader_lexicon to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package vader_lexicon is already up-to-date!\n[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n[nltk_data]    |   Package porter_test is already up-to-date!\n[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n[nltk_data]    |   Package wmt15_eval is already up-to-date!\n[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n[nltk_data]    | \n[nltk_data]  Done downloading collection all\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["\n\n# standard modules\nimport pandas as pd\nimport numpy as np\nimport nltk\nimport re\n\n# feature engineering\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.preprocessing import LabelBinarizer\n\n# classifiers\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n\n\n# measures\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import classification_report\n\n# other\nfrom joblib import Parallel\nfrom joblib import delayed\nfrom sklearn.utils import resample\nfrom sklearn.utils.validation import check_is_fitted\nfrom sklearn.base import BaseEstimator, clone\n\nnltk.download('words')\n\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"79b13783-4df8-471c-9d71-dc858877836c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\nOut[7]: True","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\nOut[7]: True"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["##Preparation\n\n###Code for deriving heuristic features"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9ce4b98c-fa60-45d2-bb84-7ce48afd4c60"}}},{"cell_type":"code","source":["class Heuristic_Feature:\n  \"\"\"\n  Class for deriving heuristic features from input text\n\n  Naming convention:\n    heur_<x>_<y>_<number>\n      <x> = c if meant for use in content text, h if meant for use with header\n      <y> = k if uses keyword matching, s if uses text statistics (e.g. word count), c if combination\n  \"\"\"\n\n  def heur_c_k_001(self, input_text):\n    if ('report bugs' in input_text.lower()) or ('reporting bugs' in input_text.lower()):\n      return 1\n    else:\n      return 0\n\n  def heur_c_k_002(self, input_text):\n    if ' is a ' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_c_k_003(self, input_text):\n    if '@abstr_code_section' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_c_k_004(self, input_text):\n    if 'attempts to' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_c_k_005(self, input_text):\n    if 'inspired by' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_c_k_006(self, input_text):\n    if 'install ' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_c_k_007(self, input_text):\n    if 'reasons' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  # Do not use lower() because we want to capture \"Added\" at beginning of sentence\n  def heur_c_k_008(self, input_text):\n    if 'Added ' in input_text:\n      return 1\n    else:\n      return 0\n\n  def heur_c_k_009(self, input_text):\n    if 'copyright' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_c_k_010(self, input_text):\n    if '@abstr_mailto' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_c_k_011(self, input_text):\n    if 'you can ' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  # Check if the text comprises solely of @abstr_code_section\n  def heur_c_k_012(self, input_text):\n    if '@abstr_code_section' == input_text.lower().strip():\n      return 1\n    else:\n      return 0\n\n  def heur_c_k_013(self, input_text):\n    if 'About' in input_text:\n      return 1\n    else:\n      return 0\n\n  def heur_c_k_014(self, input_text):\n    if 'be sure to' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_c_k_015(self, input_text):\n    if 'Download' in input_text:\n      return 1\n    else:\n      return 0\n\n  def heur_c_k_016(self, input_text):\n    if 'overview' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_c_k_017(self, input_text):\n    if 'get started' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_c_k_018(self, input_text):\n    if 'reasons' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_c_k_019(self, input_text):\n    if 'dependenc' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_c_k_020(self, input_text):\n    if 'rerun' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_c_k_021(self, input_text):\n    if 'you''ll be able' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_c_k_022(self, input_text):\n    if 'you must' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_c_k_023(self, input_text):\n    if 'previous version' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_001(self, input_text):\n    if 'configur' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_002(self, input_text):\n    if 'what' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_003(self, input_text):\n    if 'why' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_004(self, input_text):\n    if 'approach' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_005(self, input_text):\n    if 'bugs' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_006(self, input_text):\n    if 'contrib' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_007(self, input_text):\n    if 'credit' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_008(self, input_text):\n    if 'feature' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_009(self, input_text):\n    if 'install' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_010(self, input_text):\n    if 'intro' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_011(self, input_text):\n    if 'licen' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_012(self, input_text):\n    if 'objective' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_013(self, input_text):\n    if 'request' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_014(self, input_text):\n    if 'requirement' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_015(self, input_text):\n    if 'resource' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_016(self, input_text):\n    if 'setting' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_017(self, input_text):\n    if 'setup' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_018(self, input_text):\n    if 'started' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_019(self, input_text):\n    if 'usage' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_020(self, input_text):\n    if 'version' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_021(self, input_text):\n    if 'welcome' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_022(self, input_text):\n    if 'what is' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_023(self, input_text):\n    if 'overview' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_024(self, input_text):\n    if 'basic' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_025(self, input_text):\n    if 'roadmap' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_026(self, input_text):\n    if 'todo' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_027(self, input_text):\n    if 'example' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_028(self, input_text):\n    if 'about' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  def heur_h_k_029(self, input_text):\n    if 'reference' in input_text.lower():\n      return 1\n    else:\n      return 0\n\n  # Return 1 if string is single non-English word\n  # WARNING: For speed, instantiate the word set outside and pass it as parameter,\n  # so that instantiation will be done once for each program run\n  # instead of once for each row this heuristic is applied to\n  def heur_h_c_001(self, input_text, words=None):\n    lcase_input_text = input_text.lower()\n    s = lcase_input_text.split(' ')\n    if len(s) != 1:\n      return 0\n    else:\n      if words is None:\n        words = set(nltk.corpus.words.words())\n      if s[0] in words:\n        return 0\n      else:\n        return 1\n    return 0\n\n  # Returns 1 if a word in heading text is in repo name, or the other way around\n  def heur_h_c_002(self, heading_text, repo_url):\n    heading_words = heading_text.lower().split(' ')\n    repo_name = re.sub(r\"http(s)*:\\/\\/www\\.github\\.com\\/.+\\/\", '', repo_url)\n    repo_name = repo_name.replace('.', ' ').replace('-', ' ')\n    repo_name_words = repo_name.lower().split(' ')\n    match = [val for val in heading_words if val in repo_name_words]\n    if len(match) > 0:\n      return 1\n    else:\n      return 0\n\n  # See whether text comprises entirely of ASCII characters\n  def heur_c_s_001(self, input_text):\n    try:\n      input_text.encode(encoding='utf-8').decode('ascii')\n    except UnicodeDecodeError:\n      return 0\n    else:\n      return 1\n\n  # Generate DataFrame of derived features using DataFrames of some initial features\n  def derive_features_using_heuristics(self, url_corpus, heading_text_corpus, content_corpus):\n    derived_features = pd.DataFrame()\n    derived_features['heur_c_k_001'] = [self.heur_c_k_001(x) for x in content_corpus]\n    derived_features['heur_c_k_002'] = [self.heur_c_k_002(x) for x in content_corpus]\n    derived_features['heur_c_k_003'] = [self.heur_c_k_003(x) for x in content_corpus]\n    derived_features['heur_c_k_004'] = [self.heur_c_k_004(x) for x in content_corpus]\n    derived_features['heur_c_k_005'] = [self.heur_c_k_005(x) for x in content_corpus]\n    derived_features['heur_c_k_006'] = [self.heur_c_k_006(x) for x in content_corpus]\n    derived_features['heur_c_k_007'] = [self.heur_c_k_007(x) for x in content_corpus]\n    derived_features['heur_h_k_001'] = [self.heur_h_k_001(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_002'] = [self.heur_h_k_002(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_003'] = [self.heur_h_k_003(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_004'] = [self.heur_h_k_004(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_005'] = [self.heur_h_k_005(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_006'] = [self.heur_h_k_006(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_007'] = [self.heur_h_k_007(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_008'] = [self.heur_h_k_008(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_009'] = [self.heur_h_k_009(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_010'] = [self.heur_h_k_010(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_011'] = [self.heur_h_k_011(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_012'] = [self.heur_h_k_012(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_013'] = [self.heur_h_k_013(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_014'] = [self.heur_h_k_014(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_015'] = [self.heur_h_k_015(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_016'] = [self.heur_h_k_016(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_017'] = [self.heur_h_k_017(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_018'] = [self.heur_h_k_018(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_019'] = [self.heur_h_k_019(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_020'] = [self.heur_h_k_020(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_021'] = [self.heur_h_k_021(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_022'] = [self.heur_h_k_022(x) for x in heading_text_corpus]\n    derived_features['heur_c_s_001'] = [self.heur_c_s_001(x) for x in heading_text_corpus]\n\n    # Batch 02\n    derived_features['heur_c_k_008'] = [self.heur_c_k_008(x) for x in content_corpus]\n    derived_features['heur_c_k_009'] = [self.heur_c_k_009(x) for x in content_corpus]\n    derived_features['heur_c_k_010'] = [self.heur_c_k_010(x) for x in content_corpus]\n    derived_features['heur_c_k_011'] = [self.heur_c_k_011(x) for x in content_corpus]\n    derived_features['heur_c_k_012'] = [self.heur_c_k_012(x) for x in content_corpus]\n    derived_features['heur_c_k_013'] = [self.heur_c_k_013(x) for x in content_corpus]\n    derived_features['heur_h_k_023'] = [self.heur_h_k_023(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_024'] = [self.heur_h_k_024(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_025'] = [self.heur_h_k_025(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_026'] = [self.heur_h_k_026(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_027'] = [self.heur_h_k_027(x) for x in heading_text_corpus]\n    words = set(nltk.corpus.words.words())\n    derived_features['heur_h_c_001'] = [self.heur_h_c_001(x, words) for x in heading_text_corpus]\n    derived_features['heur_h_c_002'] = [self.heur_h_c_002(x, y) for x, y in zip(heading_text_corpus, url_corpus)]\n\n    # Batch 03\n    derived_features['heur_c_k_014'] = [self.heur_c_k_014(x) for x in content_corpus]\n    derived_features['heur_c_k_015'] = [self.heur_c_k_015(x) for x in content_corpus]\n    derived_features['heur_c_k_016'] = [self.heur_c_k_016(x) for x in content_corpus]\n    derived_features['heur_c_k_017'] = [self.heur_c_k_017(x) for x in content_corpus]\n    derived_features['heur_c_k_018'] = [self.heur_c_k_018(x) for x in content_corpus]\n    derived_features['heur_c_k_019'] = [self.heur_c_k_019(x) for x in content_corpus]\n    derived_features['heur_c_k_020'] = [self.heur_c_k_020(x) for x in content_corpus]\n    derived_features['heur_c_k_021'] = [self.heur_c_k_021(x) for x in content_corpus]\n    derived_features['heur_c_k_022'] = [self.heur_c_k_022(x) for x in content_corpus]\n    derived_features['heur_c_k_023'] = [self.heur_c_k_023(x) for x in content_corpus]\n    derived_features['heur_h_k_028'] = [self.heur_h_k_028(x) for x in heading_text_corpus]\n    derived_features['heur_h_k_029'] = [self.heur_h_k_029(x) for x in heading_text_corpus]\n\n    return derived_features"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6e06634a-2a73-4c3e-b773-6fb00caf593c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["###Code for OneVsRestClassifier"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4819a2e1-9f0e-440e-a31d-440cc5bd875d"}}},{"cell_type":"code","source":["class _ConstantPredictor(BaseEstimator):\n  def fit(self, X, y):\n    self.y_ = y\n    return self\n\n  def predict(self, X):\n    check_is_fitted(self, 'y_')\n    return np.repeat(self.y_, X.shape[0])\n\n  def decision_function(self, X):\n    check_is_fitted(self, 'y_')\n    return np.repeat(self.y_, X.shape[0])\n\n  def predict_proba(self, X):\n    check_is_fitted(self, 'y_')\n    return np.repeat([np.hstack([1 - self.y_, self.y_])], X.shape[0], axis=0)\n\n\ndef _fit_binary(estimator, X, y, classes=None):\n  \"\"\"\n  Fit a single binary estimator\n  \"\"\"\n  unique_y = np.unique(y)\n\n  if len(unique_y) == 1:\n    if classes is not None:\n      if y[0] == -1:\n        c = 0\n      else:\n        c = y[0]\n    estimator = _ConstantPredictor().fit(X, unique_y)\n\n  else:\n    estimator = clone(estimator)\n    estimator.fit(X, y)\n\n  return estimator\n\n\nclass OneVsRestClassifierBalance(OneVsRestClassifier):\n  def fit(self, X, y):\n    self.label_binarizer_ = LabelBinarizer(sparse_output=True)\n    Y = self.label_binarizer_.fit_transform(y)\n    Y = Y.tocsc()\n    self.classes_ = self.label_binarizer_.classes_\n    totalIns = Y.shape[0]\n    XBal = []\n    YBal = []\n\n    for i in range(len(self.label_binarizer_.classes_)):\n      if len(y.shape) > 1:\n        # Matrix\n        curIdxs = Y[:, i].nonzero()[0]\n      else:\n        curIdxs = Y.nonzero()[0]\n\n      baseX = X[curIdxs, :]\n\n      if len(y.shape) > 1:\n        # Matrix\n        baseY = y[curIdxs, :]\n      else:\n        # array, e.g. due to testing classifier performance for single label prediction\n        baseY = y[curIdxs]\n\n      tempX = X\n      tempY = y\n      imbalancedIns = baseX.shape[0]\n      numDup = totalIns/imbalancedIns - 1\n\n      for j in range(int(numDup)):\n        tempX = np.vstack((tempX, baseX))\n\n        if len(y.shape) > 1:\n          tempY = np.vstack((tempY, baseY))\n\n        else:\n          tempY = np.concatenate((tempY, baseY))\n\n      numAdd = totalIns % imbalancedIns\n      tempX = np.vstack(\n        (tempX, resample(baseX, n_samples=numAdd, random_state=0)))\n\n      if len(y.shape) > 1:\n        tempY = np.vstack(\n          (tempY, resample(baseY, n_samples=numAdd, random_state=0)))\n\n      else:\n        tempY = np.concatenate(\n          (tempY, resample(baseY, n_samples=numAdd, random_state=0)))\n\n      XBal.append(tempX)\n\n      if len(y.shape) > 1:\n        YBal.append(tempY[:, i])\n\n      else:\n        YBal.append(tempY)\n\n    self.estimators_ = Parallel(n_jobs=self.n_jobs)(delayed(_fit_binary)(self.estimator, XBal[i], YBal[i], classes=[\"not %s\" % self.label_binarizer_.classes_[i], self.label_binarizer_.classes_[i]]) for i in range(len(YBal)))\n    return self"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b2bec012-6b7f-4a4e-92f3-22f85c982eff"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["###Loading data\nLoading the old dataset"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"41984ec4-77e2-4e4c-859e-25a122196db7"}}},{"cell_type":"code","source":["def read_CSV_to_DF(filepath):\n  \"\"\"\n  Reads a csv file into a spark dataframe\n  and returns Pandas dataframe\n  \"\"\"\n  df = (\n        sqlContext\n        .read.format(\"csv\")\n        .option(\"header\", \"true\")\n    \n        .load(filepath)\n          )\n  \n  return df.toPandas()\n \n\n# importing files from DBFS\ndf = read_CSV_to_DF('/FileStore/FinalProject/old_and_new_data-1.csv')\n \n# cast the some columns to int\ndf['file_id'] = df['file_id'].astype(int)\ndf['section_id'] = df['section_id'].astype(int)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dacef63c-d013-42df-b093-530f44dd9858"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##Feature Engineering\n###Extracting statistical features using TF-IDF"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f59d092f-bcec-453e-9a6a-7a9e64155515"}}},{"cell_type":"code","source":["heading_plus_content_corpus = df['abstracted_heading_plus_content']\n\ntfidf = TfidfVectorizer(ngram_range=(1,1), analyzer='word', stop_words='english')\ntfidfX = tfidf.fit_transform(heading_plus_content_corpus)\nfeatures_tfidf = pd.DataFrame(tfidfX.todense())\nfeatures_tfidf.columns = tfidf.get_feature_names()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"313622ed-e286-4213-9fb0-4533197e5cb2"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["###Extracting heuristic features using Heuristic_Feature class"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5abfd8b7-1c78-467d-9a7e-1b9f37d5b1d6"}}},{"cell_type":"code","source":["content_corpus = df['content_text_w_o_tags']\nheading_text_corpus = df['heading_text']\nurl_corpus = df['url']\nheuristic = Heuristic_Feature()\nderived_features = heuristic.derive_features_using_heuristics(url_corpus, heading_text_corpus, content_corpus)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9f33022b-1404-42f2-b0d2-8cb5bbd45c8a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["###Combining features together"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a717579e-bcac-433a-a3ae-0aa402baf6bc"}}},{"cell_type":"code","source":["features_combined = pd.concat([features_tfidf, derived_features], axis=1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ebeb6615-9f6b-4c4e-80da-f6bf95101731"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["###Encode the target vector"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cf370765-3e51-47de-9453-acd2bbf779e8"}}},{"cell_type":"code","source":["# Transform the target vector y\nlabel_set = ['-','1','3','4','5','6','7','8']             # Class '2' has been merged into class '1'\nlabels = [str(x).split(',') for x in df['section_code']]\n\nmlb = MultiLabelBinarizer(classes=label_set)\nlabels_matrix = mlb.fit_transform(labels)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"85882afc-675f-481e-82a2-8fdf29b20ac7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/databricks/python/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:860: UserWarning: unknown class(es) ['                [\"\"[a-f @abstr_number - @abstr_number ]+\"\"', '         \"\"mail\"\" : \"\"sabre+ @abstr_number @tut.by\"\"         \"\"role\"\" : \"\"Store Owner\"\"       }        -- response --       Set-Cookie:  SESSe @abstr_number a @abstr_number a @abstr_number c @abstr_number a @abstr_number c @abstr_number b @abstr_number cb @abstr_number f @abstr_number =E @abstr_number juSPMd @abstr_number fUOg @abstr_number j_esS @abstr_number G @abstr_number MwU @abstr_number jodrDpBjl @abstr_number KHfli @abstr_number ; expires=Sat', \"         forro = require('forro')\", '         location: \"\"YOUR_LOCATION\"\"', '     \"\"express\"\": \"\"^ @abstr_number . @abstr_number . @abstr_number \"\"', '     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND', '     to deal in the Software without restriction', '   * @abstr_hyperlink ', '   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND', '   * an @abstr_hyperlink -based completion engine for C#', ' \"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number : @abstr_number ', ' \"\"alternate names\"\"', ' \"\"group\"\": \"\"g @abstr_number \"\"}     /skydns/local/domain/subdom/     /skydns/local/domain/subdom/c - {\"\"host\"\": \"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number \"\"', ' \"\"hello there\"\". The dialog will take the incoming message and find the Best Match in the list of strings', ' \"\"key @abstr_number \"\": { \"\"dataA\"\": \"\"valueA\"\"', ' \"\"nameservers\"\": [\"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number : @abstr_number \"\"', ' \"\"trouble\"\"', ' \"\"website\"\": \"\"\"\"', ' \"\"��ɫ����\"\"', \" 'utf- @abstr_number '\", ' --debug DEBUG           Enable debug mode   The application also takes the regular parameters for APIC address', ' --input INPUT           Input file       -d DEBUG', ' --login LOGIN           APIC login ID.       -p PASSWORD', ' --outfile FILE       Filename and base module name of the generated parser        -t', ' --password PASSWORD  APIC login password.       -i INPUT', ' --url URL                 APIC IP address.       -l LOGIN', ' .offsetParent()', ' 2', ' 3', ' 4', ' @abstr_code_section    * See below for other simulation configuration options that you can set from the command line or from a configuration file    * Once your simulation has completed', ' @abstr_number ', \" @abstr_number )) @abstr_code_section evtList = [ { date: new Date(' @abstr_number '\", ' @abstr_number ); function.Invoke(destination); int result = function.GetInt(\"\"e_result\"\"); @abstr_code_section C# using (SapRfcConnection conn = new PlainSapRfcConnection(\"\"TST\"\")) { var result = conn.ExecuteFunction(\"\"Z_SSRT_SUM\"\"', ' @abstr_number milliseconds). For complex problems', ' @abstr_number }. For this to work we create the hosts named x{ @abstr_number ', ' @abstr_number }.db.skydns.local in etcd:       curl -XPUT http:// @abstr_number . @abstr_number . @abstr_number . @abstr_number : @abstr_number /v @abstr_number /keys/skydns/local/skydns/db/x @abstr_number  -d \\\\         value=\\'{\"\"host\"\":\"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number \"\"}\\'     curl -XPUT http:// @abstr_number . @abstr_number . @abstr_number . @abstr_number : @abstr_number /v @abstr_number /keys/skydns/local/skydns/db/x @abstr_number  -d \\\\         value=\\'{\"\"host\"\": \"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number \"\"\\'}     curl -XPUT http:// @abstr_number . @abstr_number . @abstr_number . @abstr_number : @abstr_number /v @abstr_number /keys/skydns/local/skydns/db/x @abstr_number  -d \\\\         value=\\'{\"\"host\"\": \"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number \"\"\\'}   Now the name db.skydns.local is the \"\"load balanced\"\" name for the database', ' BUT NOT LIMITED TO', ' Debian @abstr_number and CentOS @abstr_number / @abstr_number     \"', ' EXPRESS OR IMPLIED', ' Enrico', ' Estates', ' I take this methodology to the world of node.js. This time', ' Inc. @abstr_number Montague ST STE @abstr_number BROOKLYN', ' MB) bar.SetUnits(pb.U_BYTES)  // and start bar.Start() @abstr_code_section go // create and start bar bar := pb.New(myDataLen).SetUnits(pb.U_BYTES) bar.Start()  // my io.Reader r := myReader  // my io.Writer w := myWriter  // create proxy reader reader := bar.NewProxyReader(r)  // and copy from pb reader io.Copy(w', ' Main Estate   The UDP channel is a “Road\"\"   * The members of a Road are “Estates” (as in real estate lots that front the road)   * Each Estate has a unique UDP Host Port address “ha” ', ' NSErrorFailingURLKey=https://api.leancloud.cn/ @abstr_number . @abstr_number /batch/save', ' TLS is also problematic as a security system both from performance and vulnerabilty aspects.  Elliptic Curve Cryptography', ' Version @abstr_number . @abstr_number (the \"\"License\"\");     > SystemBarTint    * Link: @abstr_hyperlink    * License: Licensed under the Apache License', ' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND', ' XML and etc. responses. Useful for RESTful APIs.   * @abstr_hyperlink - Stackable middleware (using net/context) with easy chaining.   * @abstr_hyperlink - Minimalist net/http middleware for golang.   * @abstr_hyperlink - Lightweight middleware for net/http.   * @abstr_hyperlink - Idiomatic HTTP middleware for Golang.   * @abstr_hyperlink - Go package for easily rendering JSON', ' [Failure]] (or response: #6# [NO', \" \\\\ 'notes' : @abstr_number \", ' a light-weight', ' a micro-threaded multi-process application has instead one micro-thread per logical concurrent function and the total number of micro-threads is distributed amoungst a minimal number of processes', ' a simple Sequencer might deal with navigation:    * Sequencer     * Walk Forward     * Is there a Door?     * Open Door    This will always walk forward. If it meets a door', ' a simple micro-threaded application is limited to one CPU core. To enable full utilization of all CPU cores', ' add a new Debug Configuration', ' add some ads', \" add the sass task gulp.task('serve:before'\", ' adding persistence', ' an oven and a microwave (hot plates are not electric but gas powered).   8. Sub_metering_ @abstr_number : energy sub-metering No. @abstr_number (in watt-hour of active energy). It corresponds to the laundry room', ' and \"\"camembert\"\".  F\"', \" and a direct refutation to that 'hmph! you don't know maths\", ' and a gesture is detected that should start a drag', ' and by adding the necessary method implementations to all classes which implement that interface.  Static methods on interfaces are backported by moving the static methods to a companion class (interface name + \"\"$\"\")', ' and cpu capacity become critical', ' and dangerous', ' and distribution of messages between publishers and subscribers via queues.    One of the advantages of a message queuing service for many applications is that the service hides behind an API', ' and do       adb [-e|-d|-s device] pull /sdcard/dslv_state.txt   then simply run       python dslv.py   An image should appear that represents the DSLV in the final recorded state. Right and left keys allow stepping through the recorded drag-sort frame-by-frame; up/down keys jump @abstr_number frames. This tool has been very useful for debugging jumpy behavior while drag-scrolling.  \"', \" and enter the URI of this repository. That's the only text box to fill in on that page. On the following pages\", ' and friendships requested to the current user (we’ll call these “inverse” friendships).  \"', ' and hunger. Each has a brain consisting of @abstr_number unique nodes. There are more than fifteen thousand nodes governing the behaviour of the swarm', ' and in its absence this is an \"\"acyclic\"\" graph); this prevents infinite loops.  To use the tree', ' and interprocess communications while providing much higher total performance.  Because all the cooperative micro-threads run in one process', \" and it should take one argument (it doesn't actually matter what the argument is called\", ' and it will look for the data                                   in the file passed in the property \"\"csvReportFile\"\". If you use this property', ' and parsing all the source code of all drivers is long and unpractical.   * Some implicitly declared macros (like __KERNEL__) are needed for the code to be parsed correctly. Without them lots of functions and data structures will appear as undeclared.   * A lot of the code (power management', \" and probably also needs to have some of it removed (or migrated to 'magic.verbose' or something)\", \" and start dumping checkpoints into the folder specified by checkpoint_path (default = current folder). You also have to point the train script to the VGGNet protos (see the options inside train.lua).  If you'd like to evaluate BLEU/METEOR/CIDEr scores during training in addition to validation cross entropy loss\", ' and the associated demands on memory', ' and the language automatically does the needed cloning. For ref types', ' and then run:  @abstr_code_section  And then open a browser to http://localhost: @abstr_number \"', ' and this is the actual SpriteKit class. If all you want is some sample code for SpriteKit', ' and understand AUV', ' and where they’re located? With this expanded and thoroughly revised edition', ' and writing it feels like writing HTML. A simple transform is included with React that allows converting JSX into native JavaScript for browsers to digest.  \"', ' application-driven jailer built in the spirit of fail @abstr_number ban   * @abstr_hyperlink - Go Bindings for @abstr_hyperlink ', ' are often based on a messaging or event bus that allows the various distributed components to communicate asynchronously with each other. Typically the messaging bus is some form of messaging queue service such as AMQP or ZeroMQ. The message bus supports what is commonly referred to as a publish/subscribe methodology for information exchange.  While there are many advantages to a full featured message queuing service', ' as well as parses any existing _credentials.py_ file stored in the same directory. In that case', ' because most MQ services are based on TCP/IP they tend to also use HTTP and therefore TLS/SSL for secure communications. While using HTTP provides easy integration with web based systems', ' because part of implementing OAuth requires the user to take action on the provider (Foursquare', ' both methods can be combined.  \"', ' bubble on the destination with the address and an image  @abstr_image  Turn-by-turn instructions shown in bubbles (with instructions in the default language of the phone):  @abstr_image  The same turn-by-turn instructions shown in list view:  @abstr_image  Searching for fuel stations along the route:  @abstr_image  Searching fo cinemas inside an area', ' but WITHOUT ANY WARRANTY; including but not limited to', ' but can also charge the battery via regenerative braking (negative current) during deceleration. The total energy to be computed is the NET POSITIVE energy drawn from the battery.  \"', ' but instead will query @abstr_number . @abstr_number . @abstr_number . @abstr_number on port @abstr_number and if that fails will query @abstr_number . @abstr_number . @abstr_number . @abstr_number (on @abstr_number ) to get an answer. That answer will then be given back to the original client.  When forwarding to a stub', ' but it must also have been explicitly published using the \"\"Share\"\" button in the top right corner of the Google Spreadsheets GUI.  Generally', ' but the important thing is that the line before the line to be modified reads lib:):  @abstr_code_section  You will have to modify this to look like this:  @abstr_code_section  Normally', ' but there may be cases where you\\'d like to change this. Simply set the \"\"amd\"\" option:  @abstr_code_section  Or', ' but unfortunately the formatting of these errors don\\'t make looking for it any easier. We hope to improve that in other ways (see @abstr_hyperlink )  \"', ' but want to store values that are specific for a single host. For example the public IP-address of the host or the IP-address on the tenant network.  To do that you need to specify a unique value for that host with -local. A good unique value for that would be an UUID which you can generate with uuidgen for instance.  That unique value is used as a path in etcd to store the values separately from the normal values. It is still stored in the etcd backend so a restart of SkyDNS with the same unique value will give it access to the old data.  In the example here', ' but with SystemJS module definitions. @abstr_number . Browser evaluates ES @abstr_number code generated by previous step. \"', ' but you can also directly access the raw data.  Now go ahead and @abstr_hyperlink ', ' buying or clicking all of them. Here are a few examples of what preference sets could look like:  @abstr_code_section  From these preference sets we compute a two-dimensional array', ' c_height);     template->code = codeNumber;     template->size = codeSize;     CRCodeImageTemplateStorageAddNewTemplate(codeImageTemplateStorage', ' check out @abstr_hyperlink .  \"', ' commas delimit coordinates; semicolons delimit positions| |a_m_kon |double | @abstr_number |s^(- @abstr_number ) |active motor on rate| |a_m_koff |double | @abstr_number |s^(- @abstr_number ) |active motor off rate| |a_m_kend |double | @abstr_number |s^(- @abstr_number ) |active motor off rate at filament end| |a_motor_stiffness |double | @abstr_number |pN/um |active motor spring stiffness| |a_motor_length |double | @abstr_number . @abstr_number |um |length of motor| |a_m_stall |double | @abstr_number |pN |stall force of motors| |a_m_break |double | @abstr_number |pN |rupture force of motors| |a_m_bind |double | @abstr_number . @abstr_number |pN_um |binding energy| |a_motor_v |double | @abstr_number |um/s |velocity along filaments towards barbed end when attached| |motor_intersect_flag |boolean|false | |if true', ' configure', ' context switching', ' create a directory ext_lib within your project and populate it with symlinks to your libraries. Then set up the .tern-project something like this:  @abstr_code_section  Then', ' directing it to said directory. Then the app will be launchable from the app screen and the extensions screen.  To distribute the app', ' do \"\"Project -> Open/Import Project...\"\" and select the root Makefile of your Linux kernel. When prompted for the type of the project', ' drop me a line! \"', ' each slide will be defined by default with an element containing the slide class: @abstr_code_section You can see a fully working example of the HTML structure in the [demoPage.html` file](https://github.com/alvarotrigo/fullPage.js/blob/master/examples/demoPage.html).  \"', ' either manually add -lprofile to the linker command line', ' encryption and the CurveCP handshake for secure bootstrap.  The queue management and micro-threaded application support is provided by Ioflo. RAET is a complementary project to Ioflo in that RAET enables multiple Ioflo applications to work together over a network as part of a distributed application.  The primary use case and motivating problem that resulted in the development of RAET was the need to enable SaltStack to scale better. SaltStack is a remote execution and configuration management platform written in Python. SaltStack uses ZeroMQ ( @abstr_number MQ) as its message bus or message queuing service. ZeroMQ is based on TCP/IP so suffers from the aforementioned latency and non-asynchronicity issues of TCP/IP based architectures. Moreover because ZeroMQ integrates queue management and transport in a monolithic way with special \"\"sockets\"\"', ' etc. More information and instructions for subscribing are at @abstr_hyperlink .  \"', ' etc. etc.  \"', ' evtList){}  Callback function called when user click in a day', ' execute custom python script', ' first columns and then rows are binded to a single tidy dataset.  With the help of dlpyr package data are grouped by subject and activity and then averaged. The result is saved in the working directory as summary.txt  \"', ' first ensure you have @abstr_hyperlink and then run the following command:       pear install PHP_CodeSniffer   If you prefer using @abstr_hyperlink you can easily install PHP_CodeSniffer system-wide with the following command:       composer global require \"\"squizlabs/php_codesniffer=\"\"   Make sure you have ~/.composer/vendor/bin/ in your PATH.  Or alternatively', ' for easiest transition from a \"\"Vanilla\"\" server to one enhanced by StarryPy', ' function(err', ' graphical tool for dealing with streams of data.   * @abstr_hyperlink - Vectormath for Go', ' hereby commit to the neveragain.tech pledge. Please stand with me and hold me to it. #neveragaintech\"\" * Post \"\"I', ' high performance messaging system for microservices', \" how do the things in parentheses _become_ true or false?  JavaScript lets us compare things. Most of these comparisons come straight from math: we can ask if something is less than something else (enter these in your console!):  @abstr_code_section  We can ask if something is greater than something else:  @abstr_code_section  We can even ask if something is less-than-or-equal-to something else:  @abstr_code_section  or greater-than-or-equal-to something:  @abstr_code_section  How do we test if something is _exactly_ equal to something else? We know that we can't just use =\", ' iOS and Windows). The intelxdk.config.additions.xml file can be used to include options that control your _packaged Cordova web app_ builds. For example', ' if a \"\"must-have\"\" touch pattern arises', ' if we pass utter nonsense to parseInt()? Go ahead and try it in the console — something like  @abstr_code_section  What did it return? NaN? What is that?  NaN stands for \"\"not a number\"\" — pretty handy', ' ignored if embedCSS is false   * startOpen: false do not immediately truncate', ' import the cleanup', ' including without limitation the rights to use', ' including without limitation the rights_ _to use', ' indicating that the authorization process was successful.  \"', ' infact due to a logic error in previous code the cookies were not being used anyway. Now Django Select @abstr_number does not use cookies etc.   * Few more bugs fixed in heav_data.js.   * Now production code will use minimized versions of js and css files.   * Codes added in setup.py to automate the task of minimizing js and css files', ' injection and in class annotations', ' is a tuned transport protocol that adds reliability to UDP/IP without sacrificing latency and scalability. A transactioned protocol', ' is much more appropriate for providing reliablity to asynchronous event transport than a streaming protocol.  Morover', ' it can become problematic for high performant systems Furthermore', ' it ends up owned by root (but in your home directory).  Check that you own your own .npm directory ls -ld ~/.npm  If it is owned by root', ' it evaluates the left-hand side of the colon; otherwise it evaluates the right-hand side of the colon.  Syntax:  @abstr_code_section    * Define a function ternaryTeenager that accepts age as a parameter. The body of the function should use the ternary operator to return \"\"You are a teenager\"\" if age is between @abstr_number - @abstr_number and returns \"\"You are not a teenager\"\" if the age is anything else.    Top tip : In order for the function to actually return the evaluation of the ternary operator', ' it is much better suited to many small asynchronous messages and scales better. The drawback of bare UDP/IP is that it is not reliable. What is needed', ' it is the exception. No other TCP/IP stack available for the Amiga robustly supports a similar feature. If the TCP/IP stack supports this feature', ' it means you are not using the @abstr_number . @abstr_number jre. Type java -version to check. You may need to close and reopen your terminal if you installed @abstr_number . @abstr_number recently.  \"', ' it now has all the functions.  Implementation inheritance is used instead of subtyping to make it easier to understand which functions operate on any given \"\"subject\"\". If you have an element and you need to use a function defined in Node', ' it should return \"\"You are a grownup\"\" Top tip : Remember', ' it will upgrade. - Likewise', \" it's actually ABCBAD\", ' it\\'s an important skill to have!  \"', \" it's in gcc:lib/gcc/ppc-amigaos/*compiler-version*/specs. Most likely\", \" jumps to the symbol's declaration. For C/C++/Objective-C\", ' just call .readmore() on the element containing your block of text and Readmore.js takes care of the rest. Readmore.js plays well in a responsive environment', ' just go to your project folder and run:          github_changelog_generator     * Or', ' just take forever (actually until a timeout is reached). You need to keep this in mind in order to not block your main or UI thread.  Implications of this design choice  Pros:    * A blocking API is much easier to use and understand    Cons:    * You just might accidentally block your UI thread   * You cannot issue thousands of EWS requests asynchronously simply because you cannot spawn thousands of threads in your process. You may need additional effort here    \"', ' keys and NSEC @abstr_number records returned. Authenticated denial of existence is implemented using NSEC @abstr_number white lies', ' libqs.c and the yara signatures except where noted are Copyright @abstr_number Tyler McLellan and Tylabs.  See included Mozilla Public License Version @abstr_number . @abstr_number for licensing information. \"', ' like AMQP', ' make sure that the instances are being launched with a security group that allows SSH access.  \"', ' memory', ' network', ' network) in distributed concurrent event driven applications is to use something called micro-threads. A microthread is typically an in-language feature that allows logical concurrency with no more overhead than a function call. Micro threading uses cooperative multi-tasking instead of threads and/or processes and avoids many of the complexities of resource contention', ' no matter the direction. Because we don’t care who requested the friendship once it’s approved', ' no more than the number of cpu cores. This optimizes the use of the cpu power while minimizes the overhead of process context switching.  An example of a framework that uses this type of micro-threaded but multi-process architecture is Erlang. Indeed', ' notebook', ' nothing is sent to Gmail and all messages currently stored on your device are simply marked \"\"backed up\"\". This option is handy if you previously uninstalled SMS Backup+ and do not want to send your messages again to Gmail. Please note that any messages arrived after you last uninstalled SMS Backup and this initial backup won\\'t ever be backed up to Gmail.  \"', ' of course', ' on average across all \"', ' on the other hand', ' one for front side only', ' one might ask', ' one of the best ways to manage and fine tune processor resources (cpu', ' one of the disadvantagesis the inability to manage performance at scale.  A message queuing service performs two distinct but complementary functions.    * The first is asynchronous transport of messages over the internet.   * The second is message queue management', ' or because they are tech geeks. But these data remain under-utilized both because the raw data are hard to obtain and there is a lack of statistical methods and software for processing and interpreting the data.  This assignment makes use of data from a personal activity monitoring device. This device collects data at @abstr_number minute intervals through out the day. The data consists of two months of data from an anonymous individual collected during the months of October and November', ' or both   * Added \"\"returnName\"\" setting which makes the widget return a name instead of HEX value when possible   * Removed many unnecessary features   * Removed dependency on images and made the colour picker completely CSS     \"', ' or if you are usually handling many temporary \"\"to be in a github pull request\"\" branches', ' or modify the specs file as follows. Find the lines that look like this (it may actually differ slightly from your specs file', ' otherwise SERVFAIL is returned.  This also works for IPv @abstr_number addresses', ' post an issue in @abstr_hyperlink .  If you think there is an issue with osmdroid', ' preface it by @abstr_number . These numbers correspond to the projections in the projectionEnum declaration in elevr-player.js.  If you want to add your picture to the drop-down', ' production)', ' provides increases in security with lower performance requirements relative to over other approaches. LibSodium provides an open source Elliptic Curve Cryptographic library with support for both authentication and encryption. The CurveCP protocol is based on LibSodium and provides a handshake protocol for bootstrapping secure network exchanges of information.  Finally', ' push your changes to your clone and submit a pull request; instructions are available at @abstr_hyperlink . (In case you need them', ' ready-to-use download of the library/framework (unminified) ( @abstr_number )   * Prefer hand-coded/hand-optimized JavaScript over generated/cross-compiled code.   * Running \"\"make\"\" should work and not return an error. To run make', ' requests', ' result will be @abstr_number : @abstr_number', \" rg -uuu is similar to grep -a -r.  @abstr_code_section  (Tip: If your ignore files aren't being adhered to like you expect\", ' rgb()', ' right?  What happens', \" ripgrep defaults to recursive directory search and won't search files ignored by your .gitignore files. It also ignores hidden and binary files by default. ripgrep also implements full support for .gitignore\", ' route display', ' ruby', \" run the test suite by typing learn and hitting enter. You'll see something similar to:  @abstr_image  You can see your test is currently failing\", ' run this from anywhere:      * github_changelog_generator -u github_username -p github_project     * github_changelog_generator github_username/github_project   * If you are running it against a repository on a Github Enterprise install', ' send an email to  with subject line \"\"[web-animations] ... message topic ...\"\" ( @abstr_hyperlink ).   * For issues with the polyfill', ' simply: \"\"./build.sh test\"\"  To run all the tests  > $ ./build.sh install -DallTests  \"', \" so a typical call to parseInt() looks like  @abstr_code_section  What happens if we pass a representation of a non-integer to parseInt()? Let's try it:  @abstr_code_section  If we enter the above in console\", ' so the final path becomes /v @abstr_number /keys/skydns/local/skydns/east/production/rails   * Host - The name of your service', ' so we leave it out.   * The xact() decorator will set up the connection so that a transaction _is_ started in the relevant block', ' software distributed under the License is distributed on an \"\"AS IS\"\" BASIS', ' spreadsheet) {         spreadsheet.worksheets[ @abstr_number ].cells({             range: \"\"R @abstr_number C @abstr_number :R @abstr_number C @abstr_number \"\"         }', ' storage', \" substituting '' with the IP value copied in prev:       Set-Item WSMan:\\\\localhost\\\\Client\\\\TrustedHosts -Value <machine-name or IP Address>   @abstr_number . Type Y and press Enter to confirm the change.  @abstr_number . Now you can start a session with you Windows IoT Core device. From you administrator PS console\", ' such as \"\"m @abstr_number .medium\"\". The default value of this if not specified is \"\"m @abstr_number .medium\"\". \"\"m @abstr_number .small\"\" has been deprecated in \"\"us-east- @abstr_number \"\" and \"\"m @abstr_number .medium\"\" is the smallest instance type to support both paravirtualization and hvm AMIs   * keypair_name - The name of the keypair to use to bootstrap AMIs which support it.   * monitoring - Set to \"\"true\"\" to enable detailed monitoring.   * session_token - The session token provided by STS   * private_ip_address - The private IP address to assign to an instance within a @abstr_hyperlink   * elastic_ip - Can be set to \\'true\\'', ' tend to be unreliable under load.  Separating the function of network transport of asynchrounous event from the function of message queue management allows independant tuning at scale of each function.  Most if not all of the MQ services are based on TCP/IP for transport. TCP/IP adds significant latency to the network communications and is therefore not well suited for the asynchronous nature of distibuted event driven application communications. This is primarily due to the way TCP/IP handles connection setup and teardown as well as failed connections in order to support streams. Fundamentally TCP/IP is optomized for sending large contiguous data streams not many small aynchronous events or messages. While not a problem for small scale systems', ' thanks to @abstr_hyperlink ! Tap \"\"Hint\"\" to show hint (e.g. Move left/right/up/down); tap \"\"Auto Run\"\" to run AI automatically. Check it out in the AI branch. You can also check out @abstr_hyperlink .  Thanks to @abstr_hyperlink \\'s Javascript version that gave me (DJBen', ' that is', ' the \"\"more info\"\" button will open the full Wikipedia page:  @abstr_image  Showing geolocalized Flickr photos related to the current map view:  @abstr_image  Showing geolocalized Picasa photos related to the current map view:  on the map | as a list view ------------- | ------------- @abstr_image | @abstr_image  When searching a place by name', ' the \"\"pattern matching swiss knife for malware researchers (and everyone else)\"\"   * @abstr_hyperlink - Pure Go ACME client library and CLI tool (for use with Let\\'s Encrypt)   * @abstr_hyperlink - Futureproof password hashing library.   * @abstr_hyperlink - an scrypt package with a simple', \" the Erlang ecosystem is somewhat limited in comparison to Python's and the language itself uses what one might describe as a very unfortunate syntax. One of the design objectives behine RAET was to leverage existing Python expertise and the richness of the Python ecosystem but still be able to develop distributed applications using a micro-threaded multi-process architectural model. The goal was to combine the best of both worlds.  RAET is designed to provide secure reliable scalable asynchronous message/event transport over the internet in a micro-threaded multi-process application framework that uses UDP for interhost communication and LibSodium for authentication\", ' the application needs to be able to run at least one process per CPU core. This requires same host inter-process communications. But unlike the conventional approach to multi-processing where there is of one process per logical concurrent function', \" the autoScrolling functionality will still work as expected. The user will also be free to scroll the site with the scroll bar and fullPage.js will fit the section in the screen when scrolling finishes.    * paddingTop: (default @abstr_number) Defines the top padding for each section with a numerical value and its measure (paddingTop: ' @abstr_number px'\", ' the bootstrap.json file will create a     newsblur user with no password.   @abstr_number . Start mongodb (if not already running):           mongod run   @abstr_number . Run the development server. At this point', ' the client has little ability to tune the service for performance. Often MQ services become bottlenecks for the distributed application. The more complicated MQ services', ' the completion \"\"getUserAccount\"\" would be ranked higher in the list than the \"\"Fooguxa\"\" completion (both of which are subsequence matches). A word-boundary character are all capital characters', ' the complexities of queue management from the clients. The disadvantage is that at scale', ' the content of the _credentials.py_ file must follow this format:       URL=\"\"https:// @abstr_number . @abstr_number . @abstr_number . @abstr_number \"\"     LOGIN=\"\"admin\"\"     PASSWORD=\"\"Ap @abstr_number cPass @abstr_number \"\"   If the _credentials.py_ does not exist and the credentials are not supplied from the command line', ' the diagnostic messages will be sent to stderr.  If the program was launched from Workbench or if the global variable __no_standard_io is set to a non-zero value', ' the differences in the associated traffic characteristics can become problematic at scale.  Because UDP/IP has lower latency and is connectionless', ' the entire _phrase_) to be true; with ||', ' the expanding/collapsing animation is done with CSS @abstr_number transitions.  By default', ' the identification', ' the link should say \"\" @abstr_number commits\"\".  @abstr_number . You will see a list of commits that you have made to this repository. The most recent commit is at the very top. If this represents the version of the files you want to submit', \" the name of the item you wish to remove. If the item isn't in the cart\", ' the other CNANE is returned from the remote name server.  \"', ' the predefined targets are \"\"BookShelf\"\"', ' the program must be linked against libprofile.a. To do this', \" the rate limit is only up to @abstr_number requests per hour. Unauthenticated requests are associated with your IP address (not the user making requests).  If you're seeing this warning\", \" the specs file is located at the compiler's installation directory. For cross-compilers\", ' the success of the Erlang model provided support for the viability of the RAET approach. Indeed', ' the time when the signal was received', ' the timing of messages', ' then installing the new version. Make sure to select \"\"Skip\"\" when doing the first backup', ' then start the dev server as usual with npm start:   \"', ' then the uppercase letters in your query must match uppercase letters in the completion strings (the lowercase letters still match both). So', \" then your     cmake call will be a bit more complicated.  We'll assume you downloaded a     binary distribution of LLVM+Clang from llvm.org in step  @abstr_number  and that you     extracted the archive file to folder ~/ycm_temp/llvm_root_dir (with bin\", ' there is an option of using a specific proxy to extract video information from the site: --extractor-proxy/-y.    \"', ' there is at least a single .entry element within the .feed container. Remember', ' there will be some results', ' there\\'s nothing you need to do! Ionic @abstr_number projects by default are setup with sass and come with all the build process enabled.  \"', ' therefore', ' this is /usr/local/amiga/lib/gcc/ppc-amigaos/*compiler-version*/specs. For a native compiler', ' this is a little more expensive', ' this mode is based on this function', ' though', ' thus resulting in changing the package provider on Mac OS X', ' tracking', ' true) Enable sorting of dragged item (disabling is useful when you only want item removal).   * drag_start_mode: (enum', ' two steps are required. First of all', ' two-way data binding', ' type in \"\"ping hostname_A\"\"', ' use make firefox and to build Safari use make safari.  The extensions will be in the browser-ext/login/build directory.  \"', ' username and password', ' users will be considered \"\"logged in\"\" if they have an access token stored in their session. So', ' utilizing PWM pins  Layer @abstr_number NUMPAD keys: This is useful for gaming because games can bind separate commands to numpad_ @abstr_number and regular @abstr_number ', \" we don't use an UUID\", ' we guarantee that it will not immediately return if it fails. By adding the Success node', ' we intercept all <a href=\"\"/path\"\">...</a> clicks and call msg.setLocation(\"\"/path\"\") for you. If you want to opt out of this', ' we know that our function should look like  @abstr_code_section  But how do we make string all caps? JavaScript has a method for that! It\\'s called toUpperCase(). We can call it on any string:  @abstr_code_section  So let\\'s try it with our shout() function:  @abstr_code_section  And run our tests again:  @abstr_code_section  @abstr_image  Hey! We got one to pass!  \"', ' we need to go over some basic math. In this lab', ' we should have: IP for computer A and B (denoted as IP_A and IP_B later on in the instruction)', ' we use public.addresses:       % skydns -local public.addresses.skydns.local &      % curl -XPUT http:// @abstr_number . @abstr_number . @abstr_number . @abstr_number : @abstr_number /v @abstr_number /keys/skydns/local/skydns/local/addresses/public \\\\         -d value=\\'{\"\"host\"\":\"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number \"\"}\\'      % dig @ @abstr_number . @abstr_number . @abstr_number . @abstr_number  local.dns.skydns.local. A      ;; ANSWER SECTION:     local.dns.skydns.local.  @abstr_number  IN  A    @abstr_number . @abstr_number . @abstr_number . @abstr_number   The name local.dns.skydns.local. is fixed', \" we'll see that parseInt() forces the parsed number to be an integer — which makes sense when we think about it\", \" we're going to learn about various arithmetic operators. What's an operator\", \" we're going to practice writing functions and manipulating numbers in JavaScript. First\", ' whenever you try to make a Git commit', ' where the volume of messages', ' wherein components are distributed across the internet on multiple hosts and multiple CPU cores', ' which accepts two arguments: the value to parse and the base of the value being parsed. _Usually_ you will want to work with base @abstr_number ', \" which takes our new-found speaking ability to greet our grandmother. She's not exactly deaf\", ' which was created using simulated data :  @abstr_image  Your plot will look different from the one above because you will be using the activity monitor data. Note that the above plot was made using the lattice system but you can make the same version of the plot using any plotting system you choose.  \"', ' which will automatically be created the first time you\\'re performing a backup.  \"', ' which will be resolved.  Also see the section Host Local Values.      \"', ' why not use Erlang? Unfortunately', ' will be removed in a later version)    \"', ' window', ' with clustered markers:  @abstr_image  Showing Wikipedia POIs related to the current map view. In the bubble', ' you can choose to only include a subset of IntentKit\\'s supported applications. Subspecs exist for each handler class.       # Only includes web browsers     pod \"\"IntentKit/Browsers\"\"   For more information on what subspecs are available', ' you can install PHP_CodeSniffer using the PEAR installer. This will make the phpcs and phpcbf commands immediately available for use. To install PHP_CodeSniffer using the PEAR installer', ' you can specify to set the crontab user with:  @abstr_code_section  \"', ' you may find it convenient to run watch-css automatically with npm start', ' you must call DragSortListView.moveCheckState(int from', ' you must call DragSortListView.removeCheckState(int position) within remove(which). See the documentation in the DSLV API for more info.  \"', ' you must specify _both_ --github-site and --github-api command line options:          github_changelog_generator --github-site=\"\"https://github.yoursite.com\"\" \\\\                                --github-api=\"\"https://github.yoursite.com/api/v @abstr_number /\"\"      This generates a changelog to the CHANGELOG.md file', ' you say? It\\'s a symbol that _operates_ on one or more (usually two) objects — + is a good example. The + operator says \"\"add what\\'s to the left of + and what\\'s to the right of + together.\"\" Easy-peasy!  As you read through this lesson', ' you should always use the --rebase flag to git pull', ' you won\\'t get automatic updates this way).  \"', ' your compiler will already have this added to it\\'s specs file.  Profiling makes use of a special PowerPC facility called the _Performance Monitor_. It allows to \"\"mark\"\" tasks and count only during while a marked task is running. This allows performance analysis to be made independent of the actual system load. The _Performance Monitor_ is available on all PowerPC models supported by AmigaOS @abstr_number except for the * @abstr_number e*', ' your program must be compiled with the _GCC_ command line option -pg. This instructs the compiler to generate special profiling code in the prologue and epilogue of each function. Additionally', \" { \\\\ 'build' : { \\\\ 'mac' : './install.py'\", ' ~/.bash_profile or ~/.zshrc):           export CHANGELOG_GITHUB_TOKEN=\"\"«your- @abstr_number -digit-github-token»\"\"   So', '\"\"port\"\": @abstr_number }\\'     curl -XPUT http:// @abstr_number . @abstr_number . @abstr_number . @abstr_number : @abstr_number /v @abstr_number /keys/skydns/local/skydns/east/staging/rails/ @abstr_number  \\\\         -d value=\\'{\"\"host\"\":\"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number \"\"', '\"\"port\"\": @abstr_number }\\'   And try it out:       ;; ANSWER SECTION:     bar.skydns.local.    @abstr_number     IN  SRV  @abstr_number   @abstr_number   @abstr_number  x @abstr_number .bar.skydns.local.     bar.skydns.local.    @abstr_number     IN  SRV  @abstr_number   @abstr_number   @abstr_number  bar.skydns.local.      ;; ADDITIONAL SECTION:     x @abstr_number .bar.skydns.local.  @abstr_number     IN  A    @abstr_number . @abstr_number . @abstr_number . @abstr_number   Which has x @abstr_number in the name', '\"\"port\"\": @abstr_number }\\'   We have created the following CNAME chain: @abstr_number .rails.production.east.skydns.local -> service @abstr_number .skydns.local -> @abstr_number . @abstr_number . @abstr_number . @abstr_number. If you then query for an A or AAAA for @abstr_number .rails.production.east.skydns.local SkyDNS returns:        @abstr_number .rails.production.east.skydns.local.  @abstr_number   IN  CNAME   service @abstr_number .skydns.local.     service @abstr_number .skydns.local.                  @abstr_number   IN  A        @abstr_number . @abstr_number . @abstr_number . @abstr_number   \"', '\"AI  An AI is added', '\"Audio/Music  _Libraries for manipulating audio._    * @abstr_hyperlink - A native Go FLAC decoder.   * @abstr_hyperlink - A native Go FLAC decoder.   * @abstr_hyperlink - libsox bindings for go.   * @abstr_hyperlink - libmediainfo bindings for go.   * @abstr_hyperlink - Sequence-based Go-native audio mixer for music apps.   * @abstr_hyperlink - A native Go MP# decoder.   * @abstr_hyperlink - Music theory models in Go.   * @abstr_hyperlink - Go bindings for the PortAudio audio I/O library.   * @abstr_hyperlink - Go bindings for PortMidi.   * @abstr_hyperlink - Go bindings for taglib.   * @abstr_hyperlink - A \"\"native\"\" Go Vorbis decoder (uses CGO', '\"Batching a bunch of messages using the block syntax    require \\'kafka\\'     producer = Kafka::Producer.new     producer.batch do |messages|         puts \"\"Batching a send of multiple messages..\"\"         messages << Kafka::Message.new(\"\"first message to send\"\")         messages << Kafka::Message.new(\"\"second message to send\"\")     end     * they will be sent all at once', '\"Checking Authentication  The first thing we want to do is figure out if a user has already authenticated to Foursquare in this session.  Ultimately', '\"Design Notes  ews-cpp is written in a \"\"modern C++\"\" way:    * C++ Standard Library', '\"Examples  Geocoding', '\"File handles - \"\"Too many files open\"\"  You may run into a \"\"too many files open\"\" error during compilation or reloading. You can find out how many file handles you are allowed per process by running ulimit -n. This can be quite low', '\"Host Local Values  SkyDNS supports storing values which are specific for that _instance_ of SkyDNS.  This can be useful when you have SkyDNS running on multiple hosts', '\"How Do I Create an Address Pool and Round Robin Between Them  You have @abstr_number machines with @abstr_number different IP addresses and you want to have @abstr_number name pointing to all @abstr_number possible addresses. The name we want to use is: db.skydns.local and the @abstr_number addresses are @abstr_number . @abstr_number . @abstr_number .{ @abstr_number ', '\"How can I make the app think that it has to do the backup again?  Select \"\"Reset\"\" from the menu', '\"Installation  Add this to your composer.json:  JSON { \"\"require\"\": { \"\"thekonz/piximgen\"\": \"\" @abstr_number . @abstr_number .*@dev\"\" } } @abstr_code_section PHP require_once \\'vendor/autoload.php\\'; @abstr_code_section PHP $image = new \\\\thekonz\\\\PixImGen(); @abstr_code_section PHP $image->setSettings([ \\'seed\\' => \\'GitHub rocks!\\' ]); @abstr_code_section PHP header(\\'content-type: image/png\\'); @abstr_code_section PHP echo $image->getImage();    * Look at your image!    @abstr_image  If you play around with the settings (especially the saturation settings)', '\"Installation  The easiest way to get started with PHP_CodeSniffer is to download the @abstr_hyperlink files for each of the commands:       curl -OL https://squizlabs.github.io/PHP_CodeSniffer/phpcs.phar     php phpcs.phar -h      curl -OL https://squizlabs.github.io/PHP_CodeSniffer/phpcbf.phar     php phpcbf.phar -h   If you use PEAR', '\"Installing  This plugin requires KDevelop @abstr_number . @abstr_number .  Just typing cmake . && make && sudo make install should be enough to have the project installed. Then in KDevelop', '\"Introduction  In this lab', '\"MX Records  If a service is added with \"\"mail\"\": true it is _also_ an MX record', '\"Motivation  Modern large scale distributed application architectures', '\"Next steps  Get your computer or device to use the VPN. Please refer to:  Configure IPsec/L @abstr_number TP VPN Clients Configure IPsec/XAuth (\"\"Cisco IPsec\"\") VPN Clients  How-To: IKEv @abstr_number VPN for Windows and Android  If you get an error when trying to connect', '\"Publish your book  The platform @abstr_hyperlink is like an \"\"Heroku for books\"\": you can create a book on it (public', '\"Rebasing  For feature/topic branches', '\"Restoring  If you wish to restore messages back to your phone tap \"\"Restore\"\". By default all messages stored on Gmail will be restored (this can be changed in \"\"Advanced Settings\"\"). You can safely restore to a phone which has already message stored on it', '\"Road', '\"Security  _Libraries that are used to help make your application more secure._    * @abstr_hyperlink — ACME (Let\\'s Encrypt) client tool with automatic renewal.   * @abstr_hyperlink - An in-memory', '\"Sending a sequence of messages    require \\'kafka\\'     producer = Kafka::Producer.new     message @abstr_number  = Kafka::Message.new(\"\"some random message content\"\")     message @abstr_number  = Kafka::Message.new(\"\"some more content\"\")     producer.send([message @abstr_number ', '\"Standard CLI  _Libraries for building standard or basic Command Line applications_    * @abstr_hyperlink - A feature-rich and easy to use command-line package based on golang tag   * @abstr_hyperlink - The easy way to start building Golang command line application.   * @abstr_hyperlink - An alternative CLI with \"\"human face\"\"', '\"Ternary Operator  You can think of it as a shortcut for the if-else statement.  This operator tests a condition; if the condition is truthy', '\"The config.json file  The config.json file currently only requires the key \"\"states_dir\"\" and the value \"\"states/\"\" to tell the test script where to find its states relative to the root of the git repo. The \"\"/\"\" at the end of states is important don\\'t forget it. In the example above', '\"Usage    $ python @abstr_number  aci-fabric-deploy.py --input <spreadhseet>      Optional arguments:       -u URL', '\"Usage  It\\'s really simple!    * If your git remote origin refers to your GitHub repo', '\"Using gmon (PowerPC only)  To use profiling', '\"Using unit tests  There are various unit tests included in this package to verify if certain modules are operating properly. Simply run the \"\"test\"\" prefixed python script associated with the module you would like to test.  For example to test the DrugDatabase module', '\"We love feedback!   For feedback on the API and the specification:      * File an issue on GitHub:     * Alternatively', '\"When updating the app I get \\'Package file was not signed correctly\\'  Try uninstalling the app', '\"Why do backed up SMS show up in my inbox?  This is probably related to Gmail\\'s automatic priority inbox filing. A workaround is to set up a filter with \"\"subject: SMS with\"\"', '\"href  As a bonus', '\"if-else Statements  You will often see an if statement used in combination with an else clause. An else clause will only get executed if the previous if statement is falsey.  Syntax:  @abstr_code_section    * Define a function teenager that accepts an age as a parameter. If the age is between @abstr_number and @abstr_number it should return \"\"You are a teenager!\"\". Otherwise', '\"parseInt()  The first such tool is the function parseInt()', '...) may not read any data at all. If your program needs functions such as these or atod() then you must link against libm.a or the equivalent.  To link the floating point support code with your software', '2', 'css', '记得core.js中把user改为自己的账户名'] will be ignored\n  warnings.warn('unknown class(es) {0} will be ignored'\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["/databricks/python/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:860: UserWarning: unknown class(es) ['                [\"\"[a-f @abstr_number - @abstr_number ]+\"\"', '         \"\"mail\"\" : \"\"sabre+ @abstr_number @tut.by\"\"         \"\"role\"\" : \"\"Store Owner\"\"       }        -- response --       Set-Cookie:  SESSe @abstr_number a @abstr_number a @abstr_number c @abstr_number a @abstr_number c @abstr_number b @abstr_number cb @abstr_number f @abstr_number =E @abstr_number juSPMd @abstr_number fUOg @abstr_number j_esS @abstr_number G @abstr_number MwU @abstr_number jodrDpBjl @abstr_number KHfli @abstr_number ; expires=Sat', \"         forro = require('forro')\", '         location: \"\"YOUR_LOCATION\"\"', '     \"\"express\"\": \"\"^ @abstr_number . @abstr_number . @abstr_number \"\"', '     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND', '     to deal in the Software without restriction', '   * @abstr_hyperlink ', '   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND', '   * an @abstr_hyperlink -based completion engine for C#', ' \"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number : @abstr_number ', ' \"\"alternate names\"\"', ' \"\"group\"\": \"\"g @abstr_number \"\"}     /skydns/local/domain/subdom/     /skydns/local/domain/subdom/c - {\"\"host\"\": \"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number \"\"', ' \"\"hello there\"\". The dialog will take the incoming message and find the Best Match in the list of strings', ' \"\"key @abstr_number \"\": { \"\"dataA\"\": \"\"valueA\"\"', ' \"\"nameservers\"\": [\"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number : @abstr_number \"\"', ' \"\"trouble\"\"', ' \"\"website\"\": \"\"\"\"', ' \"\"��ɫ����\"\"', \" 'utf- @abstr_number '\", ' --debug DEBUG           Enable debug mode   The application also takes the regular parameters for APIC address', ' --input INPUT           Input file       -d DEBUG', ' --login LOGIN           APIC login ID.       -p PASSWORD', ' --outfile FILE       Filename and base module name of the generated parser        -t', ' --password PASSWORD  APIC login password.       -i INPUT', ' --url URL                 APIC IP address.       -l LOGIN', ' .offsetParent()', ' 2', ' 3', ' 4', ' @abstr_code_section    * See below for other simulation configuration options that you can set from the command line or from a configuration file    * Once your simulation has completed', ' @abstr_number ', \" @abstr_number )) @abstr_code_section evtList = [ { date: new Date(' @abstr_number '\", ' @abstr_number ); function.Invoke(destination); int result = function.GetInt(\"\"e_result\"\"); @abstr_code_section C# using (SapRfcConnection conn = new PlainSapRfcConnection(\"\"TST\"\")) { var result = conn.ExecuteFunction(\"\"Z_SSRT_SUM\"\"', ' @abstr_number milliseconds). For complex problems', ' @abstr_number }. For this to work we create the hosts named x{ @abstr_number ', ' @abstr_number }.db.skydns.local in etcd:       curl -XPUT http:// @abstr_number . @abstr_number . @abstr_number . @abstr_number : @abstr_number /v @abstr_number /keys/skydns/local/skydns/db/x @abstr_number  -d \\\\         value=\\'{\"\"host\"\":\"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number \"\"}\\'     curl -XPUT http:// @abstr_number . @abstr_number . @abstr_number . @abstr_number : @abstr_number /v @abstr_number /keys/skydns/local/skydns/db/x @abstr_number  -d \\\\         value=\\'{\"\"host\"\": \"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number \"\"\\'}     curl -XPUT http:// @abstr_number . @abstr_number . @abstr_number . @abstr_number : @abstr_number /v @abstr_number /keys/skydns/local/skydns/db/x @abstr_number  -d \\\\         value=\\'{\"\"host\"\": \"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number \"\"\\'}   Now the name db.skydns.local is the \"\"load balanced\"\" name for the database', ' BUT NOT LIMITED TO', ' Debian @abstr_number and CentOS @abstr_number / @abstr_number     \"', ' EXPRESS OR IMPLIED', ' Enrico', ' Estates', ' I take this methodology to the world of node.js. This time', ' Inc. @abstr_number Montague ST STE @abstr_number BROOKLYN', ' MB) bar.SetUnits(pb.U_BYTES)  // and start bar.Start() @abstr_code_section go // create and start bar bar := pb.New(myDataLen).SetUnits(pb.U_BYTES) bar.Start()  // my io.Reader r := myReader  // my io.Writer w := myWriter  // create proxy reader reader := bar.NewProxyReader(r)  // and copy from pb reader io.Copy(w', ' Main Estate   The UDP channel is a “Road\"\"   * The members of a Road are “Estates” (as in real estate lots that front the road)   * Each Estate has a unique UDP Host Port address “ha” ', ' NSErrorFailingURLKey=https://api.leancloud.cn/ @abstr_number . @abstr_number /batch/save', ' TLS is also problematic as a security system both from performance and vulnerabilty aspects.  Elliptic Curve Cryptography', ' Version @abstr_number . @abstr_number (the \"\"License\"\");     > SystemBarTint    * Link: @abstr_hyperlink    * License: Licensed under the Apache License', ' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND', ' XML and etc. responses. Useful for RESTful APIs.   * @abstr_hyperlink - Stackable middleware (using net/context) with easy chaining.   * @abstr_hyperlink - Minimalist net/http middleware for golang.   * @abstr_hyperlink - Lightweight middleware for net/http.   * @abstr_hyperlink - Idiomatic HTTP middleware for Golang.   * @abstr_hyperlink - Go package for easily rendering JSON', ' [Failure]] (or response: #6# [NO', \" \\\\ 'notes' : @abstr_number \", ' a light-weight', ' a micro-threaded multi-process application has instead one micro-thread per logical concurrent function and the total number of micro-threads is distributed amoungst a minimal number of processes', ' a simple Sequencer might deal with navigation:    * Sequencer     * Walk Forward     * Is there a Door?     * Open Door    This will always walk forward. If it meets a door', ' a simple micro-threaded application is limited to one CPU core. To enable full utilization of all CPU cores', ' add a new Debug Configuration', ' add some ads', \" add the sass task gulp.task('serve:before'\", ' adding persistence', ' an oven and a microwave (hot plates are not electric but gas powered).   8. Sub_metering_ @abstr_number : energy sub-metering No. @abstr_number (in watt-hour of active energy). It corresponds to the laundry room', ' and \"\"camembert\"\".  F\"', \" and a direct refutation to that 'hmph! you don't know maths\", ' and a gesture is detected that should start a drag', ' and by adding the necessary method implementations to all classes which implement that interface.  Static methods on interfaces are backported by moving the static methods to a companion class (interface name + \"\"$\"\")', ' and cpu capacity become critical', ' and dangerous', ' and distribution of messages between publishers and subscribers via queues.    One of the advantages of a message queuing service for many applications is that the service hides behind an API', ' and do       adb [-e|-d|-s device] pull /sdcard/dslv_state.txt   then simply run       python dslv.py   An image should appear that represents the DSLV in the final recorded state. Right and left keys allow stepping through the recorded drag-sort frame-by-frame; up/down keys jump @abstr_number frames. This tool has been very useful for debugging jumpy behavior while drag-scrolling.  \"', \" and enter the URI of this repository. That's the only text box to fill in on that page. On the following pages\", ' and friendships requested to the current user (we’ll call these “inverse” friendships).  \"', ' and hunger. Each has a brain consisting of @abstr_number unique nodes. There are more than fifteen thousand nodes governing the behaviour of the swarm', ' and in its absence this is an \"\"acyclic\"\" graph); this prevents infinite loops.  To use the tree', ' and interprocess communications while providing much higher total performance.  Because all the cooperative micro-threads run in one process', \" and it should take one argument (it doesn't actually matter what the argument is called\", ' and it will look for the data                                   in the file passed in the property \"\"csvReportFile\"\". If you use this property', ' and parsing all the source code of all drivers is long and unpractical.   * Some implicitly declared macros (like __KERNEL__) are needed for the code to be parsed correctly. Without them lots of functions and data structures will appear as undeclared.   * A lot of the code (power management', \" and probably also needs to have some of it removed (or migrated to 'magic.verbose' or something)\", \" and start dumping checkpoints into the folder specified by checkpoint_path (default = current folder). You also have to point the train script to the VGGNet protos (see the options inside train.lua).  If you'd like to evaluate BLEU/METEOR/CIDEr scores during training in addition to validation cross entropy loss\", ' and the associated demands on memory', ' and the language automatically does the needed cloning. For ref types', ' and then run:  @abstr_code_section  And then open a browser to http://localhost: @abstr_number \"', ' and this is the actual SpriteKit class. If all you want is some sample code for SpriteKit', ' and understand AUV', ' and where they’re located? With this expanded and thoroughly revised edition', ' and writing it feels like writing HTML. A simple transform is included with React that allows converting JSX into native JavaScript for browsers to digest.  \"', ' application-driven jailer built in the spirit of fail @abstr_number ban   * @abstr_hyperlink - Go Bindings for @abstr_hyperlink ', ' are often based on a messaging or event bus that allows the various distributed components to communicate asynchronously with each other. Typically the messaging bus is some form of messaging queue service such as AMQP or ZeroMQ. The message bus supports what is commonly referred to as a publish/subscribe methodology for information exchange.  While there are many advantages to a full featured message queuing service', ' as well as parses any existing _credentials.py_ file stored in the same directory. In that case', ' because most MQ services are based on TCP/IP they tend to also use HTTP and therefore TLS/SSL for secure communications. While using HTTP provides easy integration with web based systems', ' because part of implementing OAuth requires the user to take action on the provider (Foursquare', ' both methods can be combined.  \"', ' bubble on the destination with the address and an image  @abstr_image  Turn-by-turn instructions shown in bubbles (with instructions in the default language of the phone):  @abstr_image  The same turn-by-turn instructions shown in list view:  @abstr_image  Searching for fuel stations along the route:  @abstr_image  Searching fo cinemas inside an area', ' but WITHOUT ANY WARRANTY; including but not limited to', ' but can also charge the battery via regenerative braking (negative current) during deceleration. The total energy to be computed is the NET POSITIVE energy drawn from the battery.  \"', ' but instead will query @abstr_number . @abstr_number . @abstr_number . @abstr_number on port @abstr_number and if that fails will query @abstr_number . @abstr_number . @abstr_number . @abstr_number (on @abstr_number ) to get an answer. That answer will then be given back to the original client.  When forwarding to a stub', ' but it must also have been explicitly published using the \"\"Share\"\" button in the top right corner of the Google Spreadsheets GUI.  Generally', ' but the important thing is that the line before the line to be modified reads lib:):  @abstr_code_section  You will have to modify this to look like this:  @abstr_code_section  Normally', ' but there may be cases where you\\'d like to change this. Simply set the \"\"amd\"\" option:  @abstr_code_section  Or', ' but unfortunately the formatting of these errors don\\'t make looking for it any easier. We hope to improve that in other ways (see @abstr_hyperlink )  \"', ' but want to store values that are specific for a single host. For example the public IP-address of the host or the IP-address on the tenant network.  To do that you need to specify a unique value for that host with -local. A good unique value for that would be an UUID which you can generate with uuidgen for instance.  That unique value is used as a path in etcd to store the values separately from the normal values. It is still stored in the etcd backend so a restart of SkyDNS with the same unique value will give it access to the old data.  In the example here', ' but with SystemJS module definitions. @abstr_number . Browser evaluates ES @abstr_number code generated by previous step. \"', ' but you can also directly access the raw data.  Now go ahead and @abstr_hyperlink ', ' buying or clicking all of them. Here are a few examples of what preference sets could look like:  @abstr_code_section  From these preference sets we compute a two-dimensional array', ' c_height);     template->code = codeNumber;     template->size = codeSize;     CRCodeImageTemplateStorageAddNewTemplate(codeImageTemplateStorage', ' check out @abstr_hyperlink .  \"', ' commas delimit coordinates; semicolons delimit positions| |a_m_kon |double | @abstr_number |s^(- @abstr_number ) |active motor on rate| |a_m_koff |double | @abstr_number |s^(- @abstr_number ) |active motor off rate| |a_m_kend |double | @abstr_number |s^(- @abstr_number ) |active motor off rate at filament end| |a_motor_stiffness |double | @abstr_number |pN/um |active motor spring stiffness| |a_motor_length |double | @abstr_number . @abstr_number |um |length of motor| |a_m_stall |double | @abstr_number |pN |stall force of motors| |a_m_break |double | @abstr_number |pN |rupture force of motors| |a_m_bind |double | @abstr_number . @abstr_number |pN_um |binding energy| |a_motor_v |double | @abstr_number |um/s |velocity along filaments towards barbed end when attached| |motor_intersect_flag |boolean|false | |if true', ' configure', ' context switching', ' create a directory ext_lib within your project and populate it with symlinks to your libraries. Then set up the .tern-project something like this:  @abstr_code_section  Then', ' directing it to said directory. Then the app will be launchable from the app screen and the extensions screen.  To distribute the app', ' do \"\"Project -> Open/Import Project...\"\" and select the root Makefile of your Linux kernel. When prompted for the type of the project', ' drop me a line! \"', ' each slide will be defined by default with an element containing the slide class: @abstr_code_section You can see a fully working example of the HTML structure in the [demoPage.html` file](https://github.com/alvarotrigo/fullPage.js/blob/master/examples/demoPage.html).  \"', ' either manually add -lprofile to the linker command line', ' encryption and the CurveCP handshake for secure bootstrap.  The queue management and micro-threaded application support is provided by Ioflo. RAET is a complementary project to Ioflo in that RAET enables multiple Ioflo applications to work together over a network as part of a distributed application.  The primary use case and motivating problem that resulted in the development of RAET was the need to enable SaltStack to scale better. SaltStack is a remote execution and configuration management platform written in Python. SaltStack uses ZeroMQ ( @abstr_number MQ) as its message bus or message queuing service. ZeroMQ is based on TCP/IP so suffers from the aforementioned latency and non-asynchronicity issues of TCP/IP based architectures. Moreover because ZeroMQ integrates queue management and transport in a monolithic way with special \"\"sockets\"\"', ' etc. More information and instructions for subscribing are at @abstr_hyperlink .  \"', ' etc. etc.  \"', ' evtList){}  Callback function called when user click in a day', ' execute custom python script', ' first columns and then rows are binded to a single tidy dataset.  With the help of dlpyr package data are grouped by subject and activity and then averaged. The result is saved in the working directory as summary.txt  \"', ' first ensure you have @abstr_hyperlink and then run the following command:       pear install PHP_CodeSniffer   If you prefer using @abstr_hyperlink you can easily install PHP_CodeSniffer system-wide with the following command:       composer global require \"\"squizlabs/php_codesniffer=\"\"   Make sure you have ~/.composer/vendor/bin/ in your PATH.  Or alternatively', ' for easiest transition from a \"\"Vanilla\"\" server to one enhanced by StarryPy', ' function(err', ' graphical tool for dealing with streams of data.   * @abstr_hyperlink - Vectormath for Go', ' hereby commit to the neveragain.tech pledge. Please stand with me and hold me to it. #neveragaintech\"\" * Post \"\"I', ' high performance messaging system for microservices', \" how do the things in parentheses _become_ true or false?  JavaScript lets us compare things. Most of these comparisons come straight from math: we can ask if something is less than something else (enter these in your console!):  @abstr_code_section  We can ask if something is greater than something else:  @abstr_code_section  We can even ask if something is less-than-or-equal-to something else:  @abstr_code_section  or greater-than-or-equal-to something:  @abstr_code_section  How do we test if something is _exactly_ equal to something else? We know that we can't just use =\", ' iOS and Windows). The intelxdk.config.additions.xml file can be used to include options that control your _packaged Cordova web app_ builds. For example', ' if a \"\"must-have\"\" touch pattern arises', ' if we pass utter nonsense to parseInt()? Go ahead and try it in the console — something like  @abstr_code_section  What did it return? NaN? What is that?  NaN stands for \"\"not a number\"\" — pretty handy', ' ignored if embedCSS is false   * startOpen: false do not immediately truncate', ' import the cleanup', ' including without limitation the rights to use', ' including without limitation the rights_ _to use', ' indicating that the authorization process was successful.  \"', ' infact due to a logic error in previous code the cookies were not being used anyway. Now Django Select @abstr_number does not use cookies etc.   * Few more bugs fixed in heav_data.js.   * Now production code will use minimized versions of js and css files.   * Codes added in setup.py to automate the task of minimizing js and css files', ' injection and in class annotations', ' is a tuned transport protocol that adds reliability to UDP/IP without sacrificing latency and scalability. A transactioned protocol', ' is much more appropriate for providing reliablity to asynchronous event transport than a streaming protocol.  Morover', ' it can become problematic for high performant systems Furthermore', ' it ends up owned by root (but in your home directory).  Check that you own your own .npm directory ls -ld ~/.npm  If it is owned by root', ' it evaluates the left-hand side of the colon; otherwise it evaluates the right-hand side of the colon.  Syntax:  @abstr_code_section    * Define a function ternaryTeenager that accepts age as a parameter. The body of the function should use the ternary operator to return \"\"You are a teenager\"\" if age is between @abstr_number - @abstr_number and returns \"\"You are not a teenager\"\" if the age is anything else.    Top tip : In order for the function to actually return the evaluation of the ternary operator', ' it is much better suited to many small asynchronous messages and scales better. The drawback of bare UDP/IP is that it is not reliable. What is needed', ' it is the exception. No other TCP/IP stack available for the Amiga robustly supports a similar feature. If the TCP/IP stack supports this feature', ' it means you are not using the @abstr_number . @abstr_number jre. Type java -version to check. You may need to close and reopen your terminal if you installed @abstr_number . @abstr_number recently.  \"', ' it now has all the functions.  Implementation inheritance is used instead of subtyping to make it easier to understand which functions operate on any given \"\"subject\"\". If you have an element and you need to use a function defined in Node', ' it should return \"\"You are a grownup\"\" Top tip : Remember', ' it will upgrade. - Likewise', \" it's actually ABCBAD\", ' it\\'s an important skill to have!  \"', \" it's in gcc:lib/gcc/ppc-amigaos/*compiler-version*/specs. Most likely\", \" jumps to the symbol's declaration. For C/C++/Objective-C\", ' just call .readmore() on the element containing your block of text and Readmore.js takes care of the rest. Readmore.js plays well in a responsive environment', ' just go to your project folder and run:          github_changelog_generator     * Or', ' just take forever (actually until a timeout is reached). You need to keep this in mind in order to not block your main or UI thread.  Implications of this design choice  Pros:    * A blocking API is much easier to use and understand    Cons:    * You just might accidentally block your UI thread   * You cannot issue thousands of EWS requests asynchronously simply because you cannot spawn thousands of threads in your process. You may need additional effort here    \"', ' keys and NSEC @abstr_number records returned. Authenticated denial of existence is implemented using NSEC @abstr_number white lies', ' libqs.c and the yara signatures except where noted are Copyright @abstr_number Tyler McLellan and Tylabs.  See included Mozilla Public License Version @abstr_number . @abstr_number for licensing information. \"', ' like AMQP', ' make sure that the instances are being launched with a security group that allows SSH access.  \"', ' memory', ' network', ' network) in distributed concurrent event driven applications is to use something called micro-threads. A microthread is typically an in-language feature that allows logical concurrency with no more overhead than a function call. Micro threading uses cooperative multi-tasking instead of threads and/or processes and avoids many of the complexities of resource contention', ' no matter the direction. Because we don’t care who requested the friendship once it’s approved', ' no more than the number of cpu cores. This optimizes the use of the cpu power while minimizes the overhead of process context switching.  An example of a framework that uses this type of micro-threaded but multi-process architecture is Erlang. Indeed', ' notebook', ' nothing is sent to Gmail and all messages currently stored on your device are simply marked \"\"backed up\"\". This option is handy if you previously uninstalled SMS Backup+ and do not want to send your messages again to Gmail. Please note that any messages arrived after you last uninstalled SMS Backup and this initial backup won\\'t ever be backed up to Gmail.  \"', ' of course', ' on average across all \"', ' on the other hand', ' one for front side only', ' one might ask', ' one of the best ways to manage and fine tune processor resources (cpu', ' one of the disadvantagesis the inability to manage performance at scale.  A message queuing service performs two distinct but complementary functions.    * The first is asynchronous transport of messages over the internet.   * The second is message queue management', ' or because they are tech geeks. But these data remain under-utilized both because the raw data are hard to obtain and there is a lack of statistical methods and software for processing and interpreting the data.  This assignment makes use of data from a personal activity monitoring device. This device collects data at @abstr_number minute intervals through out the day. The data consists of two months of data from an anonymous individual collected during the months of October and November', ' or both   * Added \"\"returnName\"\" setting which makes the widget return a name instead of HEX value when possible   * Removed many unnecessary features   * Removed dependency on images and made the colour picker completely CSS     \"', ' or if you are usually handling many temporary \"\"to be in a github pull request\"\" branches', ' or modify the specs file as follows. Find the lines that look like this (it may actually differ slightly from your specs file', ' otherwise SERVFAIL is returned.  This also works for IPv @abstr_number addresses', ' post an issue in @abstr_hyperlink .  If you think there is an issue with osmdroid', ' preface it by @abstr_number . These numbers correspond to the projections in the projectionEnum declaration in elevr-player.js.  If you want to add your picture to the drop-down', ' production)', ' provides increases in security with lower performance requirements relative to over other approaches. LibSodium provides an open source Elliptic Curve Cryptographic library with support for both authentication and encryption. The CurveCP protocol is based on LibSodium and provides a handshake protocol for bootstrapping secure network exchanges of information.  Finally', ' push your changes to your clone and submit a pull request; instructions are available at @abstr_hyperlink . (In case you need them', ' ready-to-use download of the library/framework (unminified) ( @abstr_number )   * Prefer hand-coded/hand-optimized JavaScript over generated/cross-compiled code.   * Running \"\"make\"\" should work and not return an error. To run make', ' requests', ' result will be @abstr_number : @abstr_number', \" rg -uuu is similar to grep -a -r.  @abstr_code_section  (Tip: If your ignore files aren't being adhered to like you expect\", ' rgb()', ' right?  What happens', \" ripgrep defaults to recursive directory search and won't search files ignored by your .gitignore files. It also ignores hidden and binary files by default. ripgrep also implements full support for .gitignore\", ' route display', ' ruby', \" run the test suite by typing learn and hitting enter. You'll see something similar to:  @abstr_image  You can see your test is currently failing\", ' run this from anywhere:      * github_changelog_generator -u github_username -p github_project     * github_changelog_generator github_username/github_project   * If you are running it against a repository on a Github Enterprise install', ' send an email to  with subject line \"\"[web-animations] ... message topic ...\"\" ( @abstr_hyperlink ).   * For issues with the polyfill', ' simply: \"\"./build.sh test\"\"  To run all the tests  > $ ./build.sh install -DallTests  \"', \" so a typical call to parseInt() looks like  @abstr_code_section  What happens if we pass a representation of a non-integer to parseInt()? Let's try it:  @abstr_code_section  If we enter the above in console\", ' so the final path becomes /v @abstr_number /keys/skydns/local/skydns/east/production/rails   * Host - The name of your service', ' so we leave it out.   * The xact() decorator will set up the connection so that a transaction _is_ started in the relevant block', ' software distributed under the License is distributed on an \"\"AS IS\"\" BASIS', ' spreadsheet) {         spreadsheet.worksheets[ @abstr_number ].cells({             range: \"\"R @abstr_number C @abstr_number :R @abstr_number C @abstr_number \"\"         }', ' storage', \" substituting '' with the IP value copied in prev:       Set-Item WSMan:\\\\localhost\\\\Client\\\\TrustedHosts -Value <machine-name or IP Address>   @abstr_number . Type Y and press Enter to confirm the change.  @abstr_number . Now you can start a session with you Windows IoT Core device. From you administrator PS console\", ' such as \"\"m @abstr_number .medium\"\". The default value of this if not specified is \"\"m @abstr_number .medium\"\". \"\"m @abstr_number .small\"\" has been deprecated in \"\"us-east- @abstr_number \"\" and \"\"m @abstr_number .medium\"\" is the smallest instance type to support both paravirtualization and hvm AMIs   * keypair_name - The name of the keypair to use to bootstrap AMIs which support it.   * monitoring - Set to \"\"true\"\" to enable detailed monitoring.   * session_token - The session token provided by STS   * private_ip_address - The private IP address to assign to an instance within a @abstr_hyperlink   * elastic_ip - Can be set to \\'true\\'', ' tend to be unreliable under load.  Separating the function of network transport of asynchrounous event from the function of message queue management allows independant tuning at scale of each function.  Most if not all of the MQ services are based on TCP/IP for transport. TCP/IP adds significant latency to the network communications and is therefore not well suited for the asynchronous nature of distibuted event driven application communications. This is primarily due to the way TCP/IP handles connection setup and teardown as well as failed connections in order to support streams. Fundamentally TCP/IP is optomized for sending large contiguous data streams not many small aynchronous events or messages. While not a problem for small scale systems', ' thanks to @abstr_hyperlink ! Tap \"\"Hint\"\" to show hint (e.g. Move left/right/up/down); tap \"\"Auto Run\"\" to run AI automatically. Check it out in the AI branch. You can also check out @abstr_hyperlink .  Thanks to @abstr_hyperlink \\'s Javascript version that gave me (DJBen', ' that is', ' the \"\"more info\"\" button will open the full Wikipedia page:  @abstr_image  Showing geolocalized Flickr photos related to the current map view:  @abstr_image  Showing geolocalized Picasa photos related to the current map view:  on the map | as a list view ------------- | ------------- @abstr_image | @abstr_image  When searching a place by name', ' the \"\"pattern matching swiss knife for malware researchers (and everyone else)\"\"   * @abstr_hyperlink - Pure Go ACME client library and CLI tool (for use with Let\\'s Encrypt)   * @abstr_hyperlink - Futureproof password hashing library.   * @abstr_hyperlink - an scrypt package with a simple', \" the Erlang ecosystem is somewhat limited in comparison to Python's and the language itself uses what one might describe as a very unfortunate syntax. One of the design objectives behine RAET was to leverage existing Python expertise and the richness of the Python ecosystem but still be able to develop distributed applications using a micro-threaded multi-process architectural model. The goal was to combine the best of both worlds.  RAET is designed to provide secure reliable scalable asynchronous message/event transport over the internet in a micro-threaded multi-process application framework that uses UDP for interhost communication and LibSodium for authentication\", ' the application needs to be able to run at least one process per CPU core. This requires same host inter-process communications. But unlike the conventional approach to multi-processing where there is of one process per logical concurrent function', \" the autoScrolling functionality will still work as expected. The user will also be free to scroll the site with the scroll bar and fullPage.js will fit the section in the screen when scrolling finishes.    * paddingTop: (default @abstr_number) Defines the top padding for each section with a numerical value and its measure (paddingTop: ' @abstr_number px'\", ' the bootstrap.json file will create a     newsblur user with no password.   @abstr_number . Start mongodb (if not already running):           mongod run   @abstr_number . Run the development server. At this point', ' the client has little ability to tune the service for performance. Often MQ services become bottlenecks for the distributed application. The more complicated MQ services', ' the completion \"\"getUserAccount\"\" would be ranked higher in the list than the \"\"Fooguxa\"\" completion (both of which are subsequence matches). A word-boundary character are all capital characters', ' the complexities of queue management from the clients. The disadvantage is that at scale', ' the content of the _credentials.py_ file must follow this format:       URL=\"\"https:// @abstr_number . @abstr_number . @abstr_number . @abstr_number \"\"     LOGIN=\"\"admin\"\"     PASSWORD=\"\"Ap @abstr_number cPass @abstr_number \"\"   If the _credentials.py_ does not exist and the credentials are not supplied from the command line', ' the diagnostic messages will be sent to stderr.  If the program was launched from Workbench or if the global variable __no_standard_io is set to a non-zero value', ' the differences in the associated traffic characteristics can become problematic at scale.  Because UDP/IP has lower latency and is connectionless', ' the entire _phrase_) to be true; with ||', ' the expanding/collapsing animation is done with CSS @abstr_number transitions.  By default', ' the identification', ' the link should say \"\" @abstr_number commits\"\".  @abstr_number . You will see a list of commits that you have made to this repository. The most recent commit is at the very top. If this represents the version of the files you want to submit', \" the name of the item you wish to remove. If the item isn't in the cart\", ' the other CNANE is returned from the remote name server.  \"', ' the predefined targets are \"\"BookShelf\"\"', ' the program must be linked against libprofile.a. To do this', \" the rate limit is only up to @abstr_number requests per hour. Unauthenticated requests are associated with your IP address (not the user making requests).  If you're seeing this warning\", \" the specs file is located at the compiler's installation directory. For cross-compilers\", ' the success of the Erlang model provided support for the viability of the RAET approach. Indeed', ' the time when the signal was received', ' the timing of messages', ' then installing the new version. Make sure to select \"\"Skip\"\" when doing the first backup', ' then start the dev server as usual with npm start:   \"', ' then the uppercase letters in your query must match uppercase letters in the completion strings (the lowercase letters still match both). So', \" then your     cmake call will be a bit more complicated.  We'll assume you downloaded a     binary distribution of LLVM+Clang from llvm.org in step  @abstr_number  and that you     extracted the archive file to folder ~/ycm_temp/llvm_root_dir (with bin\", ' there is an option of using a specific proxy to extract video information from the site: --extractor-proxy/-y.    \"', ' there is at least a single .entry element within the .feed container. Remember', ' there will be some results', ' there\\'s nothing you need to do! Ionic @abstr_number projects by default are setup with sass and come with all the build process enabled.  \"', ' therefore', ' this is /usr/local/amiga/lib/gcc/ppc-amigaos/*compiler-version*/specs. For a native compiler', ' this is a little more expensive', ' this mode is based on this function', ' though', ' thus resulting in changing the package provider on Mac OS X', ' tracking', ' true) Enable sorting of dragged item (disabling is useful when you only want item removal).   * drag_start_mode: (enum', ' two steps are required. First of all', ' two-way data binding', ' type in \"\"ping hostname_A\"\"', ' use make firefox and to build Safari use make safari.  The extensions will be in the browser-ext/login/build directory.  \"', ' username and password', ' users will be considered \"\"logged in\"\" if they have an access token stored in their session. So', ' utilizing PWM pins  Layer @abstr_number NUMPAD keys: This is useful for gaming because games can bind separate commands to numpad_ @abstr_number and regular @abstr_number ', \" we don't use an UUID\", ' we guarantee that it will not immediately return if it fails. By adding the Success node', ' we intercept all <a href=\"\"/path\"\">...</a> clicks and call msg.setLocation(\"\"/path\"\") for you. If you want to opt out of this', ' we know that our function should look like  @abstr_code_section  But how do we make string all caps? JavaScript has a method for that! It\\'s called toUpperCase(). We can call it on any string:  @abstr_code_section  So let\\'s try it with our shout() function:  @abstr_code_section  And run our tests again:  @abstr_code_section  @abstr_image  Hey! We got one to pass!  \"', ' we need to go over some basic math. In this lab', ' we should have: IP for computer A and B (denoted as IP_A and IP_B later on in the instruction)', ' we use public.addresses:       % skydns -local public.addresses.skydns.local &      % curl -XPUT http:// @abstr_number . @abstr_number . @abstr_number . @abstr_number : @abstr_number /v @abstr_number /keys/skydns/local/skydns/local/addresses/public \\\\         -d value=\\'{\"\"host\"\":\"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number \"\"}\\'      % dig @ @abstr_number . @abstr_number . @abstr_number . @abstr_number  local.dns.skydns.local. A      ;; ANSWER SECTION:     local.dns.skydns.local.  @abstr_number  IN  A    @abstr_number . @abstr_number . @abstr_number . @abstr_number   The name local.dns.skydns.local. is fixed', \" we'll see that parseInt() forces the parsed number to be an integer — which makes sense when we think about it\", \" we're going to learn about various arithmetic operators. What's an operator\", \" we're going to practice writing functions and manipulating numbers in JavaScript. First\", ' whenever you try to make a Git commit', ' where the volume of messages', ' wherein components are distributed across the internet on multiple hosts and multiple CPU cores', ' which accepts two arguments: the value to parse and the base of the value being parsed. _Usually_ you will want to work with base @abstr_number ', \" which takes our new-found speaking ability to greet our grandmother. She's not exactly deaf\", ' which was created using simulated data :  @abstr_image  Your plot will look different from the one above because you will be using the activity monitor data. Note that the above plot was made using the lattice system but you can make the same version of the plot using any plotting system you choose.  \"', ' which will automatically be created the first time you\\'re performing a backup.  \"', ' which will be resolved.  Also see the section Host Local Values.      \"', ' why not use Erlang? Unfortunately', ' will be removed in a later version)    \"', ' window', ' with clustered markers:  @abstr_image  Showing Wikipedia POIs related to the current map view. In the bubble', ' you can choose to only include a subset of IntentKit\\'s supported applications. Subspecs exist for each handler class.       # Only includes web browsers     pod \"\"IntentKit/Browsers\"\"   For more information on what subspecs are available', ' you can install PHP_CodeSniffer using the PEAR installer. This will make the phpcs and phpcbf commands immediately available for use. To install PHP_CodeSniffer using the PEAR installer', ' you can specify to set the crontab user with:  @abstr_code_section  \"', ' you may find it convenient to run watch-css automatically with npm start', ' you must call DragSortListView.moveCheckState(int from', ' you must call DragSortListView.removeCheckState(int position) within remove(which). See the documentation in the DSLV API for more info.  \"', ' you must specify _both_ --github-site and --github-api command line options:          github_changelog_generator --github-site=\"\"https://github.yoursite.com\"\" \\\\                                --github-api=\"\"https://github.yoursite.com/api/v @abstr_number /\"\"      This generates a changelog to the CHANGELOG.md file', ' you say? It\\'s a symbol that _operates_ on one or more (usually two) objects — + is a good example. The + operator says \"\"add what\\'s to the left of + and what\\'s to the right of + together.\"\" Easy-peasy!  As you read through this lesson', ' you should always use the --rebase flag to git pull', ' you won\\'t get automatic updates this way).  \"', ' your compiler will already have this added to it\\'s specs file.  Profiling makes use of a special PowerPC facility called the _Performance Monitor_. It allows to \"\"mark\"\" tasks and count only during while a marked task is running. This allows performance analysis to be made independent of the actual system load. The _Performance Monitor_ is available on all PowerPC models supported by AmigaOS @abstr_number except for the * @abstr_number e*', ' your program must be compiled with the _GCC_ command line option -pg. This instructs the compiler to generate special profiling code in the prologue and epilogue of each function. Additionally', \" { \\\\ 'build' : { \\\\ 'mac' : './install.py'\", ' ~/.bash_profile or ~/.zshrc):           export CHANGELOG_GITHUB_TOKEN=\"\"«your- @abstr_number -digit-github-token»\"\"   So', '\"\"port\"\": @abstr_number }\\'     curl -XPUT http:// @abstr_number . @abstr_number . @abstr_number . @abstr_number : @abstr_number /v @abstr_number /keys/skydns/local/skydns/east/staging/rails/ @abstr_number  \\\\         -d value=\\'{\"\"host\"\":\"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number \"\"', '\"\"port\"\": @abstr_number }\\'   And try it out:       ;; ANSWER SECTION:     bar.skydns.local.    @abstr_number     IN  SRV  @abstr_number   @abstr_number   @abstr_number  x @abstr_number .bar.skydns.local.     bar.skydns.local.    @abstr_number     IN  SRV  @abstr_number   @abstr_number   @abstr_number  bar.skydns.local.      ;; ADDITIONAL SECTION:     x @abstr_number .bar.skydns.local.  @abstr_number     IN  A    @abstr_number . @abstr_number . @abstr_number . @abstr_number   Which has x @abstr_number in the name', '\"\"port\"\": @abstr_number }\\'   We have created the following CNAME chain: @abstr_number .rails.production.east.skydns.local -> service @abstr_number .skydns.local -> @abstr_number . @abstr_number . @abstr_number . @abstr_number. If you then query for an A or AAAA for @abstr_number .rails.production.east.skydns.local SkyDNS returns:        @abstr_number .rails.production.east.skydns.local.  @abstr_number   IN  CNAME   service @abstr_number .skydns.local.     service @abstr_number .skydns.local.                  @abstr_number   IN  A        @abstr_number . @abstr_number . @abstr_number . @abstr_number   \"', '\"AI  An AI is added', '\"Audio/Music  _Libraries for manipulating audio._    * @abstr_hyperlink - A native Go FLAC decoder.   * @abstr_hyperlink - A native Go FLAC decoder.   * @abstr_hyperlink - libsox bindings for go.   * @abstr_hyperlink - libmediainfo bindings for go.   * @abstr_hyperlink - Sequence-based Go-native audio mixer for music apps.   * @abstr_hyperlink - A native Go MP# decoder.   * @abstr_hyperlink - Music theory models in Go.   * @abstr_hyperlink - Go bindings for the PortAudio audio I/O library.   * @abstr_hyperlink - Go bindings for PortMidi.   * @abstr_hyperlink - Go bindings for taglib.   * @abstr_hyperlink - A \"\"native\"\" Go Vorbis decoder (uses CGO', '\"Batching a bunch of messages using the block syntax    require \\'kafka\\'     producer = Kafka::Producer.new     producer.batch do |messages|         puts \"\"Batching a send of multiple messages..\"\"         messages << Kafka::Message.new(\"\"first message to send\"\")         messages << Kafka::Message.new(\"\"second message to send\"\")     end     * they will be sent all at once', '\"Checking Authentication  The first thing we want to do is figure out if a user has already authenticated to Foursquare in this session.  Ultimately', '\"Design Notes  ews-cpp is written in a \"\"modern C++\"\" way:    * C++ Standard Library', '\"Examples  Geocoding', '\"File handles - \"\"Too many files open\"\"  You may run into a \"\"too many files open\"\" error during compilation or reloading. You can find out how many file handles you are allowed per process by running ulimit -n. This can be quite low', '\"Host Local Values  SkyDNS supports storing values which are specific for that _instance_ of SkyDNS.  This can be useful when you have SkyDNS running on multiple hosts', '\"How Do I Create an Address Pool and Round Robin Between Them  You have @abstr_number machines with @abstr_number different IP addresses and you want to have @abstr_number name pointing to all @abstr_number possible addresses. The name we want to use is: db.skydns.local and the @abstr_number addresses are @abstr_number . @abstr_number . @abstr_number .{ @abstr_number ', '\"How can I make the app think that it has to do the backup again?  Select \"\"Reset\"\" from the menu', '\"Installation  Add this to your composer.json:  JSON { \"\"require\"\": { \"\"thekonz/piximgen\"\": \"\" @abstr_number . @abstr_number .*@dev\"\" } } @abstr_code_section PHP require_once \\'vendor/autoload.php\\'; @abstr_code_section PHP $image = new \\\\thekonz\\\\PixImGen(); @abstr_code_section PHP $image->setSettings([ \\'seed\\' => \\'GitHub rocks!\\' ]); @abstr_code_section PHP header(\\'content-type: image/png\\'); @abstr_code_section PHP echo $image->getImage();    * Look at your image!    @abstr_image  If you play around with the settings (especially the saturation settings)', '\"Installation  The easiest way to get started with PHP_CodeSniffer is to download the @abstr_hyperlink files for each of the commands:       curl -OL https://squizlabs.github.io/PHP_CodeSniffer/phpcs.phar     php phpcs.phar -h      curl -OL https://squizlabs.github.io/PHP_CodeSniffer/phpcbf.phar     php phpcbf.phar -h   If you use PEAR', '\"Installing  This plugin requires KDevelop @abstr_number . @abstr_number .  Just typing cmake . && make && sudo make install should be enough to have the project installed. Then in KDevelop', '\"Introduction  In this lab', '\"MX Records  If a service is added with \"\"mail\"\": true it is _also_ an MX record', '\"Motivation  Modern large scale distributed application architectures', '\"Next steps  Get your computer or device to use the VPN. Please refer to:  Configure IPsec/L @abstr_number TP VPN Clients Configure IPsec/XAuth (\"\"Cisco IPsec\"\") VPN Clients  How-To: IKEv @abstr_number VPN for Windows and Android  If you get an error when trying to connect', '\"Publish your book  The platform @abstr_hyperlink is like an \"\"Heroku for books\"\": you can create a book on it (public', '\"Rebasing  For feature/topic branches', '\"Restoring  If you wish to restore messages back to your phone tap \"\"Restore\"\". By default all messages stored on Gmail will be restored (this can be changed in \"\"Advanced Settings\"\"). You can safely restore to a phone which has already message stored on it', '\"Road', '\"Security  _Libraries that are used to help make your application more secure._    * @abstr_hyperlink — ACME (Let\\'s Encrypt) client tool with automatic renewal.   * @abstr_hyperlink - An in-memory', '\"Sending a sequence of messages    require \\'kafka\\'     producer = Kafka::Producer.new     message @abstr_number  = Kafka::Message.new(\"\"some random message content\"\")     message @abstr_number  = Kafka::Message.new(\"\"some more content\"\")     producer.send([message @abstr_number ', '\"Standard CLI  _Libraries for building standard or basic Command Line applications_    * @abstr_hyperlink - A feature-rich and easy to use command-line package based on golang tag   * @abstr_hyperlink - The easy way to start building Golang command line application.   * @abstr_hyperlink - An alternative CLI with \"\"human face\"\"', '\"Ternary Operator  You can think of it as a shortcut for the if-else statement.  This operator tests a condition; if the condition is truthy', '\"The config.json file  The config.json file currently only requires the key \"\"states_dir\"\" and the value \"\"states/\"\" to tell the test script where to find its states relative to the root of the git repo. The \"\"/\"\" at the end of states is important don\\'t forget it. In the example above', '\"Usage    $ python @abstr_number  aci-fabric-deploy.py --input <spreadhseet>      Optional arguments:       -u URL', '\"Usage  It\\'s really simple!    * If your git remote origin refers to your GitHub repo', '\"Using gmon (PowerPC only)  To use profiling', '\"Using unit tests  There are various unit tests included in this package to verify if certain modules are operating properly. Simply run the \"\"test\"\" prefixed python script associated with the module you would like to test.  For example to test the DrugDatabase module', '\"We love feedback!   For feedback on the API and the specification:      * File an issue on GitHub:     * Alternatively', '\"When updating the app I get \\'Package file was not signed correctly\\'  Try uninstalling the app', '\"Why do backed up SMS show up in my inbox?  This is probably related to Gmail\\'s automatic priority inbox filing. A workaround is to set up a filter with \"\"subject: SMS with\"\"', '\"href  As a bonus', '\"if-else Statements  You will often see an if statement used in combination with an else clause. An else clause will only get executed if the previous if statement is falsey.  Syntax:  @abstr_code_section    * Define a function teenager that accepts an age as a parameter. If the age is between @abstr_number and @abstr_number it should return \"\"You are a teenager!\"\". Otherwise', '\"parseInt()  The first such tool is the function parseInt()', '...) may not read any data at all. If your program needs functions such as these or atod() then you must link against libm.a or the equivalent.  To link the floating point support code with your software', '2', 'css', '记得core.js中把user改为自己的账户名'] will be ignored\n  warnings.warn('unknown class(es) {0} will be ignored'\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["##Cross Validate to find the best model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"65cc4c8c-3ed2-41d6-b35b-8afd6f22b747"}}},{"cell_type":"code","source":["def cross_validate_model(classifier, classifier_name):\n  print(f'Running experiment for {classifier_name}')\n  print('Getting per-class scores')\n  y_pred = cross_val_predict(classifier, features_combined.values, labels_matrix, cv=10)\n\n  print('Computing overall results')\n  scores_f1 = cross_val_score(classifier, features_combined.values, labels_matrix, cv=10, scoring='f1_weighted').mean()\n\n  print(classification_report(labels_matrix, y_pred, digits=3))\n  print('f1_weighted : {0}'.format(scores_f1))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6be071da-c9d4-4435-954a-d71e5a624d2f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["cross_validate_model(OneVsRestClassifierBalance(HistGradientBoostingClassifier()), 'HistGradientBoostingClassifier()')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"69bdf64f-d626-4d83-a45b-5cbae302a29e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Running experiment for HistGradientBoostingClassifier()\nGetting per-class scores\nComputing overall results\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\", line 202, in fit\n    X, y = self._validate_data(X, y, dtype=[X_DTYPE],\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4060, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\", line 202, in fit\n    X, y = self._validate_data(X, y, dtype=[X_DTYPE],\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4060, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\", line 202, in fit\n    X, y = self._validate_data(X, y, dtype=[X_DTYPE],\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\", line 202, in fit\n    X, y = self._validate_data(X, y, dtype=[X_DTYPE],\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\", line 202, in fit\n    X, y = self._validate_data(X, y, dtype=[X_DTYPE],\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\", line 202, in fit\n    X, y = self._validate_data(X, y, dtype=[X_DTYPE],\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\", line 202, in fit\n    X, y = self._validate_data(X, y, dtype=[X_DTYPE],\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\", line 202, in fit\n    X, y = self._validate_data(X, y, dtype=[X_DTYPE],\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\", line 202, in fit\n    X, y = self._validate_data(X, y, dtype=[X_DTYPE],\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n              precision    recall  f1-score   support\n\n           0      0.464     0.775     0.581       422\n           1      0.530     0.641     0.580       652\n           2      0.747     0.893     0.814      2234\n           3      0.757     0.576     0.654       151\n           4      0.767     0.723     0.744       274\n           5      0.545     0.656     0.595       811\n           6      0.883     0.769     0.822       108\n           7      0.120     0.689     0.204        61\n\n   micro avg      0.618     0.781     0.690      4713\n   macro avg      0.602     0.715     0.624      4713\nweighted avg      0.653     0.781     0.706      4713\n samples avg      0.668     0.755     0.688      4713\n\nf1_weighted : nan\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\", line 202, in fit\n    X, y = self._validate_data(X, y, dtype=[X_DTYPE],\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Running experiment for HistGradientBoostingClassifier()\nGetting per-class scores\nComputing overall results\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\", line 202, in fit\n    X, y = self._validate_data(X, y, dtype=[X_DTYPE],\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4060, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\", line 202, in fit\n    X, y = self._validate_data(X, y, dtype=[X_DTYPE],\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4060, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\", line 202, in fit\n    X, y = self._validate_data(X, y, dtype=[X_DTYPE],\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\", line 202, in fit\n    X, y = self._validate_data(X, y, dtype=[X_DTYPE],\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\", line 202, in fit\n    X, y = self._validate_data(X, y, dtype=[X_DTYPE],\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\", line 202, in fit\n    X, y = self._validate_data(X, y, dtype=[X_DTYPE],\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\", line 202, in fit\n    X, y = self._validate_data(X, y, dtype=[X_DTYPE],\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\", line 202, in fit\n    X, y = self._validate_data(X, y, dtype=[X_DTYPE],\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\", line 202, in fit\n    X, y = self._validate_data(X, y, dtype=[X_DTYPE],\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n              precision    recall  f1-score   support\n\n           0      0.464     0.775     0.581       422\n           1      0.530     0.641     0.580       652\n           2      0.747     0.893     0.814      2234\n           3      0.757     0.576     0.654       151\n           4      0.767     0.723     0.744       274\n           5      0.545     0.656     0.595       811\n           6      0.883     0.769     0.822       108\n           7      0.120     0.689     0.204        61\n\n   micro avg      0.618     0.781     0.690      4713\n   macro avg      0.602     0.715     0.624      4713\nweighted avg      0.653     0.781     0.706      4713\n samples avg      0.668     0.755     0.688      4713\n\nf1_weighted : nan\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\", line 202, in fit\n    X, y = self._validate_data(X, y, dtype=[X_DTYPE],\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n"]},"transient":null}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ENSF612 Final Project with Histogram Gradient Boost - New Data","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":4424314020178533}},"nbformat":4,"nbformat_minor":0}
