{"cells":[{"cell_type":"code","source":["%sh\npip install nltk\npip install click\npip install html2text\npip install lxml\npip install markdown2\npip install numpy\npip install pandas\npip install python-dateutil\npip install pytz\npip install regex\npip install scikit-learn\npip install scipy\npip install six\npip install sklearn\npip install soupsieve\npip install threadpoolctl\npip install tqdm\npip install bs4\npip install beautifulsoup4\npip install --upgrade pip\npython -m nltk.downloader all"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5c6453c3-0cd4-4174-a58b-e167db5eb895"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Requirement already satisfied: nltk in /databricks/python3/lib/python3.8/site-packages (3.6.5)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (from nltk) (4.62.3)\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (from nltk) (8.0.3)\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.8/site-packages (from nltk) (2021.11.10)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from nltk) (1.0.1)\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (8.0.3)\nRequirement already satisfied: html2text in /databricks/python3/lib/python3.8/site-packages (2020.1.16)\nRequirement already satisfied: lxml in /databricks/python3/lib/python3.8/site-packages (4.6.4)\nRequirement already satisfied: markdown2 in /databricks/python3/lib/python3.8/site-packages (2.4.1)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.8/site-packages (1.19.2)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.8/site-packages (1.2.4)\nRequirement already satisfied: pytz>=2017.3 in /databricks/python3/lib/python3.8/site-packages (from pandas) (2020.5)\nRequirement already satisfied: numpy>=1.16.5 in /databricks/python3/lib/python3.8/site-packages (from pandas) (1.19.2)\nRequirement already satisfied: python-dateutil>=2.7.3 in /databricks/python3/lib/python3.8/site-packages (from pandas) (2.8.1)\nRequirement already satisfied: six>=1.5 in /databricks/python3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\nRequirement already satisfied: python-dateutil in /databricks/python3/lib/python3.8/site-packages (2.8.1)\nRequirement already satisfied: six>=1.5 in /databricks/python3/lib/python3.8/site-packages (from python-dateutil) (1.15.0)\nRequirement already satisfied: pytz in /databricks/python3/lib/python3.8/site-packages (2020.5)\nRequirement already satisfied: regex in /databricks/python3/lib/python3.8/site-packages (2021.11.10)\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.8/site-packages (0.24.1)\nRequirement already satisfied: joblib>=0.11 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn) (1.0.1)\nRequirement already satisfied: scipy>=0.19.1 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn) (1.6.2)\nRequirement already satisfied: numpy>=1.13.3 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn) (1.19.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.8/site-packages (1.6.2)\nRequirement already satisfied: numpy<1.23.0,>=1.16.5 in /databricks/python3/lib/python3.8/site-packages (from scipy) (1.19.2)\nRequirement already satisfied: six in /databricks/python3/lib/python3.8/site-packages (1.15.0)\nRequirement already satisfied: sklearn in /databricks/python3/lib/python3.8/site-packages (0.0)\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.8/site-packages (from sklearn) (0.24.1)\nRequirement already satisfied: joblib>=0.11 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.0.1)\nRequirement already satisfied: scipy>=0.19.1 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.6.2)\nRequirement already satisfied: numpy>=1.13.3 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.19.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\nRequirement already satisfied: soupsieve in /databricks/python3/lib/python3.8/site-packages (2.3.1)\nRequirement already satisfied: threadpoolctl in /databricks/python3/lib/python3.8/site-packages (2.1.0)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (4.62.3)\nRequirement already satisfied: bs4 in /databricks/python3/lib/python3.8/site-packages (0.0.1)\nRequirement already satisfied: beautifulsoup4 in /databricks/python3/lib/python3.8/site-packages (from bs4) (4.10.0)\nRequirement already satisfied: soupsieve>1.2 in /databricks/python3/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.3.1)\nRequirement already satisfied: beautifulsoup4 in /databricks/python3/lib/python3.8/site-packages (4.10.0)\nRequirement already satisfied: soupsieve>1.2 in /databricks/python3/lib/python3.8/site-packages (from beautifulsoup4) (2.3.1)\nRequirement already satisfied: pip in /databricks/python3/lib/python3.8/site-packages (21.3.1)\n/usr/lib/python3.8/runpy.py:127: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n  warn(RuntimeWarning(msg))\n[nltk_data] Downloading collection 'all'\n[nltk_data]    | \n[nltk_data]    | Downloading package abc to /root/nltk_data...\n[nltk_data]    |   Package abc is already up-to-date!\n[nltk_data]    | Downloading package alpino to /root/nltk_data...\n[nltk_data]    |   Package alpino is already up-to-date!\n[nltk_data]    | Downloading package biocreative_ppi to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n[nltk_data]    | Downloading package brown to /root/nltk_data...\n[nltk_data]    |   Package brown is already up-to-date!\n[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n[nltk_data]    |   Package brown_tei is already up-to-date!\n[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n[nltk_data]    |   Package cess_cat is already up-to-date!\n[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n[nltk_data]    |   Package cess_esp is already up-to-date!\n[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n[nltk_data]    |   Package chat80 is already up-to-date!\n[nltk_data]    | Downloading package city_database to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package city_database is already up-to-date!\n[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n[nltk_data]    |   Package cmudict is already up-to-date!\n[nltk_data]    | Downloading package comparative_sentences to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package comparative_sentences is already up-to-\n[nltk_data]    |       date!\n[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n[nltk_data]    |   Package comtrans is already up-to-date!\n[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n[nltk_data]    |   Package conll2000 is already up-to-date!\n[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n[nltk_data]    |   Package conll2002 is already up-to-date!\n[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n[nltk_data]    |   Package conll2007 is already up-to-date!\n[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n[nltk_data]    |   Package crubadan is already up-to-date!\n[nltk_data]    | Downloading package dependency_treebank to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package dependency_treebank is already up-to-date!\n[nltk_data]    | Downloading package dolch to /root/nltk_data...\n[nltk_data]    |   Package dolch is already up-to-date!\n[nltk_data]    | Downloading package europarl_raw to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package europarl_raw is already up-to-date!\n[nltk_data]    | Downloading package floresta to /root/nltk_data...\n[nltk_data]    |   Package floresta is already up-to-date!\n[nltk_data]    | Downloading package framenet_v15 to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package framenet_v15 is already up-to-date!\n[nltk_data]    | Downloading package framenet_v17 to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package framenet_v17 is already up-to-date!\n[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n[nltk_data]    |   Package gazetteers is already up-to-date!\n[nltk_data]    | Downloading package genesis to /root/nltk_data...\n[nltk_data]    |   Package genesis is already up-to-date!\n[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n[nltk_data]    |   Package gutenberg is already up-to-date!\n[nltk_data]    | Downloading package ieer to /root/nltk_data...\n[nltk_data]    |   Package ieer is already up-to-date!\n[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n[nltk_data]    |   Package inaugural is already up-to-date!\n[nltk_data]    | Downloading package indian to /root/nltk_data...\n[nltk_data]    |   Package indian is already up-to-date!\n[nltk_data]    | Downloading package jeita to /root/nltk_data...\n[nltk_data]    |   Package jeita is already up-to-date!\n[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n[nltk_data]    |   Package kimmo is already up-to-date!\n[nltk_data]    | Downloading package knbc to /root/nltk_data...\n[nltk_data]    |   Package knbc is already up-to-date!\n[nltk_data]    | Downloading package lin_thesaurus to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n[nltk_data]    |   Package mac_morpho is already up-to-date!\n[nltk_data]    | Downloading package machado to /root/nltk_data...\n[nltk_data]    |   Package machado is already up-to-date!\n[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n[nltk_data]    |   Package masc_tagged is already up-to-date!\n[nltk_data]    | Downloading package moses_sample to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package moses_sample is already up-to-date!\n[nltk_data]    | Downloading package movie_reviews to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package movie_reviews is already up-to-date!\n[nltk_data]    | Downloading package names to /root/nltk_data...\n[nltk_data]    |   Package names is already up-to-date!\n[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n[nltk_data]    |   Package nps_chat is already up-to-date!\n[nltk_data]    | Downloading package omw to /root/nltk_data...\n[nltk_data]    |   Package omw is already up-to-date!\n[nltk_data]    | Downloading package opinion_lexicon to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n[nltk_data]    |   Package paradigms is already up-to-date!\n[nltk_data]    | Downloading package pil to /root/nltk_data...\n[nltk_data]    |   Package pil is already up-to-date!\n[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n[nltk_data]    |   Package pl196x is already up-to-date!\n[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n[nltk_data]    |   Package ppattach is already up-to-date!\n[nltk_data]    | Downloading package problem_reports to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package problem_reports is already up-to-date!\n[nltk_data]    | Downloading package propbank to /root/nltk_data...\n[nltk_data]    |   Package propbank is already up-to-date!\n[nltk_data]    | Downloading package ptb to /root/nltk_data...\n[nltk_data]    |   Package ptb is already up-to-date!\n[nltk_data]    | Downloading package product_reviews_1 to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n[nltk_data]    | Downloading package product_reviews_2 to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n[nltk_data]    |   Package pros_cons is already up-to-date!\n[nltk_data]    | Downloading package qc to /root/nltk_data...\n[nltk_data]    |   Package qc is already up-to-date!\n[nltk_data]    | Downloading package reuters to /root/nltk_data...\n[nltk_data]    |   Package reuters is already up-to-date!\n[nltk_data]    | Downloading package rte to /root/nltk_data...\n[nltk_data]    |   Package rte is already up-to-date!\n[nltk_data]    | Downloading package semcor to /root/nltk_data...\n[nltk_data]    |   Package semcor is already up-to-date!\n[nltk_data]    | Downloading package senseval to /root/nltk_data...\n[nltk_data]    |   Package senseval is already up-to-date!\n[nltk_data]    | Downloading package sentiwordnet to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package sentiwordnet is already up-to-date!\n[nltk_data]    | Downloading package sentence_polarity to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package sentence_polarity is already up-to-date!\n[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n[nltk_data]    |   Package shakespeare is already up-to-date!\n[nltk_data]    | Downloading package sinica_treebank to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package sinica_treebank is already up-to-date!\n[nltk_data]    | Downloading package smultron to /root/nltk_data...\n[nltk_data]    |   Package smultron is already up-to-date!\n[nltk_data]    | Downloading package state_union to /root/nltk_data...\n[nltk_data]    |   Package state_union is already up-to-date!\n[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n[nltk_data]    |   Package stopwords is already up-to-date!\n[nltk_data]    | Downloading package subjectivity to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package subjectivity is already up-to-date!\n[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n[nltk_data]    |   Package swadesh is already up-to-date!\n[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n[nltk_data]    |   Package switchboard is already up-to-date!\n[nltk_data]    | Downloading package timit to /root/nltk_data...\n[nltk_data]    |   Package timit is already up-to-date!\n[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n[nltk_data]    |   Package toolbox is already up-to-date!\n[nltk_data]    | Downloading package treebank to /root/nltk_data...\n[nltk_data]    |   Package treebank is already up-to-date!\n[nltk_data]    | Downloading package twitter_samples to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package twitter_samples is already up-to-date!\n[nltk_data]    | Downloading package udhr to /root/nltk_data...\n[nltk_data]    |   Package udhr is already up-to-date!\n[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n[nltk_data]    |   Package udhr2 is already up-to-date!\n[nltk_data]    | Downloading package unicode_samples to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package unicode_samples is already up-to-date!\n[nltk_data]    | Downloading package universal_treebanks_v20 to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n[nltk_data]    |       date!\n[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n[nltk_data]    |   Package verbnet is already up-to-date!\n[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n[nltk_data]    |   Package verbnet3 is already up-to-date!\n[nltk_data]    | Downloading package webtext to /root/nltk_data...\n[nltk_data]    |   Package webtext is already up-to-date!\n[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n[nltk_data]    |   Package wordnet is already up-to-date!\n[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n[nltk_data]    |   Package wordnet31 is already up-to-date!\n[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n[nltk_data]    |   Package wordnet_ic is already up-to-date!\n[nltk_data]    | Downloading package words to /root/nltk_data...\n[nltk_data]    |   Package words is already up-to-date!\n[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n[nltk_data]    |   Package ycoe is already up-to-date!\n[nltk_data]    | Downloading package rslp to /root/nltk_data...\n[nltk_data]    |   Package rslp is already up-to-date!\n[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n[nltk_data]    |       to-date!\n[nltk_data]    | Downloading package universal_tagset to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package universal_tagset is already up-to-date!\n[nltk_data]    | Downloading package maxent_ne_chunker to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n[nltk_data]    | Downloading package punkt to /root/nltk_data...\n[nltk_data]    |   Package punkt is already up-to-date!\n[nltk_data]    | Downloading package book_grammars to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package book_grammars is already up-to-date!\n[nltk_data]    | Downloading package sample_grammars to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package sample_grammars is already up-to-date!\n[nltk_data]    | Downloading package spanish_grammars to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package spanish_grammars is already up-to-date!\n[nltk_data]    | Downloading package basque_grammars to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package basque_grammars is already up-to-date!\n[nltk_data]    | Downloading package large_grammars to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package large_grammars is already up-to-date!\n[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n[nltk_data]    |   Package tagsets is already up-to-date!\n[nltk_data]    | Downloading package snowball_data to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package snowball_data is already up-to-date!\n[nltk_data]    | Downloading package bllip_wsj_no_aux to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n[nltk_data]    | Downloading package word2vec_sample to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package word2vec_sample is already up-to-date!\n[nltk_data]    | Downloading package panlex_swadesh to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n[nltk_data]    |   Package mte_teip5 is already up-to-date!\n[nltk_data]    | Downloading package averaged_perceptron_tagger to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n[nltk_data]    |       to-date!\n[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n[nltk_data]    |       up-to-date!\n[nltk_data]    | Downloading package perluniprops to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package perluniprops is already up-to-date!\n[nltk_data]    | Downloading package nonbreaking_prefixes to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n[nltk_data]    | Downloading package vader_lexicon to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package vader_lexicon is already up-to-date!\n[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n[nltk_data]    |   Package porter_test is already up-to-date!\n[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n[nltk_data]    |   Package wmt15_eval is already up-to-date!\n[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n[nltk_data]    | \n[nltk_data]  Done downloading collection all\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: nltk in /databricks/python3/lib/python3.8/site-packages (3.6.5)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (from nltk) (4.62.3)\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (from nltk) (8.0.3)\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.8/site-packages (from nltk) (2021.11.10)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from nltk) (1.0.1)\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (8.0.3)\nRequirement already satisfied: html2text in /databricks/python3/lib/python3.8/site-packages (2020.1.16)\nRequirement already satisfied: lxml in /databricks/python3/lib/python3.8/site-packages (4.6.4)\nRequirement already satisfied: markdown2 in /databricks/python3/lib/python3.8/site-packages (2.4.1)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.8/site-packages (1.19.2)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.8/site-packages (1.2.4)\nRequirement already satisfied: pytz>=2017.3 in /databricks/python3/lib/python3.8/site-packages (from pandas) (2020.5)\nRequirement already satisfied: numpy>=1.16.5 in /databricks/python3/lib/python3.8/site-packages (from pandas) (1.19.2)\nRequirement already satisfied: python-dateutil>=2.7.3 in /databricks/python3/lib/python3.8/site-packages (from pandas) (2.8.1)\nRequirement already satisfied: six>=1.5 in /databricks/python3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\nRequirement already satisfied: python-dateutil in /databricks/python3/lib/python3.8/site-packages (2.8.1)\nRequirement already satisfied: six>=1.5 in /databricks/python3/lib/python3.8/site-packages (from python-dateutil) (1.15.0)\nRequirement already satisfied: pytz in /databricks/python3/lib/python3.8/site-packages (2020.5)\nRequirement already satisfied: regex in /databricks/python3/lib/python3.8/site-packages (2021.11.10)\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.8/site-packages (0.24.1)\nRequirement already satisfied: joblib>=0.11 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn) (1.0.1)\nRequirement already satisfied: scipy>=0.19.1 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn) (1.6.2)\nRequirement already satisfied: numpy>=1.13.3 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn) (1.19.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.8/site-packages (1.6.2)\nRequirement already satisfied: numpy<1.23.0,>=1.16.5 in /databricks/python3/lib/python3.8/site-packages (from scipy) (1.19.2)\nRequirement already satisfied: six in /databricks/python3/lib/python3.8/site-packages (1.15.0)\nRequirement already satisfied: sklearn in /databricks/python3/lib/python3.8/site-packages (0.0)\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.8/site-packages (from sklearn) (0.24.1)\nRequirement already satisfied: joblib>=0.11 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.0.1)\nRequirement already satisfied: scipy>=0.19.1 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.6.2)\nRequirement already satisfied: numpy>=1.13.3 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.19.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\nRequirement already satisfied: soupsieve in /databricks/python3/lib/python3.8/site-packages (2.3.1)\nRequirement already satisfied: threadpoolctl in /databricks/python3/lib/python3.8/site-packages (2.1.0)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (4.62.3)\nRequirement already satisfied: bs4 in /databricks/python3/lib/python3.8/site-packages (0.0.1)\nRequirement already satisfied: beautifulsoup4 in /databricks/python3/lib/python3.8/site-packages (from bs4) (4.10.0)\nRequirement already satisfied: soupsieve>1.2 in /databricks/python3/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.3.1)\nRequirement already satisfied: beautifulsoup4 in /databricks/python3/lib/python3.8/site-packages (4.10.0)\nRequirement already satisfied: soupsieve>1.2 in /databricks/python3/lib/python3.8/site-packages (from beautifulsoup4) (2.3.1)\nRequirement already satisfied: pip in /databricks/python3/lib/python3.8/site-packages (21.3.1)\n/usr/lib/python3.8/runpy.py:127: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n  warn(RuntimeWarning(msg))\n[nltk_data] Downloading collection 'all'\n[nltk_data]    | \n[nltk_data]    | Downloading package abc to /root/nltk_data...\n[nltk_data]    |   Package abc is already up-to-date!\n[nltk_data]    | Downloading package alpino to /root/nltk_data...\n[nltk_data]    |   Package alpino is already up-to-date!\n[nltk_data]    | Downloading package biocreative_ppi to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n[nltk_data]    | Downloading package brown to /root/nltk_data...\n[nltk_data]    |   Package brown is already up-to-date!\n[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n[nltk_data]    |   Package brown_tei is already up-to-date!\n[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n[nltk_data]    |   Package cess_cat is already up-to-date!\n[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n[nltk_data]    |   Package cess_esp is already up-to-date!\n[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n[nltk_data]    |   Package chat80 is already up-to-date!\n[nltk_data]    | Downloading package city_database to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package city_database is already up-to-date!\n[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n[nltk_data]    |   Package cmudict is already up-to-date!\n[nltk_data]    | Downloading package comparative_sentences to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package comparative_sentences is already up-to-\n[nltk_data]    |       date!\n[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n[nltk_data]    |   Package comtrans is already up-to-date!\n[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n[nltk_data]    |   Package conll2000 is already up-to-date!\n[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n[nltk_data]    |   Package conll2002 is already up-to-date!\n[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n[nltk_data]    |   Package conll2007 is already up-to-date!\n[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n[nltk_data]    |   Package crubadan is already up-to-date!\n[nltk_data]    | Downloading package dependency_treebank to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package dependency_treebank is already up-to-date!\n[nltk_data]    | Downloading package dolch to /root/nltk_data...\n[nltk_data]    |   Package dolch is already up-to-date!\n[nltk_data]    | Downloading package europarl_raw to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package europarl_raw is already up-to-date!\n[nltk_data]    | Downloading package floresta to /root/nltk_data...\n[nltk_data]    |   Package floresta is already up-to-date!\n[nltk_data]    | Downloading package framenet_v15 to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package framenet_v15 is already up-to-date!\n[nltk_data]    | Downloading package framenet_v17 to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package framenet_v17 is already up-to-date!\n[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n[nltk_data]    |   Package gazetteers is already up-to-date!\n[nltk_data]    | Downloading package genesis to /root/nltk_data...\n[nltk_data]    |   Package genesis is already up-to-date!\n[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n[nltk_data]    |   Package gutenberg is already up-to-date!\n[nltk_data]    | Downloading package ieer to /root/nltk_data...\n[nltk_data]    |   Package ieer is already up-to-date!\n[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n[nltk_data]    |   Package inaugural is already up-to-date!\n[nltk_data]    | Downloading package indian to /root/nltk_data...\n[nltk_data]    |   Package indian is already up-to-date!\n[nltk_data]    | Downloading package jeita to /root/nltk_data...\n[nltk_data]    |   Package jeita is already up-to-date!\n[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n[nltk_data]    |   Package kimmo is already up-to-date!\n[nltk_data]    | Downloading package knbc to /root/nltk_data...\n[nltk_data]    |   Package knbc is already up-to-date!\n[nltk_data]    | Downloading package lin_thesaurus to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n[nltk_data]    |   Package mac_morpho is already up-to-date!\n[nltk_data]    | Downloading package machado to /root/nltk_data...\n[nltk_data]    |   Package machado is already up-to-date!\n[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n[nltk_data]    |   Package masc_tagged is already up-to-date!\n[nltk_data]    | Downloading package moses_sample to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package moses_sample is already up-to-date!\n[nltk_data]    | Downloading package movie_reviews to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package movie_reviews is already up-to-date!\n[nltk_data]    | Downloading package names to /root/nltk_data...\n[nltk_data]    |   Package names is already up-to-date!\n[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n[nltk_data]    |   Package nps_chat is already up-to-date!\n[nltk_data]    | Downloading package omw to /root/nltk_data...\n[nltk_data]    |   Package omw is already up-to-date!\n[nltk_data]    | Downloading package opinion_lexicon to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n[nltk_data]    |   Package paradigms is already up-to-date!\n[nltk_data]    | Downloading package pil to /root/nltk_data...\n[nltk_data]    |   Package pil is already up-to-date!\n[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n[nltk_data]    |   Package pl196x is already up-to-date!\n[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n[nltk_data]    |   Package ppattach is already up-to-date!\n[nltk_data]    | Downloading package problem_reports to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package problem_reports is already up-to-date!\n[nltk_data]    | Downloading package propbank to /root/nltk_data...\n[nltk_data]    |   Package propbank is already up-to-date!\n[nltk_data]    | Downloading package ptb to /root/nltk_data...\n[nltk_data]    |   Package ptb is already up-to-date!\n[nltk_data]    | Downloading package product_reviews_1 to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n[nltk_data]    | Downloading package product_reviews_2 to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n[nltk_data]    |   Package pros_cons is already up-to-date!\n[nltk_data]    | Downloading package qc to /root/nltk_data...\n[nltk_data]    |   Package qc is already up-to-date!\n[nltk_data]    | Downloading package reuters to /root/nltk_data...\n[nltk_data]    |   Package reuters is already up-to-date!\n[nltk_data]    | Downloading package rte to /root/nltk_data...\n[nltk_data]    |   Package rte is already up-to-date!\n[nltk_data]    | Downloading package semcor to /root/nltk_data...\n[nltk_data]    |   Package semcor is already up-to-date!\n[nltk_data]    | Downloading package senseval to /root/nltk_data...\n[nltk_data]    |   Package senseval is already up-to-date!\n[nltk_data]    | Downloading package sentiwordnet to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package sentiwordnet is already up-to-date!\n[nltk_data]    | Downloading package sentence_polarity to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package sentence_polarity is already up-to-date!\n[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n[nltk_data]    |   Package shakespeare is already up-to-date!\n[nltk_data]    | Downloading package sinica_treebank to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package sinica_treebank is already up-to-date!\n[nltk_data]    | Downloading package smultron to /root/nltk_data...\n[nltk_data]    |   Package smultron is already up-to-date!\n[nltk_data]    | Downloading package state_union to /root/nltk_data...\n[nltk_data]    |   Package state_union is already up-to-date!\n[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n[nltk_data]    |   Package stopwords is already up-to-date!\n[nltk_data]    | Downloading package subjectivity to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package subjectivity is already up-to-date!\n[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n[nltk_data]    |   Package swadesh is already up-to-date!\n[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n[nltk_data]    |   Package switchboard is already up-to-date!\n[nltk_data]    | Downloading package timit to /root/nltk_data...\n[nltk_data]    |   Package timit is already up-to-date!\n[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n[nltk_data]    |   Package toolbox is already up-to-date!\n[nltk_data]    | Downloading package treebank to /root/nltk_data...\n[nltk_data]    |   Package treebank is already up-to-date!\n[nltk_data]    | Downloading package twitter_samples to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package twitter_samples is already up-to-date!\n[nltk_data]    | Downloading package udhr to /root/nltk_data...\n[nltk_data]    |   Package udhr is already up-to-date!\n[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n[nltk_data]    |   Package udhr2 is already up-to-date!\n[nltk_data]    | Downloading package unicode_samples to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package unicode_samples is already up-to-date!\n[nltk_data]    | Downloading package universal_treebanks_v20 to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n[nltk_data]    |       date!\n[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n[nltk_data]    |   Package verbnet is already up-to-date!\n[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n[nltk_data]    |   Package verbnet3 is already up-to-date!\n[nltk_data]    | Downloading package webtext to /root/nltk_data...\n[nltk_data]    |   Package webtext is already up-to-date!\n[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n[nltk_data]    |   Package wordnet is already up-to-date!\n[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n[nltk_data]    |   Package wordnet31 is already up-to-date!\n[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n[nltk_data]    |   Package wordnet_ic is already up-to-date!\n[nltk_data]    | Downloading package words to /root/nltk_data...\n[nltk_data]    |   Package words is already up-to-date!\n[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n[nltk_data]    |   Package ycoe is already up-to-date!\n[nltk_data]    | Downloading package rslp to /root/nltk_data...\n[nltk_data]    |   Package rslp is already up-to-date!\n[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n[nltk_data]    |       to-date!\n[nltk_data]    | Downloading package universal_tagset to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package universal_tagset is already up-to-date!\n[nltk_data]    | Downloading package maxent_ne_chunker to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n[nltk_data]    | Downloading package punkt to /root/nltk_data...\n[nltk_data]    |   Package punkt is already up-to-date!\n[nltk_data]    | Downloading package book_grammars to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package book_grammars is already up-to-date!\n[nltk_data]    | Downloading package sample_grammars to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package sample_grammars is already up-to-date!\n[nltk_data]    | Downloading package spanish_grammars to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package spanish_grammars is already up-to-date!\n[nltk_data]    | Downloading package basque_grammars to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package basque_grammars is already up-to-date!\n[nltk_data]    | Downloading package large_grammars to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package large_grammars is already up-to-date!\n[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n[nltk_data]    |   Package tagsets is already up-to-date!\n[nltk_data]    | Downloading package snowball_data to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package snowball_data is already up-to-date!\n[nltk_data]    | Downloading package bllip_wsj_no_aux to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n[nltk_data]    | Downloading package word2vec_sample to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package word2vec_sample is already up-to-date!\n[nltk_data]    | Downloading package panlex_swadesh to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n[nltk_data]    |   Package mte_teip5 is already up-to-date!\n[nltk_data]    | Downloading package averaged_perceptron_tagger to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n[nltk_data]    |       to-date!\n[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n[nltk_data]    |       up-to-date!\n[nltk_data]    | Downloading package perluniprops to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package perluniprops is already up-to-date!\n[nltk_data]    | Downloading package nonbreaking_prefixes to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n[nltk_data]    | Downloading package vader_lexicon to\n[nltk_data]    |     /root/nltk_data...\n[nltk_data]    |   Package vader_lexicon is already up-to-date!\n[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n[nltk_data]    |   Package porter_test is already up-to-date!\n[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n[nltk_data]    |   Package wmt15_eval is already up-to-date!\n[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n[nltk_data]    | \n[nltk_data]  Done downloading collection all\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["import nltk\nimport re\nimport pandas\nfrom pandas import DataFrame\nimport numpy as np\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.preprocessing import LabelBinarizer\nfrom joblib import Parallel\nfrom joblib import delayed\nfrom sklearn.utils import resample\nfrom sklearn.utils.validation import check_is_fitted\nfrom sklearn.base import BaseEstimator, clone\nimport logging\n\nimport sqlite3\nfrom sqlite3 import Error\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"79b13783-4df8-471c-9d71-dc858877836c"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["class _ConstantPredictor(BaseEstimator):\n\n    def fit(self, X, y):\n        self.y_ = y\n        return self\n\n    def predict(self, X):\n        check_is_fitted(self, 'y_')\n\n        return np.repeat(self.y_, X.shape[0])\n\n    def decision_function(self, X):\n        check_is_fitted(self, 'y_')\n\n        return np.repeat(self.y_, X.shape[0])\n\n    def predict_proba(self, X):\n        check_is_fitted(self, 'y_')\n\n        return np.repeat([np.hstack([1 - self.y_, self.y_])],\n                         X.shape[0], axis=0)\n\n\ndef _fit_binary(estimator, X, y, classes=None):\n    \"\"\"Fit a single binary estimator.\"\"\"\n    unique_y = np.unique(y)\n    if len(unique_y) == 1:\n        if classes is not None:\n            if y[0] == -1:\n                c = 0\n            else:\n                c = y[0]\n\n        estimator = _ConstantPredictor().fit(X, unique_y)\n    else:\n        estimator = clone(estimator)\n        estimator.fit(X, y)\n    return estimator\n\nclass OneVsRestClassifierBalance(OneVsRestClassifier):\n\n    def fit(self, X, y):\n        self.label_binarizer_ = LabelBinarizer(sparse_output=True)\n        Y = self.label_binarizer_.fit_transform(y)\n        Y = Y.tocsc()\n        self.classes_ = self.label_binarizer_.classes_\n        totalIns = Y.shape[0]\n        XBal = []\n        YBal = []\n        for i in range(len(self.label_binarizer_.classes_)):\n            if len(y.shape) > 1:\n                # Matrix\n                curIdxs = Y[:, i].nonzero()[0]\n            else:\n                curIdxs = Y.nonzero()[0]\n            baseX = X[curIdxs, :]\n            if len(y.shape) > 1:\n                # Matrix\n                baseY = y[curIdxs, :]\n            else:\n                # array, e.g. due to testing classifier performance for single label prediction\n                baseY = y[curIdxs]\n            tempX = X\n            tempY = y\n            imbalancedIns = baseX.shape[0]\n            numDup = totalIns / imbalancedIns - 1\n            for j in range(int(numDup)):\n                tempX = np.vstack((tempX, baseX))\n                if len(y.shape) > 1:\n                    tempY = np.vstack((tempY, baseY))\n                else:\n                    tempY = np.concatenate((tempY, baseY))\n            numAdd = totalIns % imbalancedIns\n            tempX = np.vstack((tempX, resample(baseX, n_samples=numAdd, random_state=0)))\n            if len(y.shape) > 1:\n                tempY = np.vstack((tempY, resample(baseY, n_samples=numAdd, random_state=0)))\n            else:\n                tempY = np.concatenate((tempY, resample(baseY, n_samples=numAdd, random_state=0)))\n            XBal.append(tempX)\n            if len(y.shape) > 1:\n                YBal.append(tempY[:, i])\n            else:\n                YBal.append(tempY)\n        self.estimators_ = Parallel(n_jobs=self.n_jobs)(delayed(_fit_binary)(\n            self.estimator, XBal[i], YBal[i], classes=[\n                \"not %s\" % self.label_binarizer_.classes_[i],\n                self.label_binarizer_.classes_[i]])\n                                                        for i in range(len(YBal)))\n        # for i, column in enumerate(columns))\n        return self\n\nclass HeurFeat():\n    def heur_c_k_001(self,input_text):\n        if ('report bugs' in input_text.lower()) or ('reporting bugs' in input_text.lower()):\n            return 1\n        else:\n            return 0\n\n    def heur_c_k_002(self,input_text):\n        if ' is a ' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_c_k_003(self,input_text):\n        if '@abstr_code_section' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_c_k_004(self,input_text):\n        if 'attempts to' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_c_k_005(self,input_text):\n        if 'inspired by' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_c_k_006(self,input_text):\n        if 'install ' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_c_k_007(self,input_text):\n        if 'reasons' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    # Do not use lower() because we want to capture \"Added\" at beginning of sentence\n    def heur_c_k_008(self,input_text):\n        if 'Added ' in input_text:\n            return 1\n        else:\n            return 0\n\n    def heur_c_k_009(self,input_text):\n        if 'copyright' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_c_k_010(self,input_text):\n        if '@abstr_mailto' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_c_k_011(self,input_text):\n        if 'you can ' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    # Check if the text comprises solely of @abstr_code_section\n    def heur_c_k_012(self,input_text):\n        if '@abstr_code_section' == input_text.lower().strip():\n            return 1\n        else:\n            return 0\n\n    def heur_c_k_013(self,input_text):\n        if 'About' in input_text:\n            return 1\n        else:\n            return 0\n\n    def heur_c_k_014(self,input_text):\n        if 'be sure to' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_c_k_015(self,input_text):\n        if 'Download' in input_text:\n            return 1\n        else:\n            return 0\n\n    def heur_c_k_016(self,input_text):\n        if 'overview' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_c_k_017(self,input_text):\n        if 'get started' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_c_k_018(self,input_text):\n        if 'reasons' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_c_k_019(self,input_text):\n        if 'dependenc' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_c_k_020(self,input_text):\n        if 'rerun' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_c_k_021(self,input_text):\n        if 'you''ll be able' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_c_k_022(self,input_text):\n        if 'you must' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_c_k_023(self,input_text):\n        if 'previous version' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_001(self,input_text):\n        if 'configur' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_002(self,input_text):\n        if 'what' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_003(self,input_text):\n        if 'why' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_004(self,input_text):\n        if 'approach' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_005(self,input_text):\n        if 'bugs' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_006(self,input_text):\n        if 'contrib' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_007(self,input_text):\n        if 'credit' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_008(self,input_text):\n        if 'feature' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_009(self,input_text):\n        if 'install' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_010(self,input_text):\n        if 'intro' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_011(self,input_text):\n        if 'licen' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_012(self,input_text):\n        if 'objective' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_013(self,input_text):\n        if 'request' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_014(self,input_text):\n        if 'requirement' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_015(self,input_text):\n        if 'resource' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_016(self,input_text):\n        if 'setting' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_017(self,input_text):\n        if 'setup' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_018(self,input_text):\n        if 'started' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_019(self,input_text):\n        if 'usage' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_020(self,input_text):\n        if 'version' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_021(self,input_text):\n        if 'welcome' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_022(self,input_text):\n        if 'what is' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_023(self,input_text):\n        if 'overview' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_024(self,input_text):\n        if 'basic' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_025(self,input_text):\n        if 'roadmap' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_026(self,input_text):\n        if 'todo' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_027(self,input_text):\n        if 'example' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_028(self,input_text):\n        if 'about' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n    def heur_h_k_029(self,input_text):\n        if 'reference' in input_text.lower():\n            return 1\n        else:\n            return 0\n\n            # Return 1 if string is single non-English word\n\n    # WARNING: For speed, instantiate the word set outside and pass it as parameter,\n    # so that instantiation will be done once for each program run\n    # instead of once for each row this heuristic is applied to\n    def heur_h_c_001(self,input_text, words=None):\n        nltk.download('words')\n        lcase_input_text = input_text.lower()\n        s = lcase_input_text.split(' ')\n        if len(s) != 1:\n            return 0\n        else:\n            if words is None:\n                words = set(nltk.corpus.words.words())\n            if s[0] in words:\n                return 0\n            else:\n                return 1\n        return 0\n\n    # Returns 1 if a word in heading text is in repo name, or the other way around\n    def heur_h_c_002(self,heading_text, repo_url):\n        nltk.download('words')\n        heading_words = heading_text.lower().split(' ')\n        repo_name = re.sub(r\"http(s)*:\\/\\/www\\.github\\.com\\/.+\\/\", '', repo_url)\n        repo_name = repo_name.replace('.', ' ').replace('-', ' ')\n        repo_name_words = repo_name.lower().split(' ')\n        match = [val for val in heading_words if val in repo_name_words]\n        if len(match) > 0:\n            return 1\n        else:\n            return 0\n\n    # See whether text comprises entirely of ASCII characters\n    def heur_c_s_001(self,input_text):\n        try:\n            input_text.encode(encoding='utf-8').decode('ascii')\n        except UnicodeDecodeError:\n            return 0\n        else:\n            return 1\n\n            # Generate DataFrame of derived features using DataFrames of some initial features\n\n    def derive_features_using_heuristics(self,url_corpus, heading_text_corpus, content_corpus):\n        nltk.download('words')\n        derived_features = DataFrame()\n        derived_features['heur_c_k_001'] = [self.heur_c_k_001(x) for x in content_corpus]\n        derived_features['heur_c_k_002'] = [self.heur_c_k_002(x) for x in content_corpus]\n        derived_features['heur_c_k_003'] = [self.heur_c_k_003(x) for x in content_corpus]\n        derived_features['heur_c_k_004'] = [self.heur_c_k_004(x) for x in content_corpus]\n        derived_features['heur_c_k_005'] = [self.heur_c_k_005(x) for x in content_corpus]\n        derived_features['heur_c_k_006'] = [self.heur_c_k_006(x) for x in content_corpus]\n        derived_features['heur_c_k_007'] = [self.heur_c_k_007(x) for x in content_corpus]\n        derived_features['heur_h_k_001'] = [self.heur_h_k_001(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_002'] = [self.heur_h_k_002(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_003'] = [self.heur_h_k_003(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_004'] = [self.heur_h_k_004(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_005'] = [self.heur_h_k_005(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_006'] = [self.heur_h_k_006(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_007'] = [self.heur_h_k_007(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_008'] = [self.heur_h_k_008(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_009'] = [self.heur_h_k_009(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_010'] = [self.heur_h_k_010(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_011'] = [self.heur_h_k_011(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_012'] = [self.heur_h_k_012(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_013'] = [self.heur_h_k_013(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_014'] = [self.heur_h_k_014(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_015'] = [self.heur_h_k_015(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_016'] = [self.heur_h_k_016(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_017'] = [self.heur_h_k_017(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_018'] = [self.heur_h_k_018(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_019'] = [self.heur_h_k_019(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_020'] = [self.heur_h_k_020(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_021'] = [self.heur_h_k_021(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_022'] = [self.heur_h_k_022(x) for x in heading_text_corpus]\n        derived_features['heur_c_s_001'] = [self.heur_c_s_001(x) for x in heading_text_corpus]\n\n        # Batch 02\n        derived_features['heur_c_k_008'] = [self.heur_c_k_008(x) for x in content_corpus]\n        derived_features['heur_c_k_009'] = [self.heur_c_k_009(x) for x in content_corpus]\n        derived_features['heur_c_k_010'] = [self.heur_c_k_010(x) for x in content_corpus]\n        derived_features['heur_c_k_011'] = [self.heur_c_k_011(x) for x in content_corpus]\n        derived_features['heur_c_k_012'] = [self.heur_c_k_012(x) for x in content_corpus]\n        derived_features['heur_c_k_013'] = [self.heur_c_k_013(x) for x in content_corpus]\n        derived_features['heur_h_k_023'] = [self.heur_h_k_023(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_024'] = [self.heur_h_k_024(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_025'] = [self.heur_h_k_025(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_026'] = [self.heur_h_k_026(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_027'] = [self.heur_h_k_027(x) for x in heading_text_corpus]\n        words = set(nltk.corpus.words.words())\n        derived_features['heur_h_c_001'] = [self.heur_h_c_001(x, words) for x in heading_text_corpus]\n        derived_features['heur_h_c_002'] = [self.heur_h_c_002(x, y) for x, y in zip(heading_text_corpus, url_corpus)]\n\n        # Batch 03\n        derived_features['heur_c_k_014'] = [self.heur_c_k_014(x) for x in content_corpus]\n        derived_features['heur_c_k_015'] = [self.heur_c_k_015(x) for x in content_corpus]\n        derived_features['heur_c_k_016'] = [self.heur_c_k_016(x) for x in content_corpus]\n        derived_features['heur_c_k_017'] = [self.heur_c_k_017(x) for x in content_corpus]\n        derived_features['heur_c_k_018'] = [self.heur_c_k_018(x) for x in content_corpus]\n        derived_features['heur_c_k_019'] = [self.heur_c_k_019(x) for x in content_corpus]\n        derived_features['heur_c_k_020'] = [self.heur_c_k_020(x) for x in content_corpus]\n        derived_features['heur_c_k_021'] = [self.heur_c_k_021(x) for x in content_corpus]\n        derived_features['heur_c_k_022'] = [self.heur_c_k_022(x) for x in content_corpus]\n        derived_features['heur_c_k_023'] = [self.heur_c_k_023(x) for x in content_corpus]\n        derived_features['heur_h_k_028'] = [self.heur_h_k_028(x) for x in heading_text_corpus]\n        derived_features['heur_h_k_029'] = [self.heur_h_k_029(x) for x in heading_text_corpus]\n\n        return derived_features"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"088d13ec-c2e8-48f2-b1a7-e64e3e089e7b"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["class run_algorithms():\n    df = None\n    db_filename = \"../database/data.db\"\n    rng_seed = 100\n    log_filename = '../log/experiment_classifier_validation.log'\n\n    \n\n    def __init__(self):\n        \n        self.analysis_preparation()\n\n\n\n    def analysis_preparation(self):\n        \n        self.load_df_csv()\n\n        self.prepare_data()\n        print(\"Ready for classify. Run test_classifier with model of your choice.\")\n\n    def load_df_csv(self):\n        df_python = (\n        sqlContext\n        .read.format(\"csv\")\n        .option(\"header\", \"true\")\n    \n        .load('/FileStore/FinalProject/old_and_new_data-1.csv')\n          )\n        self.df = df_python.toPandas()\n\n    def test_classifier(self, classifier):\n        ca = OneVsRestClassifierBalance(classifier)\n        print(f'Running experiment for {classifier}')\n        print('Getting per-class scores')\n\n\n        logging.info(f\"labels matrix type: {type(self.labels_matrix)}\")\n        logging.info(f\"labels matrix shape: {self.labels_matrix.shape}\")\n        y_pred = cross_val_predict(ca, self.features_combined.values, self.labels_matrix, cv=10)\n\n        print('Computing overall results')\n        scores_f1 = cross_val_score(classifier, self.features_combined.values, self.labels_matrix, cv=10,\n                                    scoring='f1_weighted').mean()\n\n        print(classification_report(self.labels_matrix, y_pred, digits=3))\n        print('f1_weighted : {0}'.format(scores_f1))\n\n    def load_df_sql(self):\n        try:\n            sql_text = \"\"\"\n                SELECT t1.file_id, t1.section_id, t1.url, t1.heading_text, t2.content_text_w_o_tags, \n                t1.abstracted_heading_text || ' ' || t2.content_text_w_o_tags AS abstracted_heading_plus_content, \n                t1.section_code\n                FROM section_overview_75pct t1 \n                JOIN section_content_75pct t2 ON t1.file_id=t2.file_id AND t1.section_id=t2.section_id\n                \"\"\"\n            self.df = pandas.read_sql_query(con=self.conn, sql=sql_text)\n        except Error as e:\n            logging.exception(e)\n        except Exception as e:\n            logging.exception(e)\n        finally:\n            self.conn.close()\n\n    def prepare_data(self):\n        df_randomized_order = self.df.sample(frac=1, random_state=self.rng_seed)\n        heading_plus_content_corpus = df_randomized_order['abstracted_heading_plus_content']\n        content_corpus = df_randomized_order['content_text_w_o_tags']\n        heading_text_corpus = df_randomized_order['heading_text']\n        url_corpus = df_randomized_order['url']\n        label_set = ['-', '1', '3', '4', '5', '6', '7', '8']\n        labels = [str(x).split(',') for x in df_randomized_order['section_code']]\n        mlb = MultiLabelBinarizer(classes=label_set)\n        self.labels_matrix = mlb.fit_transform(labels)\n\n        tfidf = TfidfVectorizer(ngram_range=(1, 1), analyzer='word', stop_words='english')\n        tfidfX = tfidf.fit_transform(heading_plus_content_corpus)\n        ca = HeurFeat()\n        derived_features = ca.derive_features_using_heuristics(url_corpus, heading_text_corpus, content_corpus)\n        features_tfidf = pandas.DataFrame(tfidfX.todense())\n        # Assign column names to make it easier to print most useful features later\n        features_tfidf.columns = tfidf.get_feature_names()\n        self.features_combined = pandas.concat([features_tfidf, derived_features], axis=1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"37db2ff8-c8d7-4cc6-b491-da3cac381fa2"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["starter = run_algorithms()\npandas.set_option('display.max_columns', None)\nprint(starter.df.head())\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"866fa55a-09e6-4905-9c8a-9083cdd25bcd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/databricks/python/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:860: UserWarning: unknown class(es) ['                [\"\"[a-f @abstr_number - @abstr_number ]+\"\"', '         \"\"mail\"\" : \"\"sabre+ @abstr_number @tut.by\"\"         \"\"role\"\" : \"\"Store Owner\"\"       }        -- response --       Set-Cookie:  SESSe @abstr_number a @abstr_number a @abstr_number c @abstr_number a @abstr_number c @abstr_number b @abstr_number cb @abstr_number f @abstr_number =E @abstr_number juSPMd @abstr_number fUOg @abstr_number j_esS @abstr_number G @abstr_number MwU @abstr_number jodrDpBjl @abstr_number KHfli @abstr_number ; expires=Sat', \"         forro = require('forro')\", '         location: \"\"YOUR_LOCATION\"\"', '     \"\"express\"\": \"\"^ @abstr_number . @abstr_number . @abstr_number \"\"', '     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND', '     to deal in the Software without restriction', '   * @abstr_hyperlink ', '   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND', '   * an @abstr_hyperlink -based completion engine for C#', ' \"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number : @abstr_number ', ' \"\"alternate names\"\"', ' \"\"group\"\": \"\"g @abstr_number \"\"}     /skydns/local/domain/subdom/     /skydns/local/domain/subdom/c - {\"\"host\"\": \"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number \"\"', ' \"\"hello there\"\". The dialog will take the incoming message and find the Best Match in the list of strings', ' \"\"key @abstr_number \"\": { \"\"dataA\"\": \"\"valueA\"\"', ' \"\"nameservers\"\": [\"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number : @abstr_number \"\"', ' \"\"trouble\"\"', ' \"\"website\"\": \"\"\"\"', ' \"\"\"\"', \" 'utf- @abstr_number '\", ' --debug DEBUG           Enable debug mode   The application also takes the regular parameters for APIC address', ' --input INPUT           Input file       -d DEBUG', ' --login LOGIN           APIC login ID.       -p PASSWORD', ' --outfile FILE       Filename and base module name of the generated parser        -t', ' --password PASSWORD  APIC login password.       -i INPUT', ' --url URL                 APIC IP address.       -l LOGIN', ' .offsetParent()', ' 2', ' 3', ' 4', ' @abstr_code_section    * See below for other simulation configuration options that you can set from the command line or from a configuration file    * Once your simulation has completed', ' @abstr_number ', \" @abstr_number )) @abstr_code_section evtList = [ { date: new Date(' @abstr_number '\", ' @abstr_number ); function.Invoke(destination); int result = function.GetInt(\"\"e_result\"\"); @abstr_code_section C# using (SapRfcConnection conn = new PlainSapRfcConnection(\"\"TST\"\")) { var result = conn.ExecuteFunction(\"\"Z_SSRT_SUM\"\"', ' @abstr_number milliseconds). For complex problems', ' @abstr_number }. For this to work we create the hosts named x{ @abstr_number ', ' @abstr_number }.db.skydns.local in etcd:       curl -XPUT http:// @abstr_number . @abstr_number . @abstr_number . @abstr_number : @abstr_number /v @abstr_number /keys/skydns/local/skydns/db/x @abstr_number  -d \\\\         value=\\'{\"\"host\"\":\"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number \"\"}\\'     curl -XPUT http:// @abstr_number . @abstr_number . @abstr_number . @abstr_number : @abstr_number /v @abstr_number /keys/skydns/local/skydns/db/x @abstr_number  -d \\\\         value=\\'{\"\"host\"\": \"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number \"\"\\'}     curl -XPUT http:// @abstr_number . @abstr_number . @abstr_number . @abstr_number : @abstr_number /v @abstr_number /keys/skydns/local/skydns/db/x @abstr_number  -d \\\\         value=\\'{\"\"host\"\": \"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number \"\"\\'}   Now the name db.skydns.local is the \"\"load balanced\"\" name for the database', ' BUT NOT LIMITED TO', ' Debian @abstr_number and CentOS @abstr_number / @abstr_number     \"', ' EXPRESS OR IMPLIED', ' Enrico', ' Estates', ' I take this methodology to the world of node.js. This time', ' Inc. @abstr_number Montague ST STE @abstr_number BROOKLYN', ' MB) bar.SetUnits(pb.U_BYTES)  // and start bar.Start() @abstr_code_section go // create and start bar bar := pb.New(myDataLen).SetUnits(pb.U_BYTES) bar.Start()  // my io.Reader r := myReader  // my io.Writer w := myWriter  // create proxy reader reader := bar.NewProxyReader(r)  // and copy from pb reader io.Copy(w', ' Main Estate   The UDP channel is a Road\"\"   * The members of a Road are Estates (as in real estate lots that front the road)   * Each Estate has a unique UDP Host Port address ha ', ' NSErrorFailingURLKey=https://api.leancloud.cn/ @abstr_number . @abstr_number /batch/save', ' TLS is also problematic as a security system both from performance and vulnerabilty aspects.  Elliptic Curve Cryptography', ' Version @abstr_number . @abstr_number (the \"\"License\"\");     > SystemBarTint    * Link: @abstr_hyperlink    * License: Licensed under the Apache License', ' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND', ' XML and etc. responses. Useful for RESTful APIs.   * @abstr_hyperlink - Stackable middleware (using net/context) with easy chaining.   * @abstr_hyperlink - Minimalist net/http middleware for golang.   * @abstr_hyperlink - Lightweight middleware for net/http.   * @abstr_hyperlink - Idiomatic HTTP middleware for Golang.   * @abstr_hyperlink - Go package for easily rendering JSON', ' [Failure]] (or response: #6# [NO', \" \\\\ 'notes' : @abstr_number \", ' a light-weight', ' a micro-threaded multi-process application has instead one micro-thread per logical concurrent function and the total number of micro-threads is distributed amoungst a minimal number of processes', ' a simple Sequencer might deal with navigation:    * Sequencer     * Walk Forward     * Is there a Door?     * Open Door    This will always walk forward. If it meets a door', ' a simple micro-threaded application is limited to one CPU core. To enable full utilization of all CPU cores', ' add a new Debug Configuration', ' add some ads', \" add the sass task gulp.task('serve:before'\", ' adding persistence', ' an oven and a microwave (hot plates are not electric but gas powered).   8. Sub_metering_ @abstr_number : energy sub-metering No. @abstr_number (in watt-hour of active energy). It corresponds to the laundry room', ' and \"\"camembert\"\".  F\"', \" and a direct refutation to that 'hmph! you don't know maths\", ' and a gesture is detected that should start a drag', ' and by adding the necessary method implementations to all classes which implement that interface.  Static methods on interfaces are backported by moving the static methods to a companion class (interface name + \"\"$\"\")', ' and cpu capacity become critical', ' and dangerous', ' and distribution of messages between publishers and subscribers via queues.    One of the advantages of a message queuing service for many applications is that the service hides behind an API', ' and do       adb [-e|-d|-s device] pull /sdcard/dslv_state.txt   then simply run       python dslv.py   An image should appear that represents the DSLV in the final recorded state. Right and left keys allow stepping through the recorded drag-sort frame-by-frame; up/down keys jump @abstr_number frames. This tool has been very useful for debugging jumpy behavior while drag-scrolling.  \"', \" and enter the URI of this repository. That's the only text box to fill in on that page. On the following pages\", ' and friendships requested to the current user (well call these inverse friendships).  \"', ' and hunger. Each has a brain consisting of @abstr_number unique nodes. There are more than fifteen thousand nodes governing the behaviour of the swarm', ' and in its absence this is an \"\"acyclic\"\" graph); this prevents infinite loops.  To use the tree', ' and interprocess communications while providing much higher total performance.  Because all the cooperative micro-threads run in one process', \" and it should take one argument (it doesn't actually matter what the argument is called\", ' and it will look for the data                                   in the file passed in the property \"\"csvReportFile\"\". If you use this property', ' and parsing all the source code of all drivers is long and unpractical.   * Some implicitly declared macros (like __KERNEL__) are needed for the code to be parsed correctly. Without them lots of functions and data structures will appear as undeclared.   * A lot of the code (power management', \" and probably also needs to have some of it removed (or migrated to 'magic.verbose' or something)\", \" and start dumping checkpoints into the folder specified by checkpoint_path (default = current folder). You also have to point the train script to the VGGNet protos (see the options inside train.lua).  If you'd like to evaluate BLEU/METEOR/CIDEr scores during training in addition to validation cross entropy loss\", ' and the associated demands on memory', ' and the language automatically does the needed cloning. For ref types', ' and then run:  @abstr_code_section  And then open a browser to http://localhost: @abstr_number \"', ' and this is the actual SpriteKit class. If all you want is some sample code for SpriteKit', ' and understand AUV', ' and where theyre located? With this expanded and thoroughly revised edition', ' and writing it feels like writing HTML. A simple transform is included with React that allows converting JSX into native JavaScript for browsers to digest.  \"', ' application-driven jailer built in the spirit of fail @abstr_number ban   * @abstr_hyperlink - Go Bindings for @abstr_hyperlink ', ' are often based on a messaging or event bus that allows the various distributed components to communicate asynchronously with each other. Typically the messaging bus is some form of messaging queue service such as AMQP or ZeroMQ. The message bus supports what is commonly referred to as a publish/subscribe methodology for information exchange.  While there are many advantages to a full featured message queuing service', ' as well as parses any existing _credentials.py_ file stored in the same directory. In that case', ' because most MQ services are based on TCP/IP they tend to also use HTTP and therefore TLS/SSL for secure communications. While using HTTP provides easy integration with web based systems', ' because part of implementing OAuth requires the user to take action on the provider (Foursquare', ' both methods can be combined.  \"', ' bubble on the destination with the address and an image  @abstr_image  Turn-by-turn instructions shown in bubbles (with instructions in the default language of the phone):  @abstr_image  The same turn-by-turn instructions shown in list view:  @abstr_image  Searching for fuel stations along the route:  @abstr_image  Searching fo cinemas inside an area', ' but WITHOUT ANY WARRANTY; including but not limited to', ' but can also charge the battery via regenerative braking (negative current) during deceleration. The total energy to be computed is the NET POSITIVE energy drawn from the battery.  \"', ' but instead will query @abstr_number . @abstr_number . @abstr_number . @abstr_number on port @abstr_number and if that fails will query @abstr_number . @abstr_number . @abstr_number . @abstr_number (on @abstr_number ) to get an answer. That answer will then be given back to the original client.  When forwarding to a stub', ' but it must also have been explicitly published using the \"\"Share\"\" button in the top right corner of the Google Spreadsheets GUI.  Generally', ' but the important thing is that the line before the line to be modified reads lib:):  @abstr_code_section  You will have to modify this to look like this:  @abstr_code_section  Normally', ' but there may be cases where you\\'d like to change this. Simply set the \"\"amd\"\" option:  @abstr_code_section  Or', ' but unfortunately the formatting of these errors don\\'t make looking for it any easier. We hope to improve that in other ways (see @abstr_hyperlink )  \"', ' but want to store values that are specific for a single host. For example the public IP-address of the host or the IP-address on the tenant network.  To do that you need to specify a unique value for that host with -local. A good unique value for that would be an UUID which you can generate with uuidgen for instance.  That unique value is used as a path in etcd to store the values separately from the normal values. It is still stored in the etcd backend so a restart of SkyDNS with the same unique value will give it access to the old data.  In the example here', ' but with SystemJS module definitions. @abstr_number . Browser evaluates ES @abstr_number code generated by previous step. \"', ' but you can also directly access the raw data.  Now go ahead and @abstr_hyperlink ', ' buying or clicking all of them. Here are a few examples of what preference sets could look like:  @abstr_code_section  From these preference sets we compute a two-dimensional array', ' c_height);     template->code = codeNumber;     template->size = codeSize;     CRCodeImageTemplateStorageAddNewTemplate(codeImageTemplateStorage', ' check out @abstr_hyperlink .  \"', ' commas delimit coordinates; semicolons delimit positions| |a_m_kon |double | @abstr_number |s^(- @abstr_number ) |active motor on rate| |a_m_koff |double | @abstr_number |s^(- @abstr_number ) |active motor off rate| |a_m_kend |double | @abstr_number |s^(- @abstr_number ) |active motor off rate at filament end| |a_motor_stiffness |double | @abstr_number |pN/um |active motor spring stiffness| |a_motor_length |double | @abstr_number . @abstr_number |um |length of motor| |a_m_stall |double | @abstr_number |pN |stall force of motors| |a_m_break |double | @abstr_number |pN |rupture force of motors| |a_m_bind |double | @abstr_number . @abstr_number |pN_um |binding energy| |a_motor_v |double | @abstr_number |um/s |velocity along filaments towards barbed end when attached| |motor_intersect_flag |boolean|false | |if true', ' configure', ' context switching', ' create a directory ext_lib within your project and populate it with symlinks to your libraries. Then set up the .tern-project something like this:  @abstr_code_section  Then', ' directing it to said directory. Then the app will be launchable from the app screen and the extensions screen.  To distribute the app', ' do \"\"Project -> Open/Import Project...\"\" and select the root Makefile of your Linux kernel. When prompted for the type of the project', ' drop me a line! \"', ' each slide will be defined by default with an element containing the slide class: @abstr_code_section You can see a fully working example of the HTML structure in the [demoPage.html` file](https://github.com/alvarotrigo/fullPage.js/blob/master/examples/demoPage.html).  \"', ' either manually add -lprofile to the linker command line', ' encryption and the CurveCP handshake for secure bootstrap.  The queue management and micro-threaded application support is provided by Ioflo. RAET is a complementary project to Ioflo in that RAET enables multiple Ioflo applications to work together over a network as part of a distributed application.  The primary use case and motivating problem that resulted in the development of RAET was the need to enable SaltStack to scale better. SaltStack is a remote execution and configuration management platform written in Python. SaltStack uses ZeroMQ ( @abstr_number MQ) as its message bus or message queuing service. ZeroMQ is based on TCP/IP so suffers from the aforementioned latency and non-asynchronicity issues of TCP/IP based architectures. Moreover because ZeroMQ integrates queue management and transport in a monolithic way with special \"\"sockets\"\"', ' etc. More information and instructions for subscribing are at @abstr_hyperlink .  \"', ' etc. etc.  \"', ' evtList){}  Callback function called when user click in a day', ' execute custom python script', ' first columns and then rows are binded to a single tidy dataset.  With the help of dlpyr package data are grouped by subject and activity and then averaged. The result is saved in the working directory as summary.txt  \"', ' first ensure you have @abstr_hyperlink and then run the following command:       pear install PHP_CodeSniffer   If you prefer using @abstr_hyperlink you can easily install PHP_CodeSniffer system-wide with the following command:       composer global require \"\"squizlabs/php_codesniffer=\"\"   Make sure you have ~/.composer/vendor/bin/ in your PATH.  Or alternatively', ' for easiest transition from a \"\"Vanilla\"\" server to one enhanced by StarryPy', ' function(err', ' graphical tool for dealing with streams of data.   * @abstr_hyperlink - Vectormath for Go', ' hereby commit to the neveragain.tech pledge. Please stand with me and hold me to it. #neveragaintech\"\" * Post \"\"I', ' high performance messaging system for microservices', \" how do the things in parentheses _become_ true or false?  JavaScript lets us compare things. Most of these comparisons come straight from math: we can ask if something is less than something else (enter these in your console!):  @abstr_code_section  We can ask if something is greater than something else:  @abstr_code_section  We can even ask if something is less-than-or-equal-to something else:  @abstr_code_section  or greater-than-or-equal-to something:  @abstr_code_section  How do we test if something is _exactly_ equal to something else? We know that we can't just use =\", ' iOS and Windows). The intelxdk.config.additions.xml file can be used to include options that control your _packaged Cordova web app_ builds. For example', ' if a \"\"must-have\"\" touch pattern arises', ' if we pass utter nonsense to parseInt()? Go ahead and try it in the console  something like  @abstr_code_section  What did it return? NaN? What is that?  NaN stands for \"\"not a number\"\"  pretty handy', ' ignored if embedCSS is false   * startOpen: false do not immediately truncate', ' import the cleanup', ' including without limitation the rights to use', ' including without limitation the rights_ _to use', ' indicating that the authorization process was successful.  \"', ' infact due to a logic error in previous code the cookies were not being used anyway. Now Django Select @abstr_number does not use cookies etc.   * Few more bugs fixed in heav_data.js.   * Now production code will use minimized versions of js and css files.   * Codes added in setup.py to automate the task of minimizing js and css files', ' injection and in class annotations', ' is a tuned transport protocol that adds reliability to UDP/IP without sacrificing latency and scalability. A transactioned protocol', ' is much more appropriate for providing reliablity to asynchronous event transport than a streaming protocol.  Morover', ' it can become problematic for high performant systems Furthermore', ' it ends up owned by root (but in your home directory).  Check that you own your own .npm directory ls -ld ~/.npm  If it is owned by root', ' it evaluates the left-hand side of the colon; otherwise it evaluates the right-hand side of the colon.  Syntax:  @abstr_code_section    * Define a function ternaryTeenager that accepts age as a parameter. The body of the function should use the ternary operator to return \"\"You are a teenager\"\" if age is between @abstr_number - @abstr_number and returns \"\"You are not a teenager\"\" if the age is anything else.    Top tip : In order for the function to actually return the evaluation of the ternary operator', ' it is much better suited to many small asynchronous messages and scales better. The drawback of bare UDP/IP is that it is not reliable. What is needed', ' it is the exception. No other TCP/IP stack available for the Amiga robustly supports a similar feature. If the TCP/IP stack supports this feature', ' it means you are not using the @abstr_number . @abstr_number jre. Type java -version to check. You may need to close and reopen your terminal if you installed @abstr_number . @abstr_number recently.  \"', ' it now has all the functions.  Implementation inheritance is used instead of subtyping to make it easier to understand which functions operate on any given \"\"subject\"\". If you have an element and you need to use a function defined in Node', ' it should return \"\"You are a grownup\"\" Top tip : Remember', ' it will upgrade. - Likewise', \" it's actually ABCBAD\", ' it\\'s an important skill to have!  \"', \" it's in gcc:lib/gcc/ppc-amigaos/*compiler-version*/specs. Most likely\", \" jumps to the symbol's declaration. For C/C++/Objective-C\", ' just call .readmore() on the element containing your block of text and Readmore.js takes care of the rest. Readmore.js plays well in a responsive environment', ' just go to your project folder and run:          github_changelog_generator     * Or', ' just take forever (actually until a timeout is reached). You need to keep this in mind in order to not block your main or UI thread.  Implications of this design choice  Pros:    * A blocking API is much easier to use and understand    Cons:    * You just might accidentally block your UI thread   * You cannot issue thousands of EWS requests asynchronously simply because you cannot spawn thousands of threads in your process. You may need additional effort here    \"', ' keys and NSEC @abstr_number records returned. Authenticated denial of existence is implemented using NSEC @abstr_number white lies', ' libqs.c and the yara signatures except where noted are Copyright @abstr_number Tyler McLellan and Tylabs.  See included Mozilla Public License Version @abstr_number . @abstr_number for licensing information. \"', ' like AMQP', ' make sure that the instances are being launched with a security group that allows SSH access.  \"', ' memory', ' network', ' network) in distributed concurrent event driven applications is to use something called micro-threads. A microthread is typically an in-language feature that allows logical concurrency with no more overhead than a function call. Micro threading uses cooperative multi-tasking instead of threads and/or processes and avoids many of the complexities of resource contention', ' no matter the direction. Because we dont care who requested the friendship once its approved', ' no more than the number of cpu cores. This optimizes the use of the cpu power while minimizes the overhead of process context switching.  An example of a framework that uses this type of micro-threaded but multi-process architecture is Erlang. Indeed', ' notebook', ' nothing is sent to Gmail and all messages currently stored on your device are simply marked \"\"backed up\"\". This option is handy if you previously uninstalled SMS Backup+ and do not want to send your messages again to Gmail. Please note that any messages arrived after you last uninstalled SMS Backup and this initial backup won\\'t ever be backed up to Gmail.  \"', ' of course', ' on average across all \"', ' on the other hand', ' one for front side only', ' one might ask', ' one of the best ways to manage and fine tune processor resources (cpu', ' one of the disadvantagesis the inability to manage performance at scale.  A message queuing service performs two distinct but complementary functions.    * The first is asynchronous transport of messages over the internet.   * The second is message queue management', ' or because they are tech geeks. But these data remain under-utilized both because the raw data are hard to obtain and there is a lack of statistical methods and software for processing and interpreting the data.  This assignment makes use of data from a personal activity monitoring device. This device collects data at @abstr_number minute intervals through out the day. The data consists of two months of data from an anonymous individual collected during the months of October and November', ' or both   * Added \"\"returnName\"\" setting which makes the widget return a name instead of HEX value when possible   * Removed many unnecessary features   * Removed dependency on images and made the colour picker completely CSS     \"', ' or if you are usually handling many temporary \"\"to be in a github pull request\"\" branches', ' or modify the specs file as follows. Find the lines that look like this (it may actually differ slightly from your specs file', ' otherwise SERVFAIL is returned.  This also works for IPv @abstr_number addresses', ' post an issue in @abstr_hyperlink .  If you think there is an issue with osmdroid', ' preface it by @abstr_number . These numbers correspond to the projections in the projectionEnum declaration in elevr-player.js.  If you want to add your picture to the drop-down', ' production)', ' provides increases in security with lower performance requirements relative to over other approaches. LibSodium provides an open source Elliptic Curve Cryptographic library with support for both authentication and encryption. The CurveCP protocol is based on LibSodium and provides a handshake protocol for bootstrapping secure network exchanges of information.  Finally', ' push your changes to your clone and submit a pull request; instruc\n\n*** WARNING: max output size exceeded, skipping output. ***\n\nto /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\nReady for classify. Run test_classifier with model of your choice.\n  file_id section_id                                                url  \\\n0     102       1228  https://github.com/trujunzhang/ruby2-rails4-bo...   \n1     102       1229  https://github.com/trujunzhang/ruby2-rails4-bo...   \n2     102       1230  https://github.com/trujunzhang/ruby2-rails4-bo...   \n3     102       1231  https://github.com/trujunzhang/ruby2-rails4-bo...   \n4     102       1232  https://github.com/trujunzhang/ruby2-rails4-bo...   \n\n           heading_text                              content_text_w_o_tags  \\\n0    Rails Starter App   @abstr_hyperlink @abstr_hyperlink @abstr_hyper...   \n1        Thread safety   We assume that this application is thread safe...   \n2  Heroku Platform API   This application supports fast setup and deplo...   \n3  Recommended add-ons   Heroku's @abstr_hyperlink recommends the use o...   \n4          Secrets.yml   Rails @abstr_number . @abstr_number . @abstr_n...   \n\n                     abstracted_heading_plus_content section_code  \n0  Rails Starter App  @abstr_hyperlink @abstr_hyp...          1,3  \n1  Thread safety  We assume that this application...            3  \n2  Heroku Platform API  This application supports...          3,6  \n3  Recommended add-ons  Heroku's @abstr_hyperlink...            3  \n4  Secrets.yml  Rails @abstr_number . @abstr_numb...            3  \n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["/databricks/python/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:860: UserWarning: unknown class(es) ['                [\"\"[a-f @abstr_number - @abstr_number ]+\"\"', '         \"\"mail\"\" : \"\"sabre+ @abstr_number @tut.by\"\"         \"\"role\"\" : \"\"Store Owner\"\"       }        -- response --       Set-Cookie:  SESSe @abstr_number a @abstr_number a @abstr_number c @abstr_number a @abstr_number c @abstr_number b @abstr_number cb @abstr_number f @abstr_number =E @abstr_number juSPMd @abstr_number fUOg @abstr_number j_esS @abstr_number G @abstr_number MwU @abstr_number jodrDpBjl @abstr_number KHfli @abstr_number ; expires=Sat', \"         forro = require('forro')\", '         location: \"\"YOUR_LOCATION\"\"', '     \"\"express\"\": \"\"^ @abstr_number . @abstr_number . @abstr_number \"\"', '     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND', '     to deal in the Software without restriction', '   * @abstr_hyperlink ', '   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND', '   * an @abstr_hyperlink -based completion engine for C#', ' \"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number : @abstr_number ', ' \"\"alternate names\"\"', ' \"\"group\"\": \"\"g @abstr_number \"\"}     /skydns/local/domain/subdom/     /skydns/local/domain/subdom/c - {\"\"host\"\": \"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number \"\"', ' \"\"hello there\"\". The dialog will take the incoming message and find the Best Match in the list of strings', ' \"\"key @abstr_number \"\": { \"\"dataA\"\": \"\"valueA\"\"', ' \"\"nameservers\"\": [\"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number : @abstr_number \"\"', ' \"\"trouble\"\"', ' \"\"website\"\": \"\"\"\"', ' \"\"\"\"', \" 'utf- @abstr_number '\", ' --debug DEBUG           Enable debug mode   The application also takes the regular parameters for APIC address', ' --input INPUT           Input file       -d DEBUG', ' --login LOGIN           APIC login ID.       -p PASSWORD', ' --outfile FILE       Filename and base module name of the generated parser        -t', ' --password PASSWORD  APIC login password.       -i INPUT', ' --url URL                 APIC IP address.       -l LOGIN', ' .offsetParent()', ' 2', ' 3', ' 4', ' @abstr_code_section    * See below for other simulation configuration options that you can set from the command line or from a configuration file    * Once your simulation has completed', ' @abstr_number ', \" @abstr_number )) @abstr_code_section evtList = [ { date: new Date(' @abstr_number '\", ' @abstr_number ); function.Invoke(destination); int result = function.GetInt(\"\"e_result\"\"); @abstr_code_section C# using (SapRfcConnection conn = new PlainSapRfcConnection(\"\"TST\"\")) { var result = conn.ExecuteFunction(\"\"Z_SSRT_SUM\"\"', ' @abstr_number milliseconds). For complex problems', ' @abstr_number }. For this to work we create the hosts named x{ @abstr_number ', ' @abstr_number }.db.skydns.local in etcd:       curl -XPUT http:// @abstr_number . @abstr_number . @abstr_number . @abstr_number : @abstr_number /v @abstr_number /keys/skydns/local/skydns/db/x @abstr_number  -d \\\\         value=\\'{\"\"host\"\":\"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number \"\"}\\'     curl -XPUT http:// @abstr_number . @abstr_number . @abstr_number . @abstr_number : @abstr_number /v @abstr_number /keys/skydns/local/skydns/db/x @abstr_number  -d \\\\         value=\\'{\"\"host\"\": \"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number \"\"\\'}     curl -XPUT http:// @abstr_number . @abstr_number . @abstr_number . @abstr_number : @abstr_number /v @abstr_number /keys/skydns/local/skydns/db/x @abstr_number  -d \\\\         value=\\'{\"\"host\"\": \"\" @abstr_number . @abstr_number . @abstr_number . @abstr_number \"\"\\'}   Now the name db.skydns.local is the \"\"load balanced\"\" name for the database', ' BUT NOT LIMITED TO', ' Debian @abstr_number and CentOS @abstr_number / @abstr_number     \"', ' EXPRESS OR IMPLIED', ' Enrico', ' Estates', ' I take this methodology to the world of node.js. This time', ' Inc. @abstr_number Montague ST STE @abstr_number BROOKLYN', ' MB) bar.SetUnits(pb.U_BYTES)  // and start bar.Start() @abstr_code_section go // create and start bar bar := pb.New(myDataLen).SetUnits(pb.U_BYTES) bar.Start()  // my io.Reader r := myReader  // my io.Writer w := myWriter  // create proxy reader reader := bar.NewProxyReader(r)  // and copy from pb reader io.Copy(w', ' Main Estate   The UDP channel is a Road\"\"   * The members of a Road are Estates (as in real estate lots that front the road)   * Each Estate has a unique UDP Host Port address ha ', ' NSErrorFailingURLKey=https://api.leancloud.cn/ @abstr_number . @abstr_number /batch/save', ' TLS is also problematic as a security system both from performance and vulnerabilty aspects.  Elliptic Curve Cryptography', ' Version @abstr_number . @abstr_number (the \"\"License\"\");     > SystemBarTint    * Link: @abstr_hyperlink    * License: Licensed under the Apache License', ' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND', ' XML and etc. responses. Useful for RESTful APIs.   * @abstr_hyperlink - Stackable middleware (using net/context) with easy chaining.   * @abstr_hyperlink - Minimalist net/http middleware for golang.   * @abstr_hyperlink - Lightweight middleware for net/http.   * @abstr_hyperlink - Idiomatic HTTP middleware for Golang.   * @abstr_hyperlink - Go package for easily rendering JSON', ' [Failure]] (or response: #6# [NO', \" \\\\ 'notes' : @abstr_number \", ' a light-weight', ' a micro-threaded multi-process application has instead one micro-thread per logical concurrent function and the total number of micro-threads is distributed amoungst a minimal number of processes', ' a simple Sequencer might deal with navigation:    * Sequencer     * Walk Forward     * Is there a Door?     * Open Door    This will always walk forward. If it meets a door', ' a simple micro-threaded application is limited to one CPU core. To enable full utilization of all CPU cores', ' add a new Debug Configuration', ' add some ads', \" add the sass task gulp.task('serve:before'\", ' adding persistence', ' an oven and a microwave (hot plates are not electric but gas powered).   8. Sub_metering_ @abstr_number : energy sub-metering No. @abstr_number (in watt-hour of active energy). It corresponds to the laundry room', ' and \"\"camembert\"\".  F\"', \" and a direct refutation to that 'hmph! you don't know maths\", ' and a gesture is detected that should start a drag', ' and by adding the necessary method implementations to all classes which implement that interface.  Static methods on interfaces are backported by moving the static methods to a companion class (interface name + \"\"$\"\")', ' and cpu capacity become critical', ' and dangerous', ' and distribution of messages between publishers and subscribers via queues.    One of the advantages of a message queuing service for many applications is that the service hides behind an API', ' and do       adb [-e|-d|-s device] pull /sdcard/dslv_state.txt   then simply run       python dslv.py   An image should appear that represents the DSLV in the final recorded state. Right and left keys allow stepping through the recorded drag-sort frame-by-frame; up/down keys jump @abstr_number frames. This tool has been very useful for debugging jumpy behavior while drag-scrolling.  \"', \" and enter the URI of this repository. That's the only text box to fill in on that page. On the following pages\", ' and friendships requested to the current user (well call these inverse friendships).  \"', ' and hunger. Each has a brain consisting of @abstr_number unique nodes. There are more than fifteen thousand nodes governing the behaviour of the swarm', ' and in its absence this is an \"\"acyclic\"\" graph); this prevents infinite loops.  To use the tree', ' and interprocess communications while providing much higher total performance.  Because all the cooperative micro-threads run in one process', \" and it should take one argument (it doesn't actually matter what the argument is called\", ' and it will look for the data                                   in the file passed in the property \"\"csvReportFile\"\". If you use this property', ' and parsing all the source code of all drivers is long and unpractical.   * Some implicitly declared macros (like __KERNEL__) are needed for the code to be parsed correctly. Without them lots of functions and data structures will appear as undeclared.   * A lot of the code (power management', \" and probably also needs to have some of it removed (or migrated to 'magic.verbose' or something)\", \" and start dumping checkpoints into the folder specified by checkpoint_path (default = current folder). You also have to point the train script to the VGGNet protos (see the options inside train.lua).  If you'd like to evaluate BLEU/METEOR/CIDEr scores during training in addition to validation cross entropy loss\", ' and the associated demands on memory', ' and the language automatically does the needed cloning. For ref types', ' and then run:  @abstr_code_section  And then open a browser to http://localhost: @abstr_number \"', ' and this is the actual SpriteKit class. If all you want is some sample code for SpriteKit', ' and understand AUV', ' and where theyre located? With this expanded and thoroughly revised edition', ' and writing it feels like writing HTML. A simple transform is included with React that allows converting JSX into native JavaScript for browsers to digest.  \"', ' application-driven jailer built in the spirit of fail @abstr_number ban   * @abstr_hyperlink - Go Bindings for @abstr_hyperlink ', ' are often based on a messaging or event bus that allows the various distributed components to communicate asynchronously with each other. Typically the messaging bus is some form of messaging queue service such as AMQP or ZeroMQ. The message bus supports what is commonly referred to as a publish/subscribe methodology for information exchange.  While there are many advantages to a full featured message queuing service', ' as well as parses any existing _credentials.py_ file stored in the same directory. In that case', ' because most MQ services are based on TCP/IP they tend to also use HTTP and therefore TLS/SSL for secure communications. While using HTTP provides easy integration with web based systems', ' because part of implementing OAuth requires the user to take action on the provider (Foursquare', ' both methods can be combined.  \"', ' bubble on the destination with the address and an image  @abstr_image  Turn-by-turn instructions shown in bubbles (with instructions in the default language of the phone):  @abstr_image  The same turn-by-turn instructions shown in list view:  @abstr_image  Searching for fuel stations along the route:  @abstr_image  Searching fo cinemas inside an area', ' but WITHOUT ANY WARRANTY; including but not limited to', ' but can also charge the battery via regenerative braking (negative current) during deceleration. The total energy to be computed is the NET POSITIVE energy drawn from the battery.  \"', ' but instead will query @abstr_number . @abstr_number . @abstr_number . @abstr_number on port @abstr_number and if that fails will query @abstr_number . @abstr_number . @abstr_number . @abstr_number (on @abstr_number ) to get an answer. That answer will then be given back to the original client.  When forwarding to a stub', ' but it must also have been explicitly published using the \"\"Share\"\" button in the top right corner of the Google Spreadsheets GUI.  Generally', ' but the important thing is that the line before the line to be modified reads lib:):  @abstr_code_section  You will have to modify this to look like this:  @abstr_code_section  Normally', ' but there may be cases where you\\'d like to change this. Simply set the \"\"amd\"\" option:  @abstr_code_section  Or', ' but unfortunately the formatting of these errors don\\'t make looking for it any easier. We hope to improve that in other ways (see @abstr_hyperlink )  \"', ' but want to store values that are specific for a single host. For example the public IP-address of the host or the IP-address on the tenant network.  To do that you need to specify a unique value for that host with -local. A good unique value for that would be an UUID which you can generate with uuidgen for instance.  That unique value is used as a path in etcd to store the values separately from the normal values. It is still stored in the etcd backend so a restart of SkyDNS with the same unique value will give it access to the old data.  In the example here', ' but with SystemJS module definitions. @abstr_number . Browser evaluates ES @abstr_number code generated by previous step. \"', ' but you can also directly access the raw data.  Now go ahead and @abstr_hyperlink ', ' buying or clicking all of them. Here are a few examples of what preference sets could look like:  @abstr_code_section  From these preference sets we compute a two-dimensional array', ' c_height);     template->code = codeNumber;     template->size = codeSize;     CRCodeImageTemplateStorageAddNewTemplate(codeImageTemplateStorage', ' check out @abstr_hyperlink .  \"', ' commas delimit coordinates; semicolons delimit positions| |a_m_kon |double | @abstr_number |s^(- @abstr_number ) |active motor on rate| |a_m_koff |double | @abstr_number |s^(- @abstr_number ) |active motor off rate| |a_m_kend |double | @abstr_number |s^(- @abstr_number ) |active motor off rate at filament end| |a_motor_stiffness |double | @abstr_number |pN/um |active motor spring stiffness| |a_motor_length |double | @abstr_number . @abstr_number |um |length of motor| |a_m_stall |double | @abstr_number |pN |stall force of motors| |a_m_break |double | @abstr_number |pN |rupture force of motors| |a_m_bind |double | @abstr_number . @abstr_number |pN_um |binding energy| |a_motor_v |double | @abstr_number |um/s |velocity along filaments towards barbed end when attached| |motor_intersect_flag |boolean|false | |if true', ' configure', ' context switching', ' create a directory ext_lib within your project and populate it with symlinks to your libraries. Then set up the .tern-project something like this:  @abstr_code_section  Then', ' directing it to said directory. Then the app will be launchable from the app screen and the extensions screen.  To distribute the app', ' do \"\"Project -> Open/Import Project...\"\" and select the root Makefile of your Linux kernel. When prompted for the type of the project', ' drop me a line! \"', ' each slide will be defined by default with an element containing the slide class: @abstr_code_section You can see a fully working example of the HTML structure in the [demoPage.html` file](https://github.com/alvarotrigo/fullPage.js/blob/master/examples/demoPage.html).  \"', ' either manually add -lprofile to the linker command line', ' encryption and the CurveCP handshake for secure bootstrap.  The queue management and micro-threaded application support is provided by Ioflo. RAET is a complementary project to Ioflo in that RAET enables multiple Ioflo applications to work together over a network as part of a distributed application.  The primary use case and motivating problem that resulted in the development of RAET was the need to enable SaltStack to scale better. SaltStack is a remote execution and configuration management platform written in Python. SaltStack uses ZeroMQ ( @abstr_number MQ) as its message bus or message queuing service. ZeroMQ is based on TCP/IP so suffers from the aforementioned latency and non-asynchronicity issues of TCP/IP based architectures. Moreover because ZeroMQ integrates queue management and transport in a monolithic way with special \"\"sockets\"\"', ' etc. More information and instructions for subscribing are at @abstr_hyperlink .  \"', ' etc. etc.  \"', ' evtList){}  Callback function called when user click in a day', ' execute custom python script', ' first columns and then rows are binded to a single tidy dataset.  With the help of dlpyr package data are grouped by subject and activity and then averaged. The result is saved in the working directory as summary.txt  \"', ' first ensure you have @abstr_hyperlink and then run the following command:       pear install PHP_CodeSniffer   If you prefer using @abstr_hyperlink you can easily install PHP_CodeSniffer system-wide with the following command:       composer global require \"\"squizlabs/php_codesniffer=\"\"   Make sure you have ~/.composer/vendor/bin/ in your PATH.  Or alternatively', ' for easiest transition from a \"\"Vanilla\"\" server to one enhanced by StarryPy', ' function(err', ' graphical tool for dealing with streams of data.   * @abstr_hyperlink - Vectormath for Go', ' hereby commit to the neveragain.tech pledge. Please stand with me and hold me to it. #neveragaintech\"\" * Post \"\"I', ' high performance messaging system for microservices', \" how do the things in parentheses _become_ true or false?  JavaScript lets us compare things. Most of these comparisons come straight from math: we can ask if something is less than something else (enter these in your console!):  @abstr_code_section  We can ask if something is greater than something else:  @abstr_code_section  We can even ask if something is less-than-or-equal-to something else:  @abstr_code_section  or greater-than-or-equal-to something:  @abstr_code_section  How do we test if something is _exactly_ equal to something else? We know that we can't just use =\", ' iOS and Windows). The intelxdk.config.additions.xml file can be used to include options that control your _packaged Cordova web app_ builds. For example', ' if a \"\"must-have\"\" touch pattern arises', ' if we pass utter nonsense to parseInt()? Go ahead and try it in the console  something like  @abstr_code_section  What did it return? NaN? What is that?  NaN stands for \"\"not a number\"\"  pretty handy', ' ignored if embedCSS is false   * startOpen: false do not immediately truncate', ' import the cleanup', ' including without limitation the rights to use', ' including without limitation the rights_ _to use', ' indicating that the authorization process was successful.  \"', ' infact due to a logic error in previous code the cookies were not being used anyway. Now Django Select @abstr_number does not use cookies etc.   * Few more bugs fixed in heav_data.js.   * Now production code will use minimized versions of js and css files.   * Codes added in setup.py to automate the task of minimizing js and css files', ' injection and in class annotations', ' is a tuned transport protocol that adds reliability to UDP/IP without sacrificing latency and scalability. A transactioned protocol', ' is much more appropriate for providing reliablity to asynchronous event transport than a streaming protocol.  Morover', ' it can become problematic for high performant systems Furthermore', ' it ends up owned by root (but in your home directory).  Check that you own your own .npm directory ls -ld ~/.npm  If it is owned by root', ' it evaluates the left-hand side of the colon; otherwise it evaluates the right-hand side of the colon.  Syntax:  @abstr_code_section    * Define a function ternaryTeenager that accepts age as a parameter. The body of the function should use the ternary operator to return \"\"You are a teenager\"\" if age is between @abstr_number - @abstr_number and returns \"\"You are not a teenager\"\" if the age is anything else.    Top tip : In order for the function to actually return the evaluation of the ternary operator', ' it is much better suited to many small asynchronous messages and scales better. The drawback of bare UDP/IP is that it is not reliable. What is needed', ' it is the exception. No other TCP/IP stack available for the Amiga robustly supports a similar feature. If the TCP/IP stack supports this feature', ' it means you are not using the @abstr_number . @abstr_number jre. Type java -version to check. You may need to close and reopen your terminal if you installed @abstr_number . @abstr_number recently.  \"', ' it now has all the functions.  Implementation inheritance is used instead of subtyping to make it easier to understand which functions operate on any given \"\"subject\"\". If you have an element and you need to use a function defined in Node', ' it should return \"\"You are a grownup\"\" Top tip : Remember', ' it will upgrade. - Likewise', \" it's actually ABCBAD\", ' it\\'s an important skill to have!  \"', \" it's in gcc:lib/gcc/ppc-amigaos/*compiler-version*/specs. Most likely\", \" jumps to the symbol's declaration. For C/C++/Objective-C\", ' just call .readmore() on the element containing your block of text and Readmore.js takes care of the rest. Readmore.js plays well in a responsive environment', ' just go to your project folder and run:          github_changelog_generator     * Or', ' just take forever (actually until a timeout is reached). You need to keep this in mind in order to not block your main or UI thread.  Implications of this design choice  Pros:    * A blocking API is much easier to use and understand    Cons:    * You just might accidentally block your UI thread   * You cannot issue thousands of EWS requests asynchronously simply because you cannot spawn thousands of threads in your process. You may need additional effort here    \"', ' keys and NSEC @abstr_number records returned. Authenticated denial of existence is implemented using NSEC @abstr_number white lies', ' libqs.c and the yara signatures except where noted are Copyright @abstr_number Tyler McLellan and Tylabs.  See included Mozilla Public License Version @abstr_number . @abstr_number for licensing information. \"', ' like AMQP', ' make sure that the instances are being launched with a security group that allows SSH access.  \"', ' memory', ' network', ' network) in distributed concurrent event driven applications is to use something called micro-threads. A microthread is typically an in-language feature that allows logical concurrency with no more overhead than a function call. Micro threading uses cooperative multi-tasking instead of threads and/or processes and avoids many of the complexities of resource contention', ' no matter the direction. Because we dont care who requested the friendship once its approved', ' no more than the number of cpu cores. This optimizes the use of the cpu power while minimizes the overhead of process context switching.  An example of a framework that uses this type of micro-threaded but multi-process architecture is Erlang. Indeed', ' notebook', ' nothing is sent to Gmail and all messages currently stored on your device are simply marked \"\"backed up\"\". This option is handy if you previously uninstalled SMS Backup+ and do not want to send your messages again to Gmail. Please note that any messages arrived after you last uninstalled SMS Backup and this initial backup won\\'t ever be backed up to Gmail.  \"', ' of course', ' on average across all \"', ' on the other hand', ' one for front side only', ' one might ask', ' one of the best ways to manage and fine tune processor resources (cpu', ' one of the disadvantagesis the inability to manage performance at scale.  A message queuing service performs two distinct but complementary functions.    * The first is asynchronous transport of messages over the internet.   * The second is message queue management', ' or because they are tech geeks. But these data remain under-utilized both because the raw data are hard to obtain and there is a lack of statistical methods and software for processing and interpreting the data.  This assignment makes use of data from a personal activity monitoring device. This device collects data at @abstr_number minute intervals through out the day. The data consists of two months of data from an anonymous individual collected during the months of October and November', ' or both   * Added \"\"returnName\"\" setting which makes the widget return a name instead of HEX value when possible   * Removed many unnecessary features   * Removed dependency on images and made the colour picker completely CSS     \"', ' or if you are usually handling many temporary \"\"to be in a github pull request\"\" branches', ' or modify the specs file as follows. Find the lines that look like this (it may actually differ slightly from your specs file', ' otherwise SERVFAIL is returned.  This also works for IPv @abstr_number addresses', ' post an issue in @abstr_hyperlink .  If you think there is an issue with osmdroid', ' preface it by @abstr_number . These numbers correspond to the projections in the projectionEnum declaration in elevr-player.js.  If you want to add your picture to the drop-down', ' production)', ' provides increases in security with lower performance requirements relative to over other approaches. LibSodium provides an open source Elliptic Curve Cryptographic library with support for both authentication and encryption. The CurveCP protocol is based on LibSodium and provides a handshake protocol for bootstrapping secure network exchanges of information.  Finally', ' push your changes to your clone and submit a pull request; instruc\n\n*** WARNING: max output size exceeded, skipping output. ***\n\nto /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[nltk_data] Downloading package words to /root/nltk_data...\n[nltk_data]   Package words is already up-to-date!\nReady for classify. Run test_classifier with model of your choice.\n  file_id section_id                                                url  \\\n0     102       1228  https://github.com/trujunzhang/ruby2-rails4-bo...   \n1     102       1229  https://github.com/trujunzhang/ruby2-rails4-bo...   \n2     102       1230  https://github.com/trujunzhang/ruby2-rails4-bo...   \n3     102       1231  https://github.com/trujunzhang/ruby2-rails4-bo...   \n4     102       1232  https://github.com/trujunzhang/ruby2-rails4-bo...   \n\n           heading_text                              content_text_w_o_tags  \\\n0    Rails Starter App   @abstr_hyperlink @abstr_hyperlink @abstr_hyper...   \n1        Thread safety   We assume that this application is thread safe...   \n2  Heroku Platform API   This application supports fast setup and deplo...   \n3  Recommended add-ons   Heroku's @abstr_hyperlink recommends the use o...   \n4          Secrets.yml   Rails @abstr_number . @abstr_number . @abstr_n...   \n\n                     abstracted_heading_plus_content section_code  \n0  Rails Starter App  @abstr_hyperlink @abstr_hyp...          1,3  \n1  Thread safety  We assume that this application...            3  \n2  Heroku Platform API  This application supports...          3,6  \n3  Recommended add-ons  Heroku's @abstr_hyperlink...            3  \n4  Secrets.yml  Rails @abstr_number . @abstr_numb...            3  \n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["starter.test_classifier(RandomForestClassifier())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"25547856-1613-4495-9fc4-ba38b7a3d38e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Running experiment for RandomForestClassifier()\nGetting per-class scores\nComputing overall results\n              precision    recall  f1-score   support\n\n           0      0.513     0.744     0.607       422\n           1      0.748     0.400     0.521       652\n           2      0.814     0.857     0.835      2234\n           3      0.882     0.444     0.590       151\n           4      0.902     0.540     0.676       274\n           5      0.720     0.502     0.592       811\n           6      0.919     0.528     0.671       108\n           7      0.119     0.623     0.201        61\n\n   micro avg      0.713     0.680     0.696      4713\n   macro avg      0.702     0.580     0.587      4713\nweighted avg      0.763     0.680     0.700      4713\n samples avg      0.655     0.664     0.651      4713\n\nf1_weighted : 0.6308957564173909\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Running experiment for RandomForestClassifier()\nGetting per-class scores\nComputing overall results\n              precision    recall  f1-score   support\n\n           0      0.513     0.744     0.607       422\n           1      0.748     0.400     0.521       652\n           2      0.814     0.857     0.835      2234\n           3      0.882     0.444     0.590       151\n           4      0.902     0.540     0.676       274\n           5      0.720     0.502     0.592       811\n           6      0.919     0.528     0.671       108\n           7      0.119     0.623     0.201        61\n\n   micro avg      0.713     0.680     0.696      4713\n   macro avg      0.702     0.580     0.587      4713\nweighted avg      0.763     0.680     0.700      4713\n samples avg      0.655     0.664     0.651      4713\n\nf1_weighted : 0.6308957564173909\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["starter.test_classifier(LinearSVC())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"424879fb-c24f-4ee1-be06-f18ecbc5cbfb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Running experiment for LinearSVC()\nGetting per-class scores\nComputing overall results\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 228, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr',\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4060, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 228, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr',\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4060, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 228, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr',\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 228, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr',\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 228, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr',\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 228, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr',\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 228, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr',\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 228, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr',\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 228, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr',\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n              precision    recall  f1-score   support\n\n           0      0.537     0.756     0.628       422\n           1      0.554     0.541     0.548       652\n           2      0.809     0.849     0.828      2234\n           3      0.682     0.682     0.682       151\n           4      0.785     0.708     0.745       274\n           5      0.597     0.605     0.601       811\n           6      0.857     0.833     0.845       108\n           7      0.155     0.672     0.252        61\n\n   micro avg      0.675     0.740     0.706      4713\n   macro avg      0.622     0.706     0.641      4713\nweighted avg      0.700     0.740     0.716      4713\n samples avg      0.675     0.717     0.682      4713\n\nf1_weighted : nan\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 228, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr',\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Running experiment for LinearSVC()\nGetting per-class scores\nComputing overall results\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 228, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr',\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4060, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 228, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr',\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4060, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 228, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr',\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 228, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr',\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 228, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr',\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 228, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr',\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 228, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr',\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 228, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr',\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 228, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr',\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n              precision    recall  f1-score   support\n\n           0      0.537     0.756     0.628       422\n           1      0.554     0.541     0.548       652\n           2      0.809     0.849     0.828      2234\n           3      0.682     0.682     0.682       151\n           4      0.785     0.708     0.745       274\n           5      0.597     0.605     0.601       811\n           6      0.857     0.833     0.845       108\n           7      0.155     0.672     0.252        61\n\n   micro avg      0.675     0.740     0.706      4713\n   macro avg      0.622     0.706     0.641      4713\nweighted avg      0.700     0.740     0.716      4713\n samples avg      0.675     0.717     0.682      4713\n\nf1_weighted : nan\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 228, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr',\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["starter.test_classifier(GaussianNB())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0eea0067-5ffb-48f6-9500-98a2ee89aff8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Running experiment for GaussianNB()\nGetting per-class scores\nComputing overall results\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/naive_bayes.py\", line 207, in fit\n    X, y = self._validate_data(X, y)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4060, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/naive_bayes.py\", line 207, in fit\n    X, y = self._validate_data(X, y)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4060, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/naive_bayes.py\", line 207, in fit\n    X, y = self._validate_data(X, y)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/naive_bayes.py\", line 207, in fit\n    X, y = self._validate_data(X, y)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/naive_bayes.py\", line 207, in fit\n    X, y = self._validate_data(X, y)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/naive_bayes.py\", line 207, in fit\n    X, y = self._validate_data(X, y)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/naive_bayes.py\", line 207, in fit\n    X, y = self._validate_data(X, y)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/naive_bayes.py\", line 207, in fit\n    X, y = self._validate_data(X, y)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/naive_bayes.py\", line 207, in fit\n    X, y = self._validate_data(X, y)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n              precision    recall  f1-score   support\n\n           0      0.420     0.701     0.525       422\n           1      0.142     0.420     0.212       652\n           2      0.590     0.809     0.683      2234\n           3      0.127     0.470     0.201       151\n           4      0.175     0.456     0.253       274\n           5      0.240     0.560     0.336       811\n           6      0.077     0.315     0.124       108\n           7      0.108     0.344     0.164        61\n\n   micro avg      0.325     0.654     0.434      4713\n   macro avg      0.235     0.510     0.312      4713\nweighted avg      0.396     0.654     0.484      4713\n samples avg      0.405     0.634     0.449      4713\n\nf1_weighted : nan\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/naive_bayes.py\", line 207, in fit\n    X, y = self._validate_data(X, y)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Running experiment for GaussianNB()\nGetting per-class scores\nComputing overall results\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/naive_bayes.py\", line 207, in fit\n    X, y = self._validate_data(X, y)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4060, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/naive_bayes.py\", line 207, in fit\n    X, y = self._validate_data(X, y)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4060, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/naive_bayes.py\", line 207, in fit\n    X, y = self._validate_data(X, y)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/naive_bayes.py\", line 207, in fit\n    X, y = self._validate_data(X, y)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/naive_bayes.py\", line 207, in fit\n    X, y = self._validate_data(X, y)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/naive_bayes.py\", line 207, in fit\n    X, y = self._validate_data(X, y)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/naive_bayes.py\", line 207, in fit\n    X, y = self._validate_data(X, y)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/naive_bayes.py\", line 207, in fit\n    X, y = self._validate_data(X, y)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/naive_bayes.py\", line 207, in fit\n    X, y = self._validate_data(X, y)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n              precision    recall  f1-score   support\n\n           0      0.420     0.701     0.525       422\n           1      0.142     0.420     0.212       652\n           2      0.590     0.809     0.683      2234\n           3      0.127     0.470     0.201       151\n           4      0.175     0.456     0.253       274\n           5      0.240     0.560     0.336       811\n           6      0.077     0.315     0.124       108\n           7      0.108     0.344     0.164        61\n\n   micro avg      0.325     0.654     0.434      4713\n   macro avg      0.235     0.510     0.312      4713\nweighted avg      0.396     0.654     0.484      4713\n samples avg      0.405     0.634     0.449      4713\n\nf1_weighted : nan\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/naive_bayes.py\", line 207, in fit\n    X, y = self._validate_data(X, y)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["starter.test_classifier(LogisticRegression())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"36112ac5-ebed-497b-ae27-c2788f2a6ef1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Running experiment for LogisticRegression()\nGetting per-class scores\nComputing overall results\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1344, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4060, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1344, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4060, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1344, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1344, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1344, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1344, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1344, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1344, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1344, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n              precision    recall  f1-score   support\n\n           0      0.652     0.680     0.666       422\n           1      0.499     0.686     0.578       652\n           2      0.744     0.919     0.822      2234\n           3      0.533     0.742     0.620       151\n           4      0.612     0.737     0.669       274\n           5      0.544     0.714     0.617       811\n           6      0.732     0.833     0.779       108\n           7      0.291     0.377     0.329        61\n\n   micro avg      0.643     0.805     0.715      4713\n   macro avg      0.576     0.711     0.635      4713\nweighted avg      0.647     0.805     0.716      4713\n samples avg      0.689     0.773     0.710      4713\n\nf1_weighted : nan\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1344, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Running experiment for LogisticRegression()\nGetting per-class scores\nComputing overall results\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1344, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4060, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1344, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4060, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1344, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1344, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1344, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1344, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1344, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1344, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1344, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n              precision    recall  f1-score   support\n\n           0      0.652     0.680     0.666       422\n           1      0.499     0.686     0.578       652\n           2      0.744     0.919     0.822      2234\n           3      0.533     0.742     0.620       151\n           4      0.612     0.737     0.669       274\n           5      0.544     0.714     0.617       811\n           6      0.732     0.833     0.779       108\n           7      0.291     0.377     0.329        61\n\n   micro avg      0.643     0.805     0.715      4713\n   macro avg      0.576     0.711     0.635      4713\nweighted avg      0.647     0.805     0.716      4713\n samples avg      0.689     0.773     0.710      4713\n\nf1_weighted : nan\n/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1344, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 826, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/databricks/python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 864, in column_or_1d\n    raise ValueError(\nValueError: y should be a 1d array, got an array of shape (4061, 8) instead.\n\n  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["starter.test_classifier(KNeighborsClassifier())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"69bdf64f-d626-4d83-a45b-5cbae302a29e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Running experiment for KNeighborsClassifier()\nGetting per-class scores\nComputing overall results\n              precision    recall  f1-score   support\n\n           0      0.182     0.874     0.301       422\n           1      0.474     0.468     0.471       652\n           2      0.818     0.620     0.705      2234\n           3      0.421     0.656     0.513       151\n           4      0.585     0.540     0.562       274\n           5      0.369     0.420     0.393       811\n           6      0.661     0.722     0.690       108\n           7      0.032     0.869     0.063        61\n\n   micro avg      0.369     0.589     0.454      4713\n   macro avg      0.443     0.646     0.462      4713\nweighted avg      0.596     0.589     0.560      4713\n samples avg      0.471     0.576     0.499      4713\n\nf1_weighted : 0.5253375257247371\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Running experiment for KNeighborsClassifier()\nGetting per-class scores\nComputing overall results\n              precision    recall  f1-score   support\n\n           0      0.182     0.874     0.301       422\n           1      0.474     0.468     0.471       652\n           2      0.818     0.620     0.705      2234\n           3      0.421     0.656     0.513       151\n           4      0.585     0.540     0.562       274\n           5      0.369     0.420     0.393       811\n           6      0.661     0.722     0.690       108\n           7      0.032     0.869     0.063        61\n\n   micro avg      0.369     0.589     0.454      4713\n   macro avg      0.443     0.646     0.462      4713\nweighted avg      0.596     0.589     0.560      4713\n samples avg      0.471     0.576     0.499      4713\n\nf1_weighted : 0.5253375257247371\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n"]},"transient":null}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ENSF612FinalProject new data with original 4 models","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":1490589538919688}},"nbformat":4,"nbformat_minor":0}
